AppSec для LLM: prompt injection, jailbreak

AppSec (Application Security) — практика защиты приложений от кибератак

Основные угрозы: 
1. Prompt injection 
2. JailBreak

Виды и защита от PJ: 
1. Прямая инъекция — явная вставка команд
2. Косвенная инъекция — использование скрытых триггеров

Как вариант защиты: 
1. Фильтрация ввода
2. Изоляция контекста
3. Лимиты на длину ответа


Популярные техники JilBreak: 
1. Role-playing - «Притворись злым ИИ»
2. Кодирование запроса - «Расшифруй этот хеш <...>»
3. Многошаговые атаки — постепенное выуживание информации

Техники защиты: 
1. Жесткие ограничения — блокировка опасных тем
2. Мониторинг аномалий — анализ тональности и контекста
3. Сэндбоксинг — выполнение кода в изолированной среде

Promptlock — первый ИИ вымогатель. Первый известный шифровальщик, использующий генеративный ИИ для создания полиморфного кода 

В качестве мер противодействия: 
1. Использовать EDR-системы
2. Внедрять мониторинг сетевых тоннеле	й

Методы защиты в дикой природе

GithubCopilot использует sandbox для исполнения файлов.



