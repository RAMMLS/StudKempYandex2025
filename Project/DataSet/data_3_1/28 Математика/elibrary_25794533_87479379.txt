ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 41

УДК 519.856

А.В. Гасников1,2, П. Е. Двуреченский2,4, Ю.Е. Нестеров3,5
1Московский физико-технический институт (государственный университет)

2Институт проблем передачи информации РАН
3Национальный исследовательский университет Высшая школа экономики

4Weierstrass Institute for Applied Analysis and Stochastics
5Universite catholique de Louvain, Center for operations research and econometrics

Стохастические градиентные методы с неточным
оракулом

В работе предпринята попытка описать современное состояние методов проекции
градиента (в том числе прямых методов и методов покомпонентного спуска) решения
задач выпуклой стохастической оптимизации с неточным оракулом (неточность неслу-
чайной природы), выдающим стохастический субградиент. Заметная часть приведен-
ных в статье результатов была получена относительно недавно. Цель данной работы
– собрать все вместе и посмотреть на разнообразные факты из этой области с единой
позиции.

Ключевые слова: стохастическая оптимизация, рандомизация, неточный оракул,
безградиентные методы, покомпонентные методы

A.V.Gasnikov1,2, P. E.Dvurechensky2,4, Yu. E.Nesterov3,5
1Moscow Institute of Physics and Technology (State University)

2Institute for Information Transmission Problems RAS
3National Research University Higher School of Economics
4Weierstrass Institute for Applied Analysis and Stochastics

5Universite catholique de Louvain, Center for operations research and econometrics

Stochastic gradient methods with inexact oracle

In this paper, we try to describe state of the art in projected gradient methods, including
gradient-free and coordinate descent methods, for convex stochastic optimization problems
with inexact oracle. This oracle is meant to give access to the stochastic subgradient of
an objective function with some inexactness of deterministic nature. Most of the results
described in the paper are obtained relatively recently. The goal of this work is to collect
these results all together and consider them from a unified viewpoint.

Key words: stochastic optimization, randomozation, inexact oracle, gradient-free
methods, coordinate descent method

Статья приурочена к 80-летию Бориса Теодоровича Поляка

1. Введение
В 1960-е годы численные методы выпуклой оптимизации переживали свою первую боль-

шую революцию. В работах того времени четко и последовательно развивалась линия гра-
диентных методов. Основополагающим здесь можно признать вклад Бориса Теодоровича
Поляка [1, 2], с работ которого во многом и началось активное и повсеместное ис-
пользование градиентных методов в Советском Союзе. Следующая революция началась
в конце 1970-х годов после фундаментальных работ А. С. Немировского, Д. Б. Юдина,
Л. Г. Хачияна, N. Karmarkar’а и др. [3, 4]. В монографии [4] была предложена класси-
фикация задач выпуклой (и не только) оптимизации по степени гладкости и выпуклости.
Были получены нижние оценки для соответствующих классов задач оптимизации с ора-
кулом, выдающим по запросу градиент или стохастический градиент, его компоненту или



42 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

просто значение функции в точке. Стало понятно, чего в принципе можно достичь. Стали
строиться оптимальные методы, см., например, [5–7]. При этом на задачи начали смотреть
более пристально с точки зрения теории сложности. Появилась битовая сложность. Была
показана полиномиальная разрешимость задач линейного программирования в битовой
сложности [3]. Началась разработка полиномиальных методов внутренней точки для задач
выпуклой оптимизации на базе метода Ньютона, которая впоследствии привела к созда-
нию общей теории [8–11] и соответствующего пакета CVХ [12], способного решать широкий
спектр задач выпуклой оптимизации в пространствах размерности до 𝑛 ∼ 104−105. Однако
вызовы нового тысячелетия заставляют снова вернуться к градиентным методам. Задачи,
которые стали возникать в последние десять лет, отличаются огромными размерностями
𝑛 ∼ 106 − 109. Такие задачи (классифицируемые как задачи large-scale и huge-scale опти-
мизации) приходят из анализа данных, поиска равновесий в различных сетевых моделях
(связанных с компьютерными и транспортными сетями), биоинформатики и многих других
областей. Для таких размерностей шаг (итерация) метода Ньютона, становится слишком
дорогим, поэтому приходится снова возвращаться к более медленным (в смысле скоро-
сти сходимости), но более дешевым (в смысле стоимости одной итерации) градиентным
методам (см. [13]). Но для указанных размерностей даже градиентные методы могут ис-
пытывать проблемы. В этой связи оказалась очень полезной концепция «заглядывания в
черный ящик», т.е. использование структуры задачи с целью ускорения вычислений [14],
и использование вместо градиента его легко вычислимой (стохастической) аппроксимации
[11]. Как следствие, принято стало считать, что правильный способ эффективно решать ту
или иную задачу – это отказаться от общих методов, оптимальных на больших классах,
и погружаться в специфику конкретной задачи в надежде ускориться и получить оценки
лучше, чем нижние границы [4]. Можно сказать, что началась новая революция. Поток
работ на эту тему в основных профилирующих журналах (например, Math. Program.) рез-
ко возрос (см., например, обзор [11]). Тем не менее, параллельно стали появляться работы
(в том числе работы авторов статьи), показывающие, что многие эффективные методы
решения современных задач выпуклой оптимизации в пространствах огромных размеров
получаются сочетанием небольшого количества приемов и идей. Цель настоящей работы
состоит в том, чтобы собрать воедино набор основных таких идей и показать их связь с
некоторыми концепциями 1960-х годов, многие из которых восходят к Б. Т. Поляку. Мы со-
средоточимся на оценках числа итераций, требующихся различным методам для решения
задачи выпуклой оптимизации с заданной точностью по функции. Эта информация не в
полной мере характеризует эффективность метода, но она необходима для последующего
его полного исследования. Мы также ограничимся рассмотрением методов проекции гради-
ента [15, 16], в которые, например, не входят очень популярные в последнее время методы
условного градиента [11, 17, 18]. В качестве основного инструментария для получения эф-
фективных методов используется метод оценивающих последовательностей, восходящий к
работам одного из авторов статьи [7, 10, 14]. Здесь имеются и альтернативные подходы,
например, [19–21]. Из-за ограничений на объем статьи и большого количества технических
деталей мы ограничимся здесь лишь изложением общей картины. В частности, в статье
не приводится псевдокод соответствующих алгоритмов, но, как правило, указываются ис-
точники, в которых его можно найти. Мы также не претендуем здесь на полный обзор со-
временного состояния исследований, посвященных градиентным методам. Более того, при
ссылках на литературу мы далеко не всегда ссылались на первоисточники, иногда предпо-
читая ссылаться на удачно написанный более доступный и более современный обзор или
монографию.

2. Стохастическая оптимизация

Рассматривается задача выпуклой стохастической оптимизации [2, 22, 23]:



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 43

𝑓 (𝑥) = 𝐸𝜉 [𝑓 (𝑥, 𝜉)] → min, (1)
𝑥∈𝑄

где 𝑓 (𝑥) – выпуклая по 𝑥 ∈ R𝑛 (𝑛 ≫ 1) функция. Будем называть ∇𝑓 (𝑥, 𝜉) стохастиче-
ским субградиентом функции 𝑓 (𝑥, 𝜉) в точке 𝑥 по первой переменной [24]. Будем считать,
что1 п.н. ‖∇𝑓 (𝑥, 𝜉)‖2 ≤ 𝑀 , ∇ = ∇𝑥 и 𝐸𝜉 – перестановочны.2 Предположим, что 𝑄 – вы-
пуклое замкнутое ограниченное множество. Обозначим через 𝑅 – диаметр множества 𝑄:
𝑅 = max𝑥,𝑦∈𝑄 ‖𝑥− 𝑦‖2. В действительности, достаточно считать, что 𝑅 – расстояние от
точки старта до решения (ближайшего, если решение не единственно) задачи (1) (см. за-
мечание 1). При этом множество 𝑄 может быть не ограничено [27].3 Мы будем считать,
что множество 𝑄 простой структуры, т.е. на него можно эффективно проектироваться.
В работах [27–31] рассматривались различные варианты методов проекции градиента с
усреднением и длинными шагами4 применительно к решению задачи (1). Общая оценка
скорости сходимости этих методов есть (𝜎 > 0 – малый доверительный уровень, 𝑁 – чис-
ло итераций метода, на каждой итерации мы можем один раз обратиться к оракулу за
субградиентом)5 (︃ √︂ )︃

1 + ln (𝜎−1
𝑃𝑥𝑁 𝑓 (𝑥𝑁 )−min 𝑓 (𝑥) ≥ )

𝐶𝑀𝑅 =

(︃ 𝑥∈𝑄 √︂𝑁 )︃
1 + ln (𝜎−1

= 𝑃𝑥𝑁 𝐸𝜉 [𝑓 (𝑥𝑁 , 𝜉)]−min𝐸𝜉 [𝑓 (𝑥, 𝜉)] ≥
)

𝐶𝑀𝑅 ≤ 𝜎,
𝑥∈𝑄 𝑁

где 𝐶 – константа (здесь и далее константы в основном будут в диапазоне ∼ 100 − 102), а
случайный вектор 𝑥𝑁 – то, что выдает алгоритм (например, метод зеркального спуска [30]
или метод двойственных усреднений [27] – сравнительный анализ и описание «физики»
этих методов в детерминированном случае проводится в работе [21]) после 𝑁 итераций.
Мы будем называть 𝑥𝑁 – (𝜀, 𝜎)-р(︂ешением задачи (1), ес)︂ли

𝑃𝑥𝑁 𝑓 (𝑥𝑁 )−min 𝑓 (𝑥) ≥ 𝜀 ≤ 𝜎.
𝑥∈𝑄

Таким образом, для достижения точности по функции 𝜀 и доверительного уровня 𝜎 методу
потребуется (здесь и далее мы будем использовать 𝑂 ( · ), однако все эти формулы могут
быть переписаны с точными константами, что важно, поскольку во многих ситуациях такие
оценки используются для формирован(︂ия критерия ос)︂танова метода)

𝑀2𝑅2 ln(𝜎−1)
𝑂 (2)

𝜀2

1В действительности [25], здесь и практически в любом другом контексте, где возникают такого типа
условия, достаточно требовать, что п.н. выполнено неравенство ‖∇𝑓 (𝑦, 𝜉)−∇𝑓 (𝑥, 𝜉)‖2 ≤ 𝑀 . Это позво-
ляет в ряде случаев понизить оценку константы 𝑀 , и как следствие (см. (2)), ускорить метод. Отметим,
что под ∇𝑓 (𝑥, 𝜉) (аналогично под ∇𝑓 (𝑦, 𝜉)) понимается любой элемент соответствующего стохастического
субградиента [24].

2Для задач онлайн оптимизации условие перестановочности необходимо записывать в более общем (мар-
тингальном) виде [26].

3Впрочем, в случае неограниченного множества 𝑄, даже когда выпуклая функция 𝑓 (𝑥) имеет ограни-
ченную вариацию на 𝑄, мы не можем никак априорно оценить это расстояние 𝑅 в общем случае – оно
может быть сколь угодно большим [4]. Интересный нюанс для выпуклой (но не обязательно сильно вы-
пуклой и гладкой) функции 𝑓 (𝑥) имеет место, если 𝑓 (𝑥) задана на ограниченном множестве 𝑄. В этом
случае размер 𝑅 множества 𝑄 может не входить в оценку необходимого числа итераций. Например, это
имеет место для метода центра тяжести [2, 4, 11].

4Б.Т. Поляком было показано [28], что такое сочетание позволяет получать эффективные методы для
данного класса задач.

5Эта оценка неулучшаема с точностью до мультипликативной константы 𝐶 (при 𝑁 ≤ 𝑛 оценка неулуч-
шаема и в детерминированном случае 𝑓 (𝑥, 𝜉) ≡ 𝑓 (𝑥)), см. [4].



44 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

итераций. На каждой итерации вычисляется стохастический субградиент и осуществляется
проектирование.

Отметим, что если использовать метод Монте-Карло, заключающийся в замене исход-
ной задачи (1) следующей задачей

1 ∑︁𝑁
𝑓 (𝑥, 𝜉𝑘) → min, (3)

𝑁 𝑥∈𝑄
𝑘=1

где с.в. 𝜉𝑘 – i.i.d., и распределены так же, как и 𝜉, то для того, чтобы гарантировать, что
абсолютно точное решение этой новой задачи является (𝜀, 𝜎)-решением исходной задачи
потребуется взять 𝑁 порядка(︂[24] )︂

𝑀2𝑅2(𝑛 ln(𝑀𝑅/𝜀) + ln(𝜎−1))
𝑂 .

𝜀2

Это наблюдение хорошо поясняет, что подход, связанный с усреднением случайности
за счет самого метода, более предпочтителен, чем замена задачи (1) ее стохастической
аппроксимацией (3)6. Более предпочтителен не только тем, что допускает адаптивность
постановки и легко переносится на онлайн модификации исходной задачи но прежде всего
лучшей приспособленностью к большим размерностям.

Здесь важно подчеркнуть фундаментальную идею7, которую можно усмотреть, напри-
мер, в [2] и в цикле работ Б. Т. Поляка с Я. З. Цыпкиным [33], о том, что для получе-
ния (агрегирования) хороших оценок неизвестных параметров (особенно когда размерность
пространства параметров велика) имеет смысл рассматривать задачу поиска оптимальных
значений параметра как задачу стохастической оптимизации и рассматривать выборку как
источник стохастических градиентов. Например, истинное значение неизвестного вектора
параметров в предположении верности исходной параметрической гипотезы может быть
записано как решение задачи стохастической оптимизации [34, 35] (метод наибольшего
правдоподобия Фишера):

𝜃* = argmax𝐸𝜉 [𝐿 (𝜃, 𝜉)] ,
𝜃∈𝑄

где 𝐿 (𝜃, 𝜉) – логарифм функции правдоподобия. Однако решать эту задачу обычными
методами мы не можем, потому что математическое ожидание берется по с.в. 𝜉, распреде-
ление которой задается неизвестным параметром 𝜃*. Обойти эту сложность можно, если
решать ту же самую задачу

𝐸𝜉 [−𝐿 (𝜃, 𝜉)] → min
𝜃∈𝑄

методами стохастической оптимизации, получая на каждом шаге новую реализацию (эле-
мент выборки) 𝜉𝑘 и рассчитывая значения стохастического градиента 𝜕𝐿 (𝜃, 𝜉𝑘) /𝜕𝜃. То, что
выдает алгоритм, и будет оценкой вектора неизвестных параметров 𝜃*. Как правило, допол-
нительно известно, что 𝐿 (𝜃, 𝜉) – гладкая и 𝜇-сильно вогнутая (равномерно по 𝜉) функция
от 𝜃. Последнее обстоятельство позволяет получить лучшую оценку скорости сходимости
по функции [36–39] (в [36, 37] используется специальная модификация метода проекции

6Особенно ярко это проявляется в случае, бесконечномерных пространств, возникающих в статисти-
ческой теории обучения (СТО = SLT, Statistical Learning Theory) [32]. Попытка обучиться за счет мини-
мизации эмпирического риска (а именно так можно расшифровать формулу (3) в СТО) может не дать
состоятельной оценки/решающего правила, в то время как соответствующий стохастический зеркальный
спуск дает состоятельную оценку. Отметим, что в работе [32] приводится достаточно интересный общий ре-
зультат: в задачах обучения (в частности, в задачах СТО, математической статистики и онлайн обучения)
способ получения оптимальных (с точностью до логарифмических факторов) оценок/решающих правил
(или, другими словами, способ наискорейшего обучения) базируется на применении соответствующего ме-
тода зеркального спуска. Правда, найти «соответствующий метод», в свою очередь, представляет собой
непростую задачу.

7Распространяемую и на непараметрическую статистику. Отметим, что начиная с 1980-х годов XX века
в этом направлении был цикл работ А.С. Немировского, Б.Т. Поляка и А.Б. Цыбакова, оказавших заметное
влияние и на текущие исследования в этой области.



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 45

градиента с усреднением и выбором шагов ℎ𝑘 = 2 (𝜇 · (𝑘 + 1))−1 и ℎ𝑘 = (𝜇𝑘)−1, где 𝑘 –
номер итерации, о подходе [38] и близком к нему подходе [39] будет немного написано в
п. 3) (︂ )︂

𝑀2 ln(ln(𝑁)/𝜎)
𝑂 , (4)

𝜇𝑁

т.е. (𝑥 = 𝜃, 𝑓 = −𝐿, 𝐶 – (︂некоторая константа) )︂
𝑃𝑥 𝑓 (𝑥𝑁 )− ln (ln (𝑁) /

min 𝑓 (𝑥) ≥ 𝜎
𝐶𝑀2 )

𝑁 ≤ 𝜎.
𝑥∈𝑄 𝜇𝑁

Из неравенства Рао–Крамера [35] (𝑄 = R𝑛) будет следовать, что оценка (4) – не улучшаемая
(с точностью до слагаемого ln (ln (𝑁))). Правда, тут возникают некоторые тонкости, когда
мы говорим о неулучшаемости оценок с учетом вероятностей больших отклонений. Строго
говоря, классические результаты типа Рао–Крамера, Ван-Трисса и т.п. (см., например, [35])
позволяют лишь говорить о неулучшаемости в смысле сходимости полных математических
ожиданий (без вероятностей больших отклонений), и именно в таком смысле можно полу-
чить (с помощью методов [11, 37–39]) неулучшаемую (с точностью до мультипликативной
константы) оценку:

𝐶𝑀2
𝐸𝜉,𝑥 [𝑓 (𝑥𝑁 , 𝜉)]−min𝐸𝜉 [𝑓 (𝑥, 𝜉)] ≤ ,

𝑁
𝑥∈𝑄 𝜇𝑁

где 𝐶 – некоторая константа.
Можно обобщить рассмотренную постановку задачи (1) на случай, когда ‖∇𝑓 (𝑥, 𝜉)‖2

имеет субгауссовский хвост (опр(︀еделе
𝜎−

)︀ние см., например,(︀в [30)︀]). Тогда (в том числе в силь-
но выпуклом случае) вместо ln 1 стоит писать ln2 𝜎−1 . Если же ‖∇𝑓 (𝑥, 𝜉)‖22 имеет
степенной хвост [40], т.е. (︃ )︃ (︂ )︂

‖∇𝑓 (𝑥, 𝜉)‖2
𝑃 2 ≥ 1

𝑡 = 𝑂 ,
𝑀2 𝑡𝛼

где 𝛼 > 2, то8 (︃ √ )︃
𝑁 + (𝑁/𝜎)1/𝛼

𝑃𝑥𝑁 𝑓 (𝑥𝑁 )−min 𝑓 (𝑥) ≥ 𝐶𝛼𝑀𝑅 ≤ 𝜎.
𝑥∈𝑄 𝑁

Если дополнительно(︃𝑓 (𝑥) = 𝐸𝜉 [𝑓 (𝑥, 𝜉)] – 𝜇-сильно выпуклая функц)︃ия, то (при 𝛼 > 1)

ln (ln (𝑁)) + 𝜎−1/𝛼
𝑃𝑥𝑁 𝑓 (𝑥𝑁 )−min 𝑓 (𝑥) ≥ 𝐶 2

𝛼𝑀 ≤ 𝜎.
𝑥∈𝑄 𝜇𝑁 [︁ ]︁

Если ничего не известно о ‖∇𝑓 (𝑥, 𝜉)‖22, кроме неравенства 𝐸𝜉 ‖∇𝑓 (𝑥, 𝜉)‖22 ≤ 𝑀2, то по
неравенству Маркова (︃ ⌢ )︃

𝑃𝑥𝑁 𝑓 (𝑥𝑁 )−min 𝑓 (𝑥) ≥ 𝐶√𝑀𝑅 ≤ 𝜎,

(︃ 𝑥∈𝑄 𝜎 𝑁)︃
) ≥ 𝐶𝑀2

𝑃𝑥𝑁 𝑓 (𝑥𝑁 )−min 𝑓 (𝑥 ≤ 𝜎,
𝑥∈𝑄 𝜎𝜇𝑁

8Приводимые ниже неравенства стоит понимать так, что 𝑥𝑁 выдается методом [27,30], а в сильно вы-
пуклом случае, методом [37–39]. При этом для оценок вероятностей больших уклонений в случае тяжелых
хвостов требуются некоторые оговорки и уточнения. К сожалению, мы не смогли найти соответствующий
выписанным оценкам (в случае тяжелых хвостов) источник литературы. Приведенные здесь нами формулы
нуждаются в дополнительной проверке.



46 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

второе неравенство подразумевает 𝜇-сильную выпуклость 𝑓 (𝑥).
Можно задать вопрос: насколько вообще уместно рассматривать постановки, в которых

возникают тяжелые хвосты. Ведь, если мы можем эффективно вычислять значения функ-
ции 𝑓 (𝑥) = 𝐸𝜉 [𝑓 (𝑥, 𝜉)] в задаче (1), то ни о каких тяжелых хвостах можно не заботить-
ся. Поскольку, выбр(︀ав чи

𝜎−
)︀сло шагов так, чтобы метод находил 𝜀-решение с вероятностью

≥ 1/2, запустив log 1
2 реализаций такого метода и выбрав реализацию с ми(︀нима

𝜎−
)︀льным

значением функции в конечной точке алгоритма, мы за дополнительную log 1
2 плату

(мультипликативную) получим с вероятностью 1−𝜎 среди выданных ответов хотя бы одно
𝜀-решение [31, 39]. Однако предположение о возможности эффективно вычислять значения
функции (при условии трудной вычислимости ее градиента), как правило, не встречается
на практике. В некотором смысле типичным тут является пример 1 (см. ниже) вычисле-
ния вектора PageRank (при 𝑛 ∼ 109). Собственно, искусственность ситуации, в которой
значение функции легко вычислимо, а градиент нет, неплохо соответствует философии
быстрого автоматического дифференцирования (БАД) [41, 42]. Согласно теории БАД, ес-
ли мы можем посчитать значение функции, то мы можем не более чем в 4 раза дороже
посчитать и ее градиент.9 Как следствие, если мы можем эффективно вычислить значение
𝑓 (𝑥), то, как правило, мы и ∇𝑓 (𝑥) можем эффективно вычислить. Тогда и на исходную
задачу (1) можно смотреть уже не как на задачу стохастической оптимизации, а как на
обычную задачу выпуклой оптимизации, что может существенно ускорить ее решение (см.
п. 3 ниже). Впрочем, во многих интересных приложениях отмеченный прием (амплифика-
ция), как правило, весьма успешно работает [43, 44], поскольку время работы метода, как
правило, оказывается заметно большим, чем расчет значения функции.

Отметим также (следуя А.С. Немировскому), что с помощью концепции неточного ора-
кула (см. п. 3 ниже) мы можем редуцировать задачу с тяжелыми хвостами ‖∇𝑓 (𝑥, 𝜉)‖22 и
компактным множеством 𝑄 к ситуации, когда п.н. ‖∇𝑓 (𝑥, 𝜉)‖2 ≤ 𝑀 (𝜀). Для этого нужно
«обрезать» стохастический гр{︃адиент

∇𝑓 (𝑥, 𝜉) , ‖∇𝑓 (𝑥, 𝜉)‖2 ≤𝑀 (𝜀)
∇𝑓 (𝑥, 𝜉) :=

𝑀 (𝜀) ∇𝑓(𝑥,𝜉)
‖∇𝑓(𝑥,𝜉)‖ , ‖∇ .

𝑓 (𝑥, 𝜉)‖2 > 𝑀 (𝜀)
2

Константа 𝑀 (𝜀) подбирается оптимальным образом, исходя из желаемой точности 𝜀. Чем
больше 𝑀 (𝜀), тем меньше смещение (bias) обрезанного стохастического градиента, как
следствие, тем точнее можно восстановить решение исходной задачи, но при этом возрас-
тает необходимое число итераций (см. (2), (4), в которые входит константа 𝑀 = 𝑀 (𝜀)).
Оптимальный выбор этой константы (с точностью до логарифмического фактора) дает
приведенные выше оценки.

Все сказанное выше10 обобщается и на другие прокс-⧸︁структуры [4] (не обязательно ев-
клидовы, когда выбирается прокс-функция 𝑑 (𝑥) = ‖𝑥‖22 2), согласно которым осуществ-
ляется (как правило, по явным формулам11) «проектирова∑︀ние» на 𝑄. Например, для мно-
жества 𝑄 = 𝑆𝑛 (1) (𝑆𝑛 (𝑅) = {𝑥 ∈ R𝑛 : 𝑥𝑖 ≥ 0, 𝑖 = 1, ..., 𝑛, 𝑛

𝑖=1 𝑥𝑖 = 𝑅} – единичный сим-
9Это легко понять в случае 𝑓 (𝑥) = ⟨𝑐, 𝑥⟩. В случае, когда 𝑓 (𝑥) – многочлен, это также несложно понять

(Баур–Штрассен). В общем случае рассуждения аналогичны.
10В сильно выпуклом случае (если в прямом пространстве выбрана ⧸︁𝑞-(︁норма (𝑙𝑛𝑞 ))︁и прокс-функция

𝑑 (𝑥) ≥ 0) в оценку (4) дополнительно входит фактор 𝜔 = sup 2𝑉 (𝑥, 𝑦) 𝛼 ‖𝑦 − 𝑥‖2𝑞 ≥ 1, где 𝑉 (𝑥, 𝑦)
𝑥,𝑦∈𝑄

определяется через 𝑑 (𝑥) в замечании 1 (при 1 ≤ 𝑞 ≤ 2 удается найти такую прокс-функцию, что 𝜔 = 𝑂 (ln𝑛),
см. замечание 2), где 𝛼 – ко⧸︀нстанта сильной выпуклости 𝑑 (𝑥) на 𝑄 в 𝑞-норме [38]. Отметим, что при этом
константы в отношение 𝑀2 𝜇 в оценке (4), считаются относительно 𝑞-нормы.

11Впрочем, в подавляющем большинстве случаев даже если нет возможности явно решить задачу проек-
тирования, ее можно эффективно решить приближенно [9] (посредством перехода к двойственной задаче
малой размерности). Как правило, при таком способе рассуждений необходимо использовать концепцию
неточного оракула (см. п. 3), поскольку рассчитать градиент двойственного функционала можно лишь при-
ближенно. Однако все эти выкладки обычно не изменяют по порядку сложность одной итерации метода,
основной составляющей которой является расчет (пересчет) градиента или его стохастического аналога.
Некоторые тонкости и оговорки тут возникают в случае разреженных постановок задач [43, 44].



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 47

плекс в 𝑛-мерном пространстве) часто рассматривается (∑︀см. пример 1 вычисления векто-
ра PageRank ниже) KL-прокс-структура: 𝑑 (𝑥) = ln𝑛 + 𝑛

𝑖=1 𝑥𝑖 ln𝑥𝑖. Эта прокс-функция
𝑑 (𝑥) ≥ 0 сильно выпукла в 1-норме с константой сильной выпуклости 𝛼 = 1 на 𝑆𝑛 (1)
– в силу неравенства Пинскера [27, 30]. Она «наилучшим» образом подходит для сим-
плекса (с некоторыми оговорками [26, 45]). Выгода от ее использования в том, что норма
стохастического субградиента всегда оценивается в сопряженном пространстве к простран-
ству, в котором прокс-функция 1-сильно выпукла. В рассматриваемом случае√получается
‖∇𝑓 (𝑥, 𝜉)‖∞ ≤ 𝑀 , что в типичных ситуациях дает оценку константы 𝑀 в ∼ 𝑛 раз луч-
ше, чем в 2-норме, а плата за это – увеличение оценки размера области (в этой ситуации в
оценке числа итераций нужно использовать 𝑅2 = max 𝑑 (𝑥) /𝛼) в ∼ ln𝑛 раз. Детали имеют-

𝑥∈𝑄
ся, например, в статье [30]. Интересным также представляется выбор прокс-функции для
прямого произведения симплексов [46]. Здесь мы отметим (следуя А.С. Немировскому),
что в общем случае оптимальный выбор прокс-структуры (с точностью до умножения
на степень логарифма размерности пространства) связан с симметризацией множества 𝑄.
Выпуклое центрально симметричное множество 𝐵 = (𝑄−𝑄) /2 порождает по теореме
Колмогорова норму, в которой 𝐵 является единичным шаром. Далее ищется оптималь-
ная прокс-функция, согласованная с этой нормой. Говоря более формально, ищется такая
сильно выпуклая в этой норме функция 𝑑 (𝑥) ≥ 0 с константой сильной выпуклости 𝛼 ≥ 1,
чтобы число 𝑅2 = max 𝑑 (𝑥) /𝛼 было минимально возможным. Если 𝑄 = 𝐵𝑛

2 (1) – единич-
𝑥∈𝑄

ный евклидов шар, то значение 𝑅2 ≤ 1, т.е. не зависит от размерности пространства 𝑛, но
если 𝑄 = 𝐵𝑛

∞ (1) – единичный шар в 𝑙𝑛∞ норме, то 𝑅2 = Ω(𝑛) (т.е. существует такое число
𝜒, что при достаточно больших значениях 𝑛 имеет место неравенство 𝑅2 ≥ 𝜒𝑛, причем
можно добиться того, что 𝑅2 = 𝑂 (𝑛)). Как будет видно из замечания 2 (на примере когда
𝑄 = 𝐵𝑛

∞ (1)), выбор 𝑙𝑛∞ нормы не всегда приводит к оптимальным во всех смыслах оценкам
(аналогичные примеры нам встретятся и в следующих двух пунктах).

Замечание 1. Стоит обратить внимание на то, что если выбрана евклидова прокс-
структура, то 𝑅2 – квадрат евклидова диаметра 𝑄. При переходе к другой прокс-
структуре в оценках числа итераций в качестве 𝑅2 фигурирует прокс-диаметр 𝑄
(diam (𝑄) = max 𝑑 (𝑥)), поделенный на константу сильной выпуклости 𝛼 = 𝛼 (𝑄) прокс-

𝑥∈𝑄
функции, заданной на 𝑄, относительно выбранной нормы в прямом пространстве. Скажем,
в случае выбора KL-прокс-структуры, 1-нормы в прямом пространстве и 𝑄 = 𝑆𝑛 (𝑟), имеем

𝑅2 = diam (𝑆𝑛 (𝑟)) /𝛼 (𝑆𝑛 (𝑟)) = 𝑟 · diam (𝑆𝑛 (1)) / (𝛼 (𝑆𝑛 (1)) /𝑟) = 𝑟2 · (ln𝑛) /1 = 𝑟2 ln𝑛.

Для евклидовой прокс-структуры размер 𝑄 = 𝑆𝑛 (𝑟) равнялся бы 2𝑟2. Отсюда можно сде-
лать вывод (верный и в общем случае), что выбор прокс-структуры имеет целью оптималь-
но учесть структуру множества с точки зрения того, как в итоговую оценку числа итераций
будет входить размерность пространства, в котором происходит оптимизация. При гомоте-
тичном увеличении/уменьшении множества оценки числа итераций будут меняться одина-
ково, независимо от выбранной прокс-структуры. Отметим также, что в формуле (2) для
прокс-структуры, отличной от евклидовой(︀ (︀ )︀)︀ (︀

𝜎−
)︀

, точнее писать не 𝑅2 ln 1 , где 𝑅2 = 𝑟2 ln𝑛
(приводим для KL-прокс-структуры), а 𝑟2 ln𝑛+ ln 𝜎−1 = 𝑟2 ln (𝑛/𝜎). В действительно-
сти, в оценки скоростей сходимости (в среднем, но не в оценки вероятностей больших укло-
нений, см. замечание 4) всех упомянутых в данной статье методов (кроме обычного (пря-
мого) градиентного метода и метода Франк–Вульфа) входит не прокс-диаметр множества
𝑄, на котором происходит оптимизация (если 𝑄 = R𝑛 прокс-диаметр будет бесконечным), а
брэгмановское «расстояние» 𝑉 (𝑥*, 𝑥0) от решения 𝑥* до точки старта 𝑥0 (часто выбирают
𝑥0 = argmin 𝑑 (𝑥), 𝑑 (𝑥0) = 0, ∇𝑑 (𝑥0) = 0 [27]), где 𝑉 (𝑥, 𝑦) = 𝑑 (𝑥)− 𝑑 (𝑦)− ⟨∇𝑑 (𝑦) , 𝑥− 𝑦⟩.

𝑥∈𝑄
Замечание 2. Пусть 𝑄 = 𝐵𝑛

𝑞 (1) – единичный шар в 𝑞-норме или, в более общем случае,
𝑄 содержится в 𝐵𝑛

𝑞 (1). Относительно оптимального выбора нормы и прокс-структуры мож-
но заметить следующее (см., например, [4, 9, 47]): если 𝑞 ≥ 2, то в качестве нормы оптималь-
но выбирать ‖‖2 (2-норму) и евклидову прокс-структуру. Определим 𝑞′ из 1/𝑞 + 1/𝑞′ = 1.



48 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

Пусть 1 ≤ 𝑞 ≤ 2, тогда 𝑞′ ≥ 2. Если при этом 𝑞′ = 𝑜 (log 𝑛), то оптимально выбирать
‖‖ = ‖‖𝑞, а прокс-структуру задавать прокс-функцией 𝑑 (𝑥) = 1

2(𝑞−1) ‖𝑥‖
2
𝑞 . Во всех этих

случаях 𝑅2 = 𝑂 (1). Для 𝑞′ ≥ Ω (log 𝑛), выберем 𝑎 = 2 log 𝑛/ (2 log 𝑛− 1), ‖‖ = ‖‖𝑎, а прокс-
структуру будем задавать прокс-функцией 𝑑 (𝑥) = 1

2(𝑎−1) ‖𝑥‖
2
𝑎. В этом случае𝑅2 = 𝑂 (log 𝑛).

Не сложно проверить, что для единичного симплекса, вложимого в единичный шар в
1-норме, выбор соответствующих прокс-структур из замечаний 1, 2 приводит к одинако-
вым оценкам числа итераций в категориях 𝑂 (). В частности, для случая когда 𝑄 = 𝐵𝑛

∞ (1),
выбор 2-н[︁ормы и евк]︁лидовой прокс-ст(︀руктуры(︀ пр)︀ив⧸︀од)︀ит к оценке (д(︀алее в з(︀амеч)︀а⧸︀нии)︀
речь идет только об оценке (2)) 1) 𝑂 𝑀2 −1

2𝑛 ln 𝜎 𝜀2 вместо 2) 𝑂 𝑀2
∞𝑛 ln 𝜎−1 𝜀2

(здесь 𝐸𝜉 ‖∇𝑓 (𝑥, 𝜉)‖2 2
1 ≤𝑀∞), получаемой при выборе 𝑙𝑛∞ нормы в прямом пространстве.

Аналогично вышенаписанному можно отметить, что в тип(︀ичных си(︀туац)︀и⧸︀ях)︀оценка 2 может
быть в ∼ 𝑛 раз хуже оценки 1. Тем не менее оценка 2 𝑂 𝑀2 −1

∞𝑛 ln 𝜎 𝜀2 не улучшаема
в общем случае. Потому что в общем случае нет гарантий, что 𝑀2

2 ≪ 𝑀2
∞, а если такие

гарантии есть, то это уже сужает класс функций, для которого получена нижняя оценка с
константой 𝑀2

∞.
Подчеркнем, что приведенные здесь оценки (2), (4) (в детерминированном случае при

дополнительном условии, что требуемое число итераций для достижения точности 𝜀 удо-
влетворяет неравенству 𝑁 (𝜀) ≤ 𝑛 [4]) без дополнительных предположений являются
неулучшаемыми (с точностью до мультипликативных констант) для класса задач стоха-
стической оптимизации (1) и негладких детерминированных задач. Причем дополнитель-
ная гладкость функционала задачи (1) в стохастической постановке в общем случае не
приводит к улучшению приведенных оценок (2), (4). Если делать дополнительные предпо-
ложения о малости случайного шума (low noise conditions), то приведенные оценки можно
улучшать (см. п. 3). Один пример того, как можно устанавливать неулучшаемость оценок,
был рассмотрен выше, следуя [2] (на основе неравенства Рао–Крамера), в общем случае
следует смотреть монографию [4] и [47]. Отметим, что в работе [47] показывается, что для
задач стохастической оптимизации (1) при оптимизации на шарах в 𝑞-норме оценки типа
(2), даваемые методами зеркального спуска с выбором прокс-структуры согласно замеча-
нию 2, соответствуют с точностью до логарифмического фактора нижним оценкам.

Следует, однако, различать задачи стохастической оптимизации и задачи, в которые
мы сами искусственно привносим случайность (используя рандомизацию), с целью умень-
шения числа арифметических операций на одну итерацию метода [31, 43, 44, 48]. К послед-
нему можно отнести случай, когда (негладкий) выпуклый функционал в задаче является
детерминированным, но представляет собой трудно вычислимый интеграл (сумму), зави-
сящую от (оптимизируемых) параметров, который может быть компактно представлен в
виде математического ожидания по некоторой простой вероятностной мере. Тогда выгод-
нее вычислять на ка(︀ждой итерации метода стохастический градиент, существенно экономя
на вычислениях на кажд

𝜎−
)︀ом шаге и лишь немного теряя на логарифмическом увеличении

числа шагов (∼ ln 1 ). Подробнее об этом подходе будет сказано ниже в примере 3.
Ярким примером на эту тему является Google problem (PageRank). По-видимому, одними
из первых на эту задачу посмотрели в указанном выше контексте А. В. Назин и Б. Т. Поляк
в работе [49], см. также [44, 50–52].

Пример 1 (PageRank). Задача поиска вектора PageRank 𝑝 из уравнения 𝑃 𝑇 𝑝 = 𝑝
(𝑃 – стохастическая матрица по строкам матрица), сводится [51, 52] к негладкой задаче
выпуклой оптимизации (седловой зад⟨︀аче) ⟩︀

max 𝑢, 𝑃 𝑇 𝑝− 𝑝 → min .
𝑢∈𝑆𝑛(1) 𝑝∈𝑆𝑛(1)

Перепишем эту задачу в общем виде

min max ⟨𝑦,𝐴𝑥⟩ ,
𝑥∈𝑆𝑛(1) 𝑦∈𝑆𝑛(1)



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 49

где матрица 𝐴 большого размера 𝑛 × 𝑛 (вообще говоря, неразреженная) с элементами,
ограниченными по модулю числом 𝑀 = 1. Клю[︁чевое наблюдение для решения этой задачи
состоит в том [30, 49], что: ]︁

𝐴𝑥 = 𝐸 𝐴⟨𝑖[𝑥]⟩
𝑖[𝑥] ,

где 𝐴⟨𝑖⟩ – 𝑖-й столбец матрицы 𝐴, в(︀ектор 𝑥 ∈ 𝑆𝑛 (1), а с.в. 𝑖 [𝑥] имеет категориальное распре-
деление с вектором параметров 𝑥. Ва)︀жным следствием является тот факт, что левая часть
равенства, 𝐴𝑥, вычисляется за 𝑂 𝑛2 арифметических операций, а выражение, стоящее в
правой части под математическим ожиданием, 𝐴⟨𝑖[𝑥]⟩ – всего лишь за 𝑂 (𝑛) арифметических
операций. Используя это наблюдение (и аналогичное для умножения матрицы 𝐴 на вектор-
строку слева), можно показать, что (рандомизированный) метод зеркального спуска [30]
(с KL-прокс-структурой) и стохастическим градиентом по 𝑥, равным 𝐴⟨𝑖[𝑥]⟩ (аналогично по
𝑦), после (︂ )︂ (︂ )︂

𝑛𝑀2 ln (𝑛/𝜎) 𝑛 ln (𝑛/𝜎)
𝑂 = 𝑂

𝜀2 𝜀2

элементарных арифметических операций выдает такие 𝑥 ∈ 𝑆𝑛 (1) и 𝑦 ∈ 𝑆𝑚 (1), что

max 𝑦𝑇𝐴𝑥− min 𝑦𝑇𝐴?̃? ≤ 𝜀
𝑦∈𝑆𝑚(1) ?̃?∈𝑆𝑛(1)

с в(︀ероятностью ≥ 1− 𝜎.
Аналогичные)︀ рассуждения [31, 48] позволяют получить с такими же затратами

𝑂 𝑛 ln (𝑛/𝜎) 𝜀−2 такой вектор 𝑥 ∈ 𝑆𝑛 (1), что ‖𝐴𝑥‖∞ ≤ 𝜀. Кроме того, если дополни-
тельно известно, что матрица 𝑃 – разрежена, то можно(︀организовать поиск (𝜀, 𝜎)-решения
еще эффективнее – рандомизировать при проектировании на симплекс [26, )︀48, 52]. Тогда
вместо фактора 𝑛 в оценках общего числа операций 𝑂 𝑛+ 𝑠 ln𝑛 ln (𝑛/𝜎) 𝜀−2 будет фигу-
рировать 𝑠 – «среднее» число элементов матрицы 𝑃 (по строкам и столбцам) отличных от
нуля (к сожалению, численные эксперименты Антона Аникина показали, что это «эффек-
тивное среднее» число на практике часто близко к максимальному по строкам и столбцам,
т.е. от этого подхода можно получить гарантированную выгоду, только если имеет место
равномерная разреженность матрицы по строкам и столбцам [48]).

Отметим, что в определенных ситуациях (например, при условии 𝑛 ≫ 𝜀−2 – типич-
ном для задач huge-scale оптимизации) такому рандомизированному методу потребуется
использовать относительно небольшое количество элементов матрицы 𝐴 за все время ра-
боты, в то время как для класса детерминированных алгоритмов потребуется считать как
минимум половину элементов матрицы 𝐴 [3] для 𝜀 = 0.1.

Хочется также отметить, что на задаче из примера 1 можно продемонстрировать боль-
шую часть современного инструментария, необходимого для решения задач huge-scale оп-
тимизации. Так, в случае разреженной матрицы 𝐴 для решения поставленной негладкой
задачи выпуклой оптимизации (и многих других) хорошо подходит метод Б. Т. Поляка [2,
51], работающий по нижним оценкам (2) (функционал негладкий) и при этом учитывающий
разреженность 𝐴 при пересчете градиента [51]. Другой подход [50] (задача поиска вектора
PageRank сводится к минимизации другого функционала), также нашедший широкое при-
менение [43, 53–55], связан с заменой градиентного спуска на покомпонентный спуск. Такая
замена увеличивает в среднем число итераций всегда не больше (а, как правило, намного
меньше), чем в 𝑛 раз, но зато (благодаря разреженности) происходит экономия при пере-
счете одной компоненты градиента, как правило (но не всегда – особенности возникают в
разреженных задачах), в 𝑛 раз по сравнению с расчетом полного градиента. В результате
получается√выгода, которая при определенных условиях может сократить объем вычис-
лений в ∼ 𝑛 раз (см., например, [43]). Поясним это следующим примером [48], который
можно понимать как вариацию неускоренного варианта покомпонентного метода с выбором
максимальной компоненты [50].



50 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

Пример 2 (разреженный PageRank). Задача поиска вектора PageRank также мо-
жет быть сведена к следующей задаче выпуклой оптимизации (далее для определенности
будем полагать 𝛾 = 1, в действительности, по этому параметру требуется прогонка)

∑︁𝑛1
𝑓 (𝑥) = ‖𝐴𝑥‖2 𝛾

+ (−𝑥 2
𝑘) → min ,

2 2 2 + ⟨𝑥,𝑒⟩=1
𝑘=1

где, как и в примере 1, 𝐴 = 𝑃 𝑇 − 𝐼, 𝐼 – еди{︂ничная матрица, 𝑒 = (1, ..., 1)𝑇 ,

𝑦, 𝑦 ≥ 0
(𝑦)+ = .

0, 𝑦 < 0
√

При этом мы считаем, что в каждом столбце и каждой строке матрицы 𝑃 не более 𝑠≪ 𝑛
элементов отлично от нуля (𝑃 – разрежена). Эту задачу предлагается решать обычным
градиентным методом12, но не в евкли{︂довой норме, а в 1-норме (см., н}︂апример, [21]):

𝐿
𝑥𝑘+1 = 𝑥𝑘 + argmin 𝑓 (𝑥𝑘) + ⟨∇𝑓 (𝑥𝑘) , ℎ⟩+ ‖ℎ‖2 ,

⃦⃦ ℎ: ⟨ℎ,𝑒⟩=0 2 1

где ⟨𝑖⟩⃦⃦2𝐿 = max 𝐴 + 𝛾 ≤ 3 (𝐴⟨𝑖⟩ – тижения точности
1,...,𝑛 2 (︀𝑖-й ст⧸︀олб)︀ец мат

𝑖= (︀р⧸︀ицы)︀ 𝐴). Для дос
𝜀2 по функции потребует(︀ся с)︀делать 𝑂 𝐿𝑅2 𝜀2 = 𝑂 1 𝜀2 итераций [14]. Не сложно про-
верить, что пересчет градиента на каждой итерации заключается в умножении 𝐴𝑇𝐴ℎ, что
может быть сделано за 𝑂 𝑠2 . Связано это с тем, что в⧸︀ектор ℎ всегда имеет т⧸︀олько две ком-
поненты, отличные от нуля (такая разреженность получилась благодаря выбору 1-нормы),
причем эти компоненты соответствуют argmin 𝜕𝑓 (𝑥𝑘) 𝜕𝑥𝑖 и argmax 𝜕𝑓 (𝑥𝑘) 𝜕𝑥𝑖, что пере-

𝑖=1,...,𝑛 𝑖=1(︀,...,𝑛считывается (при использовании специального двоичного дерева (кучи)︀) для поддержания
максимальной и минимальной компоненты градиента [51]) за 𝑂 𝑠2 ln𝑛 (логарифмический
фактор можно ослабить, если использовать, например, фибоначчиевы или б(︀родалевы ⧸︀куч)︀и
[48]). Таким образом, общая трудоемкость предложенного метода будет 𝑂 𝑛+ 𝑠2 ln𝑛 𝜀2 ,
что заметно лучше многих известных методов [52]. Стоит также отметить, что функционал,
выбранный в этом примере, обеспечивает намного лучшую оценку ‖𝐴𝑥‖2 ≤ 𝜀 по сравне-
нию с функционалом из примера 1, который (в(︀ варианте [31⧸︀]) о)︀беспечивает ‖𝐴𝑥‖∞ ≤ 𝜀.
Наилучшая (в разреженном случае без, условий на спектральную щель матрицы 𝑃 [52])
из известных нам на данный момент оценок 𝑂 𝑠 ln𝑛 ln (𝑛/𝜎) 𝜀2 [26, 52] для ‖𝐴𝑥‖∞ мо-
жет быть улучшена приведенной в этом примере оц√енкой, поскольку, как уже отм√ечалось
ранее, ‖𝐴𝑥‖2 может быть (и так часто бывает) в ∼ 𝑛 раз больше ‖𝐴𝑥‖∞, а 𝑠≪ 𝑛.

Заметим, что в решении могут быть маленькие отрицательные компоненты. Также чис-
ленные эксперименты показали [48], что для достижения выписанных оценок требуется
препроцессинг (в нашем случае он заключается в представлении матрицы по строкам в
виде списка смежности: в каждой строке отличный от нуля элемент хранит ссылку на
следующий отличный от нуля элемент, аналогичное представление матрицы делается и
по столбцам). Заметим, что препроцессинг помогает ускорять решение задач не только в
связи с более полным учетом разреженности постановки, но и, например, в связи с более
эффективной организацией рандомизации [31, 43, 50].

Пример 2 также характерным образом демонстрирует, как используется разреженность
(см. также [44, 51, 56]). Обратим внимание на то, что число элементов в матрице 𝑃 , отлич-
ных от нуля, даже при наложенном условии разреженности (по строкам и столбцам), все

12Выписанная далее оценка скорости сходимости (на число итераций) – неулучшаема с точностью до
мультипликативного фактора. Речь идет не об оптимальности метода на классе гладких задач на сим-
плексе, а о том, что конкретно для этого метода такая оценка если и может быть улучшена, то лишь на
мультипликативный фактор. Это замечание касается практически всех известных сейчас градиентных ме-
тодов. Показывается это приблизительно так же (даже еще проще), как и в случае оптимальности оценок
на классах [4]: строятся конкретные примеры (семейства) функций.



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 51

равно может быть достаточно большим 𝑠𝑛. Удивляет то, что в оценке общей трудоемко-
сти это число не присутствует. Это в перспективе (при правильной организации работы с
памятью) позволяет решать задачи огромных размеров. Более того, даже в случае неболь-
шого числа не разреженных ограничений вида ⟨𝑎𝑖, 𝑥⟩ = 𝑏𝑖, 𝑖 = 1, ..,𝑚 = 𝑂 (1), можно
«раздуть» пространство (не более чем в два раза), в котором происходит оптимизация (во
многих методах, которые учитывают разреженность такое раздутие не приведет к серьез-
ным затратам), и переписать эту систему в виде 𝐴𝑥 = 𝑏, где матрица будет иметь размеры
𝑂 (𝑛)×𝑂 (𝑛), но число отличных от нуля элементов в каждой строке и столбце будет 𝑂 (1).
Таким образом, допускается небольшое число «плотных» ограничений.

Заметим, что если применить метод условного градиента [17] (Франк–Вульфа) к задаче
из примера 2, то общая трудоемко(︃сть (для точности 𝜀2(︀ ⧸︀ )︀,)︃как и в примере 2) будет [48, 56]

𝑠2 ln 2 + 𝑛 𝑠2
𝑂 𝑛+ .

𝜀2

В связи со сказанным выше, заметим, что задача может быть не разрежена, но свойство
разреженности появляется в решении при использовании метода Франк–Вульфа, что также
может заметно сокращать объем вычислений в постановках аналогичных примеру 2, но
с матрицами 𝐴, у которой число столбцов на много порядков больше числа строк (см.,
например, п. 3.3 [11], [57]).

Приведем еще один пример, подсказывающий, как следует решать задачу (3), получен-
ную из (1) с применением идеи метода Монте-Карло.

Пример 3 (рандомизация суммы). Пусть необходимо решить задачу выпуклой оп-
тимизации (или ее композитный вариант, см., например, замечание 6):

𝑁
1 ∑︁

𝑓 (𝑥) = 𝑓𝑘 (𝑥) → min, (5)
𝑁 𝑥∈𝑄

𝑘=1

где 𝑓𝑘 (𝑥) – негладкие выпуклые функции с ограниченной числом 𝑀 нормой субградиента,
𝑄 – выпуклое замкнутое множество простой структуры (можем эффективно на него проек-
тироваться, согласно заданной прокс-функции) прокс-диаметра 𝑅. Введем новую функцию

𝑓 (𝑥, 𝜉) = 𝑓𝜉(𝑥),

где 𝜉 принимает значения от 1 до 𝑁 с вероятностью 1/𝑁 . Стохастический субградиент
функции 𝑓(𝑥, 𝜉) легко вычислить. Для этого разыгрывается за 𝑂 (ln𝑁) с.в. 𝜉, принима-
ющая значения 1, ...., 𝑁 с равными вероятностями (см., например, [52]). Затем считается
субградиент 𝑓𝜉 (𝑥) (и выполняется прокс-проектирование на 𝑄). Как уже отмечалось ранее,
можно найти (𝜀, 𝜎)-решение так пони(︃маемой зад(︀ачи )︀()︃5) за

𝑀2𝑅2 ln 𝜎−1

𝑂
𝜀2

итераций, со стоимостью одной и(︀терации, равной 𝑂 (ln𝑁), + затраты на вычисления суб-
градиента 𝑓𝜉 (𝑥) + затраты на вычисле⧸︀ние)︀проекции. Если решать задачу без рандомиза-
ции, то число итераций будет 𝑂 𝑀2𝑅2 𝜀2 , строго говоря, здесь 𝑀 должно быть немного
меньше за счет того, что ⃦⃦⃦⃦ ⃦⃦⃦⃦

𝑁

max
𝑥∈ ⃦ 1 ∑︁∇𝑓𝑘 (𝑥) ≤

𝑁 ⃦ max ‖∇𝑓𝑘 (𝑥)‖* ,
𝑄 𝑘=1,...,𝑁,𝑥∈𝑄

𝑘=1 *

но мы считаем, что обе части неравенства одного порядка. Зато шаг итерации будет теперь
почти в 𝑁 раз дороже. И если 𝑁 ≫ 1, это может оказаться существенным.



52 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

Приведенную постановку можно распространить на случай, когда взвешивание функ-
ций не равномерное (тогда первое разыгрывание с.в. 𝜉, имеющей категориальное распре-
деление, или приготовление процедуры рандомизации займет 𝑂 (𝑁), а все последующие
𝑂 (ln𝑁)) и 𝑓𝑘 (𝑥) := 𝐸𝜉 [𝑓𝑘 (𝑥, 𝜉𝑘)] с равномерно ограниченными (по 𝑘, 𝑥 и 𝜉) нормами сто-

𝑘

хастических субградиентов. При этом все приведенные оценки числа итераций сохранятся.
Причем требование равномерной ограниченности норм стохастических субградиентов мож-
но существенно ослабить за небольшую плату (см. выше).

Если на решение задачи (3) теперь посмотреть в контексте описанной рандомизации
с 𝑓𝑘 (𝑥) = 𝑓 (𝑥, 𝜉𝑘) (здесь 𝜉𝑘 – не случайная величина, а полученная в методе Монте-Карло
𝑘-я по порядку реализация с.в. 𝜉), то «все встанет на свои места» в смысле одинаково-
сти (с точностью до логарифмического фактора) двух подходов к решению задачи (1),
описанных в начале пункта.

Описанная рандомизация при вычислении субградиента суммы функций, по-видимому,
была одной из первых, которые предлагались в стохастической оптимизации [22]. Однако
она популярна и по сей день, например, в связи с приложениями к поиску равновесий
в транспортных сетях [58–62] и анализу данных [63–65]. В частности, в [11, 43, 59, 66–
71] в предположении, что все функции в (5) гладкие с константой Липшица градиента
𝐿, предложен специальный рандомизированный метод (на базе описанного выше способа
рандомизации су(︂м(︂мы), в кот{︂ором чис

⧸︀ √︁ло вычисле

⧸︀ }︂
н)︂ий градиентов слагаемы

(︀ (︀ )︀)︀)︂
х13

𝑂 𝑁 +min 𝐿𝑅2 𝜀, 𝑁𝐿𝑅2 𝜀 ln (Δ𝑓/𝜀) + ln 𝜎−1 ,

где Δ𝑓 разность значения функции в стартовой точке и в минимуме. Эта оценка с точ-
ностью до выражения под логарифмом соответствует нижней оценке в классе детермини-
рованных алгоритмов [70, 72]. Если дополнительно имеется еще и 𝜇-сильная выпуклость
𝑓 (𝑥), то оценку мож(︁н(︁о перепис{︁ать сл√︀едующим}︁)︁о(︀бразом (︀ )︀)︀)︁

𝑂 𝑁 +min 𝐿/𝜇, 𝑁𝐿/𝜇 ln (Δ𝑓/𝜀) + ln 𝜎−1 .

Отметим, что вторая оценка переходит в первую при следующей квадратичной регуля⧸︁ри-
зации. К выпуклому функционалу прибавляется регуляризирующее слагаемое 𝜇 ‖𝑥‖22 2.
В результате функционал⧸︀становится сильно выпуклым и справедлива вторая оценка на
число вычислений градиента. Такая регуляризация изменяет исходную целевую функцию
на число, не больше 𝜇𝑅2 2, и чт⧸︀обы итоговая погрешность по исходной функции была
порядка 𝜀, нужно выбирать 𝜇 ≃ 𝜀 𝑅2 и решать регуляризованную задачу с точностью 𝜀/2.
При подстановке этого значения во вторую оценку числа вычислений градиента последняя
переходит в первую оценку.

Отметим также, что сначала (с(︂м., например, [55, 68]) получается результат о сходимости
средних14: )︂

𝐸 𝑓 (𝑥𝑁 )−min 𝑓 (𝑥) ≤ 𝜀,
𝑥∈𝑄

где (︁(︁ {︁ √︀ }︁)︁ )︁
𝑁 = 𝑁 (𝜀) = 𝑂 𝑁 +min 𝐿/𝜇, 𝑁𝐿/𝜇 ln (Δ𝑓/𝜀) ,

Потом из неравенства Марко(︂ва получают оценку вероя)︂тности больших уклонений:
(︀ )︀

𝑃 𝑓 𝑥𝑁(𝜀) −min 𝑓 (𝑥) ≥ 𝜎 ≤ 𝜀/𝜎,
𝑥∈𝑄

13Строго говоря, имеющиеся сейчас рассуждения для второго аргумента минимума [43, 73] позволяют по-
лучить только при дополнительных предположениях о структуре задачи оценку, аналогичную приведенной
ниже, и то только в категориях общего числа арифметических операций.

14Описанная далее конструкция не зависит от того, изначально имела место сильная выпуклость или мы
ее искусственно ввели должной регуляризацией.



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 53

которую переписывают в виде(︂ (︀ )︀ )︂
𝑃 𝑓 𝑥𝑁(𝜀𝜎) −min 𝑓 (𝑥) ≥ 𝜎 ≤ 𝜀,

𝑥∈𝑄

где (︁(︁ {︁ √︀ }︁)︁(︀ (︀ )︀)︀)︁
𝑁 (𝜀𝜎) = 𝑂 𝑁 +min 𝐿/𝜇, 𝑁𝐿/𝜇 ln (Δ𝑓/𝜀) + ln 𝜎−1 .

Мы привели здесь это наблюдение, потому что оно оказывается полезным и во многих
других контекстах, в которых рандомизированный метод сходится со скоростью геометри-
ческой прогрессии.

При наличии дополнительной структуры у задачи (5) приведенные оценки можно бы-
ло получить (и даже немного улучшить, например, учитывая разреженность) исходя из
рандомизированных покомпонентных методов (например, ALPHA или APPROX [63] или
ACRCD* из замечания 8 [43]) для «двойственной» к (5) задаче [43, 55, 59, 73, 74].15 Заметим
также, что в работе [43] показывается, как можно просто получить часть выписанных оце-
нок с помощью метода, работающего по оценкам (8) (см. ниже).

В книге [2] Б.Т. Поляк отмечает, что если рандомизация осуществляется каким-то спе-
циальным образом, например[︁, таким, что]︁16

𝐸 ‖∇𝑓 (𝑥, 𝜉)‖2* ≤ 𝐶𝑛 ‖∇𝑓 (𝑥)‖2* + Δ, (6)

где Δ ≥ 0 – некоторая малая погрешность, и в точке минимума ∇𝑓 (𝑥) = 0, то приведен-
ные выше оценки (2), (4) можно существенно улучшить. Примеры будут приведены ниже
в п. 4 (см. (22)). В частности, в сильно выпуклом случае можно получить геометрическую
скорость сходимости. Важно отметить, что при рандомизации, возникающей в покомпо-
нентных спусках, спусках по направлению и безградиентных методах в гладком случае
условие (6) выполняется [2, 50, 76]. Мы вернемся к этому кругу вопросов в п. 4. Описанная
же выше конструкция (с довольно грубым неравенством Маркова) используется в данном
контексте [50, 76] для (точной!) оценки больших уклонений. Причем за счет регуляриза-
ции функционала, о которой было сказано выше, все это переносится и просто на гладкий
случай без предположения сильной выпуклости.

3. Стохастические градиентные методы с неточным оракулом
В этом пункте мы опишем, что можно получить, если дополнительно известно, что 𝑓 (𝑥)

– гладкая по 𝑥 функция, с константой Липшица градиента 𝐿 и(или) сильно выпуклая с
константой 𝜇 ≥ 0, но вычисление стохастического градиента на каждом шаге происходит
с неконтролируемой неточностью 𝛿, вообще говоря, не случайной природы.17

Замечание 3. И гладкости, и сильной выпуклости можно добиться искусственно. Как
уже отмечалось в п. 2, сильная выпуклость всегда легко получается регуляризацией функ-
ционала в исходной задаче. Как правило, это не дает ничего нового с точки зрения вы-
писанных оценок (и даже может ухудшать эти оценки на логарифмический фактор), но
в ряде специальных случаев (см. ниже) это может давать определенные преимущества.
Кроме того, такая регуляризация иногда просто необходима для корректности постановки.
Это связано с тем, что в общем случае даже для гладких детерминированных выпуклых
задач мы можем гарантировать сходимость итерационного метода лишь по функции, но
не по аргументу. Для сходимости по аргументу нужна сильная выпуклость функционала,

15Строго говоря, построение двойственной задачи предполагает возможность явного выделения в функ-
ционале в виде отдельного слагаемого сильно выпуклого композита – желательно сепарабельного.

16Если рассматривать приложения методов стохастической оптимизации к СТО [32], а в правой части
неравенства вместо ‖∇𝑓 (𝑥)‖2* писать ‖∇𝑓 (𝑥)‖1/2* , то выписанное неравенство будет соответствовать усло-
виям малого шума Цыбакова–Массара, Бернштейна [75].

17Особое внимание таким постановкам стали уделять после выхода книг [2, 33]. В них обстоятельно
изучается «влияние помех», в том числе не случайной природы, на методы выпуклой оптимизации.



54 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

которую и обеспечивают должной регуляризацией (см., например, конец п. 2), при этом
сходимость по аргументу имеет место к решению регуляризованной задачи. Идея регуляри-
зации используется в популярном методе двойственного сглаживания [77] (регуляризация
двойственной задачи с целью улучшения гладких свойств прямой). В отличие от прямой ре-
гуляризации эта техника хорошо работает только для вполне конкретных задач, имеющих
определенную (седловую – Лежандрову) структуру (модель), когда исходная задача имеет
явное двойственное представление (см. пример 4), введя в которое регуляризацию, мож-
но явно (эффективно) пересчитать, во что превратится исходная прямая задача. Другой
пример сглаживания будет приведен в п. 4.

Сформулируем более точно предположения об оракуле, выдающем стохастический гра-
диент, следуя [78, 79].18

Предположение 1. (𝛿, 𝐿, 𝜇)-оракул выдает (на запрос, в котором указывается только
одна точка 𝑥) такую пару (𝐹 (𝑥, 𝜉) , 𝐺 (𝑥, 𝜉)) (с.в. 𝜉 независимо разыгрывается из одного и
того же распределения, фигури[︁рующего в постановке (1)), что для всех 𝑥 ∈ 𝑄 ограничена
дисперсия ]︁

𝐸𝜉 ‖𝐺 (𝑥, 𝜉)− 𝐸𝜉 [𝐺 (𝑥, 𝜉)]‖2* ≤ 𝐷,

и для любых 𝑥, 𝑦 ∈ 𝑄

𝜇 ‖𝑦 − 𝑥‖2 ≤ 𝐸𝜉 [𝑓 (𝑦, 𝜉)]− 𝐸𝜉 [𝐹 (𝑥, 𝜉)]− ⟨𝐸𝜉 [𝐺 (𝑥, 𝜉)] , 𝑦 − 𝑥⟩ ≤ 𝐿 ‖𝑦 − 𝑥‖2 + 𝛿.
2 2

Из недавних результатов [78–87] можно получить общий метод (мы приводим огруб-
ленный вариант оценки времени работы этого метода для большей наглядности) с такими
оценками скорости сходимости19:

{︃ (︃ √︂ )︃ (︃ (︂ )︂ 𝑝 )︃}︃
𝐿𝑅2 𝐷𝑅2 (︁𝜇)︁ 1 )︂ (︂

𝑝+
min 𝑂 + +𝑁𝑝𝛿 , 𝑂 𝐿𝑅2 1 𝐷 𝐿 𝑝+1

exp −ϒ𝑁 · + + 𝛿 ,
𝑁𝑝+1 𝑁 𝐿 𝜇𝑁 𝜇

(7)
где 1 ≤ ϒ ≤ 𝐶 ln𝑛, 𝐶 – некоторая константа, а параметр 𝑝 ∈ [0, 1] подбирается «оптималь-
но» перед запуском метода исходя из масштаба шума 𝛿. Для лучшего понимания оценки
(7) полез{︃но (︃ее перепис√︂ать в еще бол)︃ее огр(︂убленном(︂виде20: (︁𝜇)︁ 1 )︂ )︂}︃

𝐿𝑅2 𝐷𝑅2
min 𝑂 + +𝑁𝑝 𝑝+

𝑅2 1 𝐷
𝛿 , 𝑂 𝐿 exp −ϒ𝑁 · + +𝑁𝑝𝛿 .

𝑁𝑝+1 𝑁 𝐿 𝜇𝑁

Этот общий метод есть в некотором смысле «выпуклая комбинация» двойственного гради-
ентного метода (DGM) и быстрого градиентного метода21 (FGM) [83, 87], оценки скорости
сходимости для которых имеют соответственно вид

18В работе [78] собрано много различных мотиваций такому предположению (определению), обобщаю-
щему классическую концепцию 𝛿-субградиента [2]. В определенном смысле это предположение 1 наиболее
общее и одновременно наиболее точно отражающее спектр всевозможных приложений [43, 55, 60–62].

19Оценки характеризуют достигнутую в среднем точность (по оптимизируемому функционалу) после
𝑁 итераций. При этом, в случае когда минимум достигается на втором аргументе (выгодно использовать
факт наличия 𝜇-сильной выпуклости), под 𝑁 правильнее понимать не число итераций, а число обращений
к (𝛿, 𝐿, 𝜇)-оракулу [87]. Отметим, что при 𝑝 = 0 оценку можно сделать непрерывной по параметру 𝜇 ≥ 0 (см.
[79]). Также заметим, что в метод (например, в размер шагов) не входит требуемое число итераций (или
желаемая точность – одно через другое выражается). Таким образом, можно говорить об адаптивности
метода. Отметим, что за это не приходится дополнительно платить логарифмическую плату [27]. Отметим
также, что при 𝑝 = 1 метод наихудшим (а при 𝑝 = 0 наилучшим) способом (среди всех разумных вариаций
градиентного метода) накапливает неточность в вычислении градиента. Это переносится и на негладкие
задачи (см. далее).

20Насколько нам известно, для всех методов, которые используют только градиент и значение функции
(или их стохастические аналоги) накопление шума методом со скоростью 𝑁𝑝𝛿 с 𝑝 ∈ [0, 1] – является общим
местом.

21Отметим, что при 𝐷 = 0 не улучшаемые оценки, которые дает метод FGM [11], были установлены
Б.Т. Поляком [2] для ряда других многошаговых методов (метод тяжелого шарика, сопряженных гради-



ТРУДЫ МФТИ{︂. 20(︂16. Том 8, № 1 А
√︁ )︂.В. Гасников, П.Е. Двуреченский, Ю

(︁
2 (︀ )︀ )︁}︂

.Е. Нестеров 55

(DGM) min{︂𝑂(︂ 𝐿𝑅 𝐷𝑅2

𝑁 +√︁ 𝑁 + 𝛿 )︂, 𝑂 𝐿𝑅2exp −ϒ1𝑁
𝜇

(︁ (︁ 𝐷
𝐿√︁+ 𝜇)︁𝑁 + 𝛿 ,√︁ )︁}︂

𝐿𝑅2
(FGM) 𝐷𝑅2

min 𝑂 𝑅 e p
𝑁2 + 𝑁 +𝑁𝛿 , 𝑂 𝐿 2 x −ϒ 𝐷

2𝑁
𝜇 𝐿
𝐿 + 𝜇𝑁 + 𝜇 𝛿 .

Комбинируя эти два метода, можно непрерывно настраиваться (оптимально подбирая ме-
тод, регулируя 𝑝 ∈ [0, 1]) на шум (известного масштаба). В этой связи также полезно
отметить (аналогичный факт имеет место и для покомпонентного варианта FGM [43]),
что FGM есть специальная выпуклая комбинация прямого градиентного метода (PGM),
оценки скорости сходимости которого совпадают с оценками DGM, и метода зеркального
спуска/двойственных усреднений [21, 92] (по-видимому, здесь вместо зеркального спуска
можно использовать и метод из работы [93]). Нельзя в этой связи не обратить внимание
на то, что комбинация двух методов привела к новому методу, работающему лучше, чем
каждый из методов по отдельности. Отметим здесь также недавнюю работу [94], в которой
предлагается общий способ получения ускоренных (быстрых) методов.

Вся последующая часть п. 3 будет посвящена обсуждению этих результатов и их окрест-
ностей.

Прежде всего, заметим, что дисперсию у первого аргумента минимума в (7) можно
уменьшать в 𝑚 раз, запрашивая на одном шаге реализацию стохастического градиента
не один раз, а 𝑚 раз, и заменяя стохастический градиент средним арифметическим [11,
31, 79] (в случае тяжелых хвостов у стохастических градиентов лучше пользоваться более
робастными оценками, например, медианного типа [4]).22 Это имеет смысл делать, если
слагаемое, отвечающее стохастичности, доминирует. Важно, что мы при этом не увели-
чиваем число итераций, и слагаемое 𝑁𝑝𝛿 остается прежним. Отметим, что число вызовов
оракула при этом увеличивается, но тем не менее в некоторых ситуациях такой подход
может оказаться оправданным. Такая игра используется23 в способе получения второго
аргумента оценки (7). В этой связи оценку (7) правильнее переписать следующим образом
(здесь 𝑁 (𝜀) – число обращений к (𝛿, 𝐿, 𝜇)-оракулу, необходимых для достижения в сред-
нем по функции точности 𝜀, индекс 1 соответствует просто выпуклому, а индекс 2 сильно
выпуклому случаю):

{︃ (︂ )︂ 1 (︂ )︂}︃
𝐿𝑅2 𝑝+1 𝐷𝑅2

𝑁1 (𝜀) = max{︃𝑂(︃ , 𝑂 ,

(︂𝜀 )︂ 𝜀2

1 (︂ )︂)︃ (︂ )︂}︃
𝐿 𝑝+1 𝐿𝑅2 𝐷

𝑁2 (𝜀) = max 𝑂 ln , 𝑂 (8)
𝜇 𝜀 𝜇𝜀

при (условия на допустимый уровень шума, при котором оценки (8) имеют такой же вид,
с точностью до 𝑂 (1), как если бы шума не было)

ентов). Отличие в том, что тогда оценки были установлены локально. Все приведенные в данной статье
оценки – глобальные, т.е. не требуют оговорок о близости точки старта к решению, для гарантии нуж-
ной скорости сходимости. Заметим также, что техника установления локальной сходимости основана, как
правило, на первом методе Ляпунова [2, 88], в то время как глобальной – на втором [2, 89]. При этом
функцию Ляпунова можно искать по непрерывному аналогу итерационного процесса – системе дифферен-
циальных уравнений [89]. Скажем, для обычного градиентного метода это будет система [1] (Коши, 1847):
𝑑𝑥/𝑑𝑡 = −∇𝑓 (𝑥). Скорости сходимости у итерационного процесса и его непрерывного аналога могут от-
личаться. Скажем, непрерывный аналог метода Ньютона сходится за конечное время. Другой пример –
метод зеркального спуска [4]. Недавно появилась работа, посвященная и непрерывному аналогу FGM [90],
см. также [91].

22Этот прием в западной литературе часто называют «mini-batch» [11].
23Вместе с идеей рестартов [38, 43, 56, 84–87], распространяющей (ускоряющей) практически любой ите-

рационный метод (желательно с явной оценкой необходимого числа итераций 𝑁 (𝜀) для достижения за-
данной точности 𝜀) на случай сильно выпуклого функционала. Нетривиально здесь то, что при довольно
общих условиях при таком распространении сохраняется (и работает уже в условиях сильной выпуклости)
свойство оптимальности исходного метода.



56 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

(︂ (︁ )︁ 𝑝 )︂ (︂ )︂
≤ 𝜀 (︁

𝑝+1 𝜇)︁ 𝑝
+1

𝛿1 (𝜀) 𝑂 𝜀 · , 𝛿2 (𝜀) ≤ 𝑂 𝜀 · 𝑝
. (9)

𝐿𝑅2 𝐿

Как уже отмечалось, выписанные оценки (7) ((8), (9)) характеризуют скорость сходимо-
сти в среднем. Они, с одной стороны, не улучшаемы24 с точностью до мультипликативной
константы (см. п. 2 и [4, 47]), а, с другой стороны, достигаются. Все это (неулучшаемость
оценок) справедливо и при 𝛿 = 0 и(или) 𝐷 = 0. При этом в случае 𝐷 = 0, 𝜇 = 0 необ-
ходимо считать, что требуемое число итераций для достижения точности 𝜀 удовлетворяет
неравенству 𝑁 (𝜀) ≤ 𝑛 [4], в противном случае оценки улучшаемы – метод центров тяжести
[4, 11], с оценкой числа итераций типа 𝑂 (𝑛 ln (𝐵/𝜀)), где |𝑓 (𝑥)| ≤ 𝐵. В терминах больших
отклонений возникают оценки, аналогичные тем, которые были приведены в п. 2, см. [87].

Отмеченные результаты переносятся и на прокс-структуры отличные от евклидо-
вой [87]. При этом рассмотрение какой-либо другой 𝑞-нормы (𝑙𝑞-нормы) в прямом про-
странстве (𝑞 ≥ 1), отличной от евклидовой, в сильно выпуклом случае (когда минимум
достигается на втором выражении в (7)), как правило, не имеет смысла. Связано это с
тем, что квадрат евклидовой асферичности 𝑞-нормы, который может возникать в оценках
числа обусловленности прокс-функции в 𝑞-норме (это число, в свою очередь, оценивает
увеличение числа итераций метода при переходе от евклидовой норме к 𝑞-норме), боль-
ше либо равен 1. Равенство достигается на евклидовой норме. Скажем, для 1-нормы эта
асферичность оценивается снизу размерностью пространства [14, 38]. Другими словами,
действительно, можно выбирать в сильно выпуклом случае 𝑞-норму (отличную от евкли-
довой) и получать оцен(︃ки(︂на ч)︂исло итераци)︂й)︃вида (см. (7), (8) и п. 2)

1 (︂
𝐿 𝑝+1 𝐿𝑅2 2𝑉 (𝑥, 𝑦)

𝑂 𝜔 ln , 𝜔 = sup ,
𝜇 𝜀 2

𝑥,𝑦∈𝑄 𝛼 ‖𝑦 − 𝑥‖𝑞

где 𝐿 и 𝜇 считаются относительно 𝑞-нормы, а 𝑅2 – брэгмановское «расстояние» от точки
старта до решения (см. замечание 1). Однако смысла, как правило, в этом нет, посколь-
ку 𝜔 ≥ 1, а число обусловленности 𝜒 = 𝐿/𝜇 не меньше, чем в случае выбора 2-нормы.
Например [38], для функции ‖𝑥‖22 = 𝑥21 + ...+ 𝑥2𝑛 в евклидовой норме число обусловленно-
сти 𝜒 = 1, а в 1-норме 𝜒 = 𝑛. Тем не менее выгода от использования не евклидовой прокс-
структуры в сильно выпуклом случае может быть, если рассматривать задачи композитной
оптимизации, в которых сильная выпуклость приходит от композитного слагаемого (см.
замечание 6). Так, в приложениях, описанных в работах [55, 59], в качестве композитного
слагаемого возникает сильно выпуклая в 1-норме энтропийная функция. Отметим, что эн-
тропию при этом нельзя использовать в качестве прокс-функции. Другими словами, в дан-
ной ситуации нельзя использовать KL-прокс-структуру (см. замечание 1), поскольку для
нее 𝜔 = ∞. Нужно брать (и это можно сделать, см. замечание 2) другую прокс-функцию,
соответствующую 1-норме, которая обеспечивает (по-видимому, оптимально возможную)
оценку 𝜔 = 𝑂 (ln𝑛).

Заметим также, что обычный метод FGM в не стохастическом сильно выпуклом случае
для задач безусловной оптимизации, в действительности, дает оценку (следует сравнить с
(8)) [10]: (︃√︃ (︂ )︂)︃

𝐿 𝑓 (𝑥0)− 𝑓 (𝑥*)
𝑂 ln .

𝜇 ⧸︀𝜀
Поскольку ∇𝑓 (𝑥*) = 0, то 𝑓 (𝑥0)− 𝑓 (𝑥*) ≤ 𝐿𝑅2 2. Ес⧸︀ли рассматривается задача условной
оптимизации (на выпуклом множестве 𝑄 ⊂ R𝑛), то, вообще говоря, ∇𝑓 (𝑥*) ̸= 0, следова-
тельно, нельзя утверждать, что 𝑓 (𝑥0)− 𝑓 (𝑥*) ≤ 𝐿𝑅2 2. В [79, 87] предлагается обобщение

24В нижнюю оценку во втором выражении под знаком минимума при экспоненте вместо 𝐿𝑅2 входит
𝜇𝑅2, а константа ϒ = 1 в (7). Впрочем, получить вместо фактора 𝐿𝑅2 фактор 𝜇𝑅2 можно аккуратно
проанализировав оценки, даваемые с помощью техники рестартов (см., например, [21, 87]).



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 57

классического FGM для класса гладких сильно выпуклых⧸︀задач, которое фактически поз-
воляет вместо 𝑓 (𝑥0) − 𝑓 (𝑥*) писать нижнюю оценку 𝜇𝑅2 2 ≤ 𝑓 (𝑥0) − 𝑓 (𝑥*) в том числе
для задач условной оптимизации. Заметим, что это же наблюдение справедливо для опи-
сываемых в данной работе методов (мы не стали писать 𝜇𝑅2 вместо 𝐿𝑅2 в (7) и далее для
сохранения непрерывности выписанных оценок по 𝜇, т.е. чтобы делать меньше оговорок о
переключениях с сильно выпуклого случая на выпуклый при малых значениях 𝜇).

Замечание 4. Отметим, что пока нам не известно (для произвольной прокс-структуры,
отличной от евклидовой) строгое обоснование оценок (7) ((8), (9)) с вероятностями боль-
ших отклонений для случая не ограниченного множества 𝑄. В известном нам способе по-
лучения оценок вероятностей больших уклонений (см., например, [79, 87]), к сожалению,
явно используется предположение об ограниченности множества 𝑄. С другой стороны, для
используемых в статье неускоренных методов (кроме Франк–Вульфа и кроме PGM в ва-
рианте [21], для PGM в варианте [79] все хорошо) оценки на скорость сходимости обычно
получаются в следующем виде [14, 27, 60, 61, 79, 87, 92]:

∑︁𝑁
𝜆𝑘 · (𝑓 (𝑥𝑘)− 𝑓 (𝑥*)) ≤ 𝑉 (𝑥*, 𝑥0)− 𝑉 (𝑥*, 𝑥𝑁+1)+

𝑘=0∑︁𝑁
+ 𝜆

𝑘=0 (︂𝑘 ⟨𝐺 (𝑥𝑘, 𝜉𝑘)−∇𝑓 (𝑥𝑘) , 𝑥* − 𝑥𝑘⟩+
{︁ }︁ )︂

𝑁
+ Δ̃𝑁 {𝜆𝑘}𝑁𝑘=0 , ‖𝐺 (𝑥𝑘, 𝜉𝑘)−∇𝑓 (𝑥𝑘)‖2* , 𝛿 , {𝜆𝑘} ≥ 0

𝑘=0

или, в случае ускоренных методов (к которым относится FGM и его производные), в по-
хожем, но немного более громоздком (с большим числом параметров и оценивающих по-
следовательностей). Опуская в правой части 𝑉 (𝑥*, 𝑥𝑁+1), далее оптимально подбирают
параметры метода {𝜆𝑘}, получают оценку скорости сходимости метода по функции в сред-
нем. Если считать, что ‖𝑥* − 𝑥𝑘‖ = 𝑂 (𝑅), то отсюда также получают оценки скорости
сходимости и с вероятностями больших уклонений (используется обобщение неравенства
Азума–Хефдинга для последовательности мартингал-разностей [24, 79]). В детерминиро-
ванном случае соотношение ‖𝑥* − 𝑥𝑘‖ = O(𝑅) имеет место (всегда в евклидовом случае, и
в зависимости от метода в общем случае) ввиду сходимости метода и того, что параметры
оптимально подбираются так, что слагаемые 𝑉 (𝑥*, 𝑥0) и Δ̃𝑁 одного порядка (отличаются
обычно не более чем в 10 раз):

1 ‖𝑥𝑘 − 𝑥*‖2 ≤ 𝑉 (𝑥*, 𝑥𝑘) ≤ 𝑉 (𝑥*, 𝑥0) + Δ̃𝑘−1 ≤ 𝑉 (𝑥*, 𝑥0) + Δ̃𝑁 .
2

В случае стохастического оракула, к сожалению, такие рассуждения уже не проходят.
Можно, однако, из таких соображений оценить 𝐸𝑥 [𝑉 (𝑥*, 𝑥𝑘)]. Дальше угадывается хвост

𝑘

распределения случайной величины ‖𝑥* − 𝑥𝑘‖ исходя из выписанного выше соотношения,
которое стоит понимать как равенство, т.е. хвост распределения ищется как неподвиж-
ная точка (а точнее ее оценка). Задавшись определенным доверительным уровнем 𝜎 ≥ 0
можно(︀оценить «эффективный» 𝑅: с вероятностью ≥ 1 − 𝜎 имеют место неравенства
𝑉 (𝑥*, 𝑥𝑘) ≤ 𝑅, 𝑘 = 0, ..., 𝑁)︀. В частности, для субгауссовских стохастических градиентов
𝑅 = 𝑂 𝑉 (𝑥*, 𝑥0) ln

2 (𝑁/𝜎) , а для равномерно ограниченных – 𝑅 = 𝑂 (𝑉 (𝑥*, 𝑥0) ln (𝑁/𝜎)).
Детали можно посмотреть в доказательстве теоремы 4 работы [60] (см. также [43]).
Примечательно, что все эти рассуждения в случае не ограниченного множества не тре-
буют равномерной ограниченности констант Липшица (функции, градиента) на всем [92].
Похожим образом можно получать оценки вероятностей больших уклонений в сильно вы-
пуклом случае в онлайн контексте (см. конец этого пункта). К сожалению, не все методы
обладают такими же свойствами. Например, PGM [21] (в случае детерминированного ора-
кула и не евклидовой прокс-структуры [43]) гарантирует лишь, что ‖𝑥* − 𝑥𝑘‖ = 𝑂 (𝑅),



58 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

𝑘 = 0, ..., 𝑁 , если [21] (прокс-диаметр здесь не нужен):

𝑅 = max {‖𝑥− 𝑥*‖ : 𝑥 ∈ 𝑄, 𝑓 (𝑥) ≤ 𝑓 (𝑥0)} .
Хотя PGM и является релаксационным методом (𝑓 (𝑥𝑘+1) ≤ 𝑓 (𝑥𝑘)), возможно, что 𝑅 = ∞.
Требование 𝑅 < ∞ (коэрцитивности) не является сильно обременительным. Его можно
обеспечивать за счет регуляризации задачи [97].

Полезно также иметь в виду, что за счет допускаемой неточности оракула, мож-
но погрузить задачу с гельдеровым градиентом, т.е. удовлетворяющим неравенству
‖∇𝑓 (𝑥)−∇𝑓 (𝑦)‖* ≤ 𝐿𝜈 ‖𝑥− 𝑦‖𝜈 , при некотором 𝜈 ∈ [0, 1] (в том числе и негладкую за-
дачу с ограниченной нормой разности субградиентов при 𝜈 = 0) в класс гладких задач с
неточным оракулом, характеризующимся[︂ точностью]︂ 𝛿 и [78]

1−𝜈
𝐿𝜈 (1− 𝜈) 1+𝜈

𝐿 = 𝐿𝜈 . (10)
2𝛿 (1 + 𝜈)

Заметим в этой связи, что если в предположении 1 считать

𝐸𝜉 [𝑓 (𝑦, 𝜉)]− 𝐸𝜉 [𝐹 (𝑥, 𝜉)]− ⟨𝐸𝜉 [𝐺 (𝑥, 𝜉)] , 𝑦 − 𝑥⟩ ≤ 𝐿 ‖𝑦 − 𝑥‖2 +𝑀 ‖𝑦 − 𝑥‖+ 𝛿,
2

то вместо 𝐷 в (7) стоит писать 𝑀2 +𝐷 [95, 96].
Таким образом, например, можно получить о⧸︀ценки (2), (4) из оценки (7). В частности,

метод двойственных усреднений и зеркальный спуск (см. п. 2) можно получить из PGM
в варианте [79] с неточным оракулом и 𝐿 = 𝑀2 (2𝛿). Но наряду с введенной нами искус-
ственной неточностью оракула, можно допустить, что имеется также реальная неточность
оракула. Несложно привести оценки (на базе формулы (7) и ((8), (9))), сочетающие наличие
в задаче искусственной и реальной неточности [61].

Как мы предполагали выше, множество 𝑄 должно быть достаточно простой струк-
туры, чтобы на него можно было эффективно проектироваться. Однако в приложениях
часто возникают задачи условной минимизации [2], в которых, например, есть ограниче-
ния вида 𝑔 (𝑥) ≤ 0, где 𝑔 (𝑥) – выпуклые функции [15]. «Зашивать» эти ограничения в 𝑄,
как правило, не представляется возможным ввиду вышесказанного требования о легкости
проектирования. Тем не менее на основе описанного выше можно строить (за дополнитель-
ную логарифмическую плату) двухуровневые методы (наверное, лучше говорить «методы
уровней», чтобы не было путаницы с многоуровневой оптимизацией, см. пример 5) услов-
ной оптимизации [10, 96]. При этом на каждом шаге такого метода потребуется проекти-
роваться на пересечение множества 𝑄 с некоторым полиэдром, вообще говоря, зависящим
от номера шага. Последнее обстоятельство в общем случае сужает класс задач, к которому
применимы такие многоуровневые методы до класса задач, к которым применимы методы
внутренней точки [10]. В частности, возникает довольно обременительное условие на раз-
мер пространства, в котором проходит оптимизация: 𝑛 ∼ 104−105. Все это не удивительно,
поскольку имеются нижние оценки [4] (рассматриваются аффинные ограничения в виде
ра(︀венств, аналогично могут быть рассмотрены и неравенства), показывающие, что в об-
щем√случа⧸︀е д)︀ля нахождения такого 𝑥 ∈ R𝑛, что ‖𝐴𝑥− 𝑏‖2 ≤ 𝜀 потре(︀буетс)︀я не меньше, чем
Ω 𝐿𝑥𝑅𝑥 𝜀 операций типа умножения 𝐴𝑥 (𝐿𝑥 = 𝜎⃦⃦⃦m(︀ax (𝐴)︀) = 𝜆 ⃦⃦⃦ 𝐴𝑇

max 𝐴 – максимальное
собственное значение матрицы 𝐴𝑇𝐴, 𝑅𝑥 = ‖𝑥*‖ −

𝐴𝑇 1
2 = 𝐴 𝐴𝑇 𝑏 ). Аналогичное можно

2
сказать и про седловые задачи: для отыскания такой пары (𝑥, 𝑦), что (левая часть этого
неравенства всегда неотрицательная)

max 𝑦𝑇𝐴𝑥− min 𝑦𝑇𝐴?̃? ≤ 𝜀,
𝑦∈𝑆𝑛(1) ?̃?∈𝑆𝑛(1)

потребуется не меньше, чем Ω (Λ/𝜀) (Λ – максимальный по модулю элемент матрицы 𝐴)
операций типа умножения 𝐴𝑥 и 𝑦𝑇𝐴. Заметим, что обе выписанные нижние оценки спра-
ведливы при условии, что число итераций (операций типа умножения 𝐴𝑥) 𝑘 ≤ 𝑛. Как



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 59

следствие, в общем случае даже для гладкой детерминированной сильно выпуклой по-
становки при наличии всего лишь аффинных ограничений 𝐴𝑥 = 𝑏 нельзя надеяться на
быстрое решение. Тем не менее некоторые дополнительные предположения в ряде случаев
позволяют ускорить решение таких задач (см., например, [55, 97]).

Замечание 5 (см. также [92]). Задача поиска такого 𝑥*, что 𝐴𝑥* = 𝑏 сводится к
задаче выпуклой гладкой оптимизации

𝑓 (𝑥) = ‖𝐴𝑥− 𝑏‖22 → min .
𝑥

Нижняя оценка для скорости(︀решен⧸︀ия)︀такой задачи [4] (см. также формулу (7) с(︀𝛿√= 𝐷 =⧸︀0)︀,
𝑝 = 1) имеет вид: 𝑓 (𝑥𝑘) ≥ Ω 𝐿𝑥𝑅

2 𝑘2𝑥 . Откуда следует, что только при 𝑘 ≥ Ω 𝐿𝑥𝑅𝑥 𝜀
можно гарантировать выполнение неравенства 𝑓 (𝑥 2

𝑘) ≤ 𝜀 , т.е. ‖𝐴𝑥𝑘 − 𝑏‖2 ≤ 𝜀. Заметим,
что эта нижняя оценка для специальных матриц может быть улучшена. Причем речь идет
не о недавних результатах D. Spielman’а [98] (премия Неванлины 2010 года), а о более
простой ситуации. Вернемся к за(︂даче поиска вектор(︂а Pa)︂geRank (примеры 1, 2), которую
мы перепишем как (︀ )︀ )︂

𝑃 𝑇 − 𝐼 0
𝐴𝑥 = 𝑥 = = 𝑏,

1 . . . . . . 1 1

где 𝐼– единичная матрица. По теореме Фробениуса–Перрона [99] решение такой системы
с неразложимой матрицей 𝑃 единственно и положительно 𝑥 > 0. Сведем решение этой
системы уравнений к вырожденной задаче выпуклой оптимизации:

1 ‖𝑥‖2 → min .
2 2

𝐴𝑥=𝑏

Построим двойственную к ней задач{︂у [9]: }︂
1

min ‖𝑥‖2 1
2{︂= minmax ‖𝑥‖22 +}︂⟨𝑏−𝐴𝑥,{︂𝜆⟩ =

𝐴𝑥=𝑏 2 𝑥 𝜆 2
1 1 ⃦⃦ ⃦⃦ }︂

= maxmin ‖𝑥‖2 𝑏−𝐴𝑥, 𝜆⟩ = max ⟨𝑏, 𝜆⟩ − 𝐴𝑇 2
𝜆 .

𝜆 𝑥 2 2 + ⟨
𝜆 2 2

Поскольку система 𝐴𝑥 = 𝑏 совместна, то по теореме Фредгольма не существует такого 𝜆,
что 𝐴𝑇𝜆 = 0 и ⟨𝑏, 𝜆⟩ > 0, следовательно, двойственная задача имеет конечное решение (т.е.
существует ограниченное решение двойственно задачи 𝜆*). Зная решение 𝜆* двойственной
задачи ⃦⃦ ⃦⃦

⟨ 2
𝑏, 𝜆⟩ − 1

𝐴𝑇𝜆 → max,
2 2 𝜆

можно восстановить решение прямой задачи (из условия оптимальности по 𝑥): 𝑥 (𝜆) = 𝐴𝑇𝜆.
Однако важно здесь то, что FGM [10] для этой двойственной задачи дает возможность
попутно получать следующую оценку на норму (︂этого гр)︂адиента [92]:

‖𝐴𝑥𝑘 −
𝐿𝑦𝑅𝑦

𝑏‖2 = 𝑂 ,
𝑘2

где 𝑥𝑘 есть известная выпуклая комбинац(︀ия )︀
{𝑥 (𝜆 𝑇

𝑖)}𝑘𝑖=1 , 𝐿𝑦 = 𝜎max 𝐴 = 𝜎max (𝐴) , 𝑅
*

𝑦 = ‖𝜆 ‖2 ,

где можно считать, что 𝜆* – решение двойственной задачи с наименьш(︀√ей евкл⧸︀ид)︀овой нор-
мой. Кажется, что это противоречит нижней оценке ‖𝐴𝑥𝑘 − 𝑏‖2 ≥ Ω 𝐿𝑥𝑅𝑥 𝑘 . Однако
важно напомнить [4], что эта нижняя оценка установлена для всех 𝑘 ≤ 𝑛 (𝑛 – раз-
мерность вектора 𝑥), и она будет улучшена в результате описанной процедуры, толь-
ко если дополнит√ельно предположить, что матрица 𝐴 удовлетворяет следующему усло-
вию: 𝐿𝑦𝑅𝑦 ≪ 𝑛 𝐿𝑥𝑅𝑥, что сужает класс, на котором была получена нижняя оценка



60(︀ Инф

√ ⧸︀о)︀рматика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1
√

Ω 𝐿𝑥𝑅𝑥 𝑘 . В типичных ситуациях можно ожидать, что 𝑅𝑦 ≫ 𝑅𝑥 (𝑅𝑥 ≤ 2). Это об-
стоятельство мешает выполнению требуемого условия.

Пример 4. Если имеется дополнительная информация о структуре седловой задачи, то
можно её использовать для ускорения [14, 100]. Более того, многие современные постановки
задач (негладкой) выпуклой оптимизации (в частности, связанные с compressed sensing и 𝑙1-
оптимизацией) в пространствах огромных размеров специально стараются представить сед-
ловым образом с целью получения эффективного решения (см. работы А.С. Немировского,
А. Б. Юдицкого [31, 101, 102]). Далее будет разобран один простой пример (немного обоб-
щающий результаты [78, 79], см. также [92]), демонстрирующий возможности градиент-
ных методов с неточным оракулом в седловом контексте. Рассматривается седловая задача
(𝑥 ∈ R𝑛,𝑦 ∈ R𝑚):

𝑓 (𝑥) = max {𝐺 (𝑦) + ⟨𝐵𝑦, 𝑥⟩} → min ,
‖𝑦‖2≤𝑅𝑦 ‖𝑥‖2≤𝑅𝑥

где функция 𝐺 (𝑦) – сильно вогнутая с константой 𝜅 относительно 2-нормы и константой
Липшица градиента 𝐿𝐺 (также в 2-норме). Тогда функция 𝑓 (𝑥) будет гладкой, с констан-
той Липшица градиента в 2-норме 𝐿𝑓 =(︁𝜎√︁max (𝐵) /𝜅. Ка⧸︀залос)︁ь бы, что мы можем решить
задачу минимизации функции 𝑓 (𝑥) за 𝑂 𝜎max (𝐵)𝑅2

𝑥 (𝜅𝜀) итераций, где 𝜀 – желаемая
точность по функции. Но это возможно, только если мы можем абсолютно точно находить
∇𝑓 (𝑥) = 𝐵𝑦* (𝑥), где 𝑦* (𝑥) – решение вспомогательной задачи максимизации по 𝑦 при
заданном 𝑥. В действительности, мы можем(︁решать эту задачу (при различных 𝑥) лишь
приближенно. Если мы решаем вспомогатель√︀ную задач(︀у быст⧸︀ры)︀)︁м градиентным методом
[14] с точностью 𝛿/2 (на это потребуется 𝑂 𝐿𝐺/𝜅 ln 𝐿𝐺𝑅

2
𝑦 𝛿 итераций), то выдава-

емая по формуле ∇𝑓 (𝑥)(︁=√︁𝐵⧸︀𝑦𝛿/2 (𝑥) а)︁ппроксимация градиента будет (𝛿, 2𝐿𝑓 , 0)-оракулом
[78, 79]. Выбирая 𝛿 = 𝑂 𝜀 (︃𝜀√︂(𝐿 2

𝑓𝑅𝑥) (см. форм(︃улу (9) при)︃𝑝)︃= 1), получим после

𝐿𝐺𝜎max (𝐵)𝑅2
𝑥 𝐿𝑓𝐿𝐺𝑅

2
𝑥𝑅

2
𝑦

𝑂 ln
𝜅2𝜀 𝜀

итераций (на итерациях производится умножение матрицы 𝐵 на вектор/строчку и вы-
числение градиента 𝐺 (𝑦)) 𝜀-решение задачи минимизации 𝑓 (𝑥). Отметим, что если не
использовать сильную вогнутость функции 𝐺 (𝑦), то для получения пары (𝑥𝑁 , 𝑦𝑁 ), удо-
влетворяющей неравенству

max {𝐺 (𝑦) + ⟨𝐵𝑦, 𝑥𝑁 ⟩} − min {𝐺 (𝑦𝑁 ) + ⟨𝐵𝑦𝑁 , 𝑥⟩} ≤ 𝜀,

(︀‖𝑦‖2≤{︀𝑅𝑦 }︀‖⧸︀𝑥‖2)︀≤𝑅𝑥

потребуется Ω max 𝐿 2
𝐺𝑅𝑦, 𝜎max (𝐵)𝑅𝑥𝑅𝑦 𝜀 итераций (см., например, [4, 9, 11]).

Интересно отдельно разобра∑︀ть ситуацию, когда вместо множества ‖𝑦‖2 ≤ 𝑅𝑦 фигуриру-
ет симплекс 𝑆𝑚 (𝑅𝑦), 𝐺 (𝑦) = − 𝑚

𝑘=1 𝑦𝑘 ln (𝑦𝑘/𝑅𝑦) – сильно вогнутая в 1-норме с константой
𝜅 = 1 функция и 𝑅𝑥 = ∞ (энтропийно-линейное программирование [97]). В этом случае
мы не можем обеспечить даже равномерной ограниченности(︀градиен

𝜀−
(︀та ф)︀у)︀нкции 𝐺 (𝑦). Тем

не менее также можно рассчитывать [97] на зависимость 𝑂 1/2 ln 𝜀−1 числа итераций
от точности 𝜀 для критерия:

max min {𝐺 (𝑦) + ⟨𝐵𝑦, 𝑥⟩} −min {𝐺 (𝑦𝑁 ) + ⟨𝐵𝑦𝑁 , 𝑥⟩} ≤ 𝜀.
𝑦∈𝑆𝑚(𝑅𝑦) 𝑥 𝑥

При этом вместо энтропии в качестве функции 𝐺 (𝑦) можно брать любую сильно вогну-
тую в 1-норме функцию, для которой решени(︀е з(︀адач)︀и)︀максимизации (вычисление 𝑓 (𝑥) с
точностью 𝜀) может быть осуществлено за 𝑂 ln 𝜀−1 . В примере с энтропией, для 𝑓 (𝑥)
есть просто явная формула. Точнее, важно то, что есть явная формула25 для оптимального

25Сложность формулы оценивается числом ненулевых элементов в матрице 𝐵. При этом считаем, что
градиент 𝐺 (𝑦) рассчитывается быстрее, чем занимает умножение матрицы 𝐵 на столбец/строку.



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 61

решения 𝑦* (𝑥).26 К сожалению, имеется проблема вхождения в оценку необходимого числа
итераций неизвестного размера решения 𝑥* задачи минимизации 𝑓 (𝑥). Эта проблема ре-
шаема [97]. В частн(︀ости, в случае, когда 𝐺 (𝑦) имеет ограниченную вариацию на множестве
𝑆𝑚 (𝑅𝑦) (для энтропии эт(︀а вар)︀иация равна 𝑅𝑦 ln𝑚), можно предложить метод, с оценкой
числа итераций 𝑂 𝜀−

)︀
1 ln 𝜀−1 . В эту оценку уже никак не входит неизвестный размер

решения 𝑥*, который может оказаться большим [97]. Далее мы еще вернемся к вопросу
о том, как действовать, в случае, когда тот или иной параметр задачи (в данном случае
размер решения) априорно не известен.

Отметим, что сильной вогнутости можно добиться и
дит к оптимальн(︀ искусственно [77], глава 3 [79], [92,

97]. Подход отмеченных работ приво ым для такого класса задач оцен-
кам (с точностью до логарифмического фактора27 ln 𝜀−

)︀
1 ) и позволяет, на самом деле,

контролировать точность решения одновременно по 𝑥 и по 𝑦 без использования прямо-
двойственности в классическом варианте (см. ниже), что может быть полезным в опре-
деленных ситуациях [55]. Здесь под оптимальными методами мы имеем в виду методы с
проксимальным оракулом. Однако в ряде задач оптимизации огромных размеров оказы-
вается эффективнее использовать линейный минимизационный оракул [103], пришедший
из метода Франк–Вульфа (см., например, п. 3.3 [11]). Грубо говоря, суть подхода в том,
что сначала вычисляется не 𝑓 (𝑥) согласно модели, описанной в примере 4, а в седловом
представлении задачи меняется порядок взятия максимума и минимума и вычисляется с
помощью линейного минимизационного оракула сначала минимум по 𝑥. Причем это не
обязательно делать точно (см. п. 5 § 1 главы 5 [2]). Получающаяся задача максимиза-
ции по 𝑦 уже не будет гладкой, поэтому с учетом сильной вогнутости 𝐺 (𝑦) здесь(︀мож)︀-
но рассчитывать только на зависимость числа итераций от желаемой точности 𝑂 𝜀−1 .
Получается вроде как хуже, чем раньше. Но тут надо учитывать, как входят размерности
𝑛 и 𝑚, которые могут быть огромными в приложениях, см. п. 3.3 [11], [59, 60, 61, 103].
Удивительным образом, в сложность внутренней задачи при таком подходе (минимизации
по 𝑥) при определенной структуре (как правило, связанной с ограничениями симплексного
типа и матрицей 𝐵, имеющей комбинаторую [103] или сетевую природу [60]) может не вхо-
дить размерность вектора 𝑥 (т.е. 𝑛), что позволяет решать задачи колоссальных размеров
по 𝑛.

Пример 4 был приведен, прежде всего, потому, что он поясняет одно интересное и доста-
точно современное направление в численных методах выпуклой оптимизации (см., напри-
мер, [61, 62, 92, 96, 101, 102]). Грубо говоря, это направление можно охарактеризовать, как
попытку ввести оптимальную «алгебру» над алгоритмами выпуклой оптимизации. А имен-
но, если требуется оптимизировать функционал (искать седловую точку), который облада-
ет разными свойствами (гладкости, сильной выпуклости, быстроты вычислимости частных
производных и т.п.) по разным группам переменных (такие задачи часто в последнее время
возникают в разных приложениях, в частности, в транспортных и экономических [58, 60,
61, 62, 104–107]) и(или) сам представляет собой некоторую суперпозицию других функ-
ционалов (с разными свойствами; наиболее популярен случай суммы двух функционалов
[9, 14, 43, 55, 59, 63, 96, 101, 102]), то хотелось бы получить такую декомпозицию исход-
ной задачи, чтобы правильное сочетание (правильное чередование с правильными частота-
ми) оптимальных методов для получившихся отдельных подзадач позволило бы получить

26Отметим, что если 𝐺 (𝑦) – сепарабель(︀ная)︀в)︀огнутая функция (но не обязательно сильно вогнутая) и вме-
сто ограничения ‖𝑦‖2 ≤ 𝑅𝑦 задано сепарабельное ограничение (например, ‖𝑦‖∞ ≤ 𝑅𝑦), то 𝜀-приближенный
поиск 𝑦* (︀

(𝑥) можно осуществить за 𝑂 ln 𝜀−1 умножений матрицы 𝐵 на столбец, решая соответствующие
одномерные задачи. Не много более громоздкие рассуждения [55(︀] п(︀озво)︀л)︀яют и при наличии ограничения
‖𝑦‖2 ≤ 𝑅𝑦 осуществить 𝜀-приближенный поиск 𝑦* (𝑥) также за 𝑂 ln 𝜀−1 умножений матрицы 𝐵 на стол-
бец. К сожалению, отсутствие сильной вогнутости не позволяет использовать в том же виде концепцию
(𝛿, 𝐿, 𝜇)-ор(︀акул)︀а для внешней задачи, однако можно п(︀ри этом использовать концепцию 𝛿-субградиента для
внешней задачи [2]. Это приводит лишь к оценкам 𝑂 𝜀−

)︀
2 , которые уже не будут оптимальными (улучша-

емы до 𝑂 𝜀−1 ).
27Ниже мы обсудим, как можно избавиться от этого логарифмического фактора для задач с явной фор-

мулой для 𝑦* (𝑥), например, для задач энтропийно-линейного программирования [55, 97].



62 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

оптимальный метод для исходной задачи. В ряде интересных случаев такое оказывается
возможным (с оговоркой, что оптимальность понимается с точностью до логарифмическо-
го фактора). По-видимому, новым в этом направлении является наблюдение, отмеченное в
примере 4 (см. также [61, 62, 92]), что при определенных условиях идея оптимального соче-
тания различных методов для решения одной сложной по структуре задачи оптимизации,
может быть реализована на основе концепции неточного оракула.

Другой способ борьбы с дополнительными ограничениями типа равенств или нера-
венств в задачах выпуклой оптимизации базируется на прямо-двойственной структуре [27]
всех обсуждаемых методов (поскольку они строят модель функции [14]). Это означает, что
ограничения вносятся во вспомогательную задачу оптимизации, возникающую на каждом
шаге метода и отвечающую за проектирование. В результате на каждом шаге решается
более сложная задача. Тем не менее если такие вспомогательные задачи можно эффектив-
но решать (что в общем случае также наталкивается на сложности, описанные ранее) с
помощью метода множителей Лагранжа (найдя и сами множители), или когда у исходной
задачи есть модель (см. пример 4 и [18, 55, 59–62, 77, 92, 97, 110]), то тогда описанные
методы позволяют не только эффективно решать исходную задачу оптимизации с ограни-
чениями, но и находить попутно (по явно выписываемым формулам) решение двойственной
задачи.

Основная идея работы [27] состоит в том (здесь мы ограничимся рассмотрением детер-
минированного случая с точным оракулом, выдающим градиент; в стохастическом случае
с неточным оракулом см., например, [55] и лемму 7.7 [79]), что метод генерирует в прямом
пространстве на итерациях такую последовательность {𝑥𝑘}28, что зазор двойственности
(duality gap) Δ(𝜆, 𝑥;𝑁) удовлетворяе{︃т условию }︃

𝑁
1 ∑︁

Δ(𝜆, 𝑥;𝑁) = max 𝜆𝑘 ⟨∇𝑓 (𝑥𝑘) , 𝑥𝑘 − 𝑢⟩ ≤ 𝜀,

∑︀ 𝑢∈𝑄 𝑆𝑁
𝑘=0

где 𝑆𝑁 = 𝑁
𝑘=0 𝜆𝑘, 𝜆𝑘 ≥ 0, поэт(︃ому )︃

𝑁
1 ∑︁

𝑓 𝜆𝑘𝑥𝑘 −min 𝑓 (𝑥) ≤ 𝜀.
𝑆𝑁 𝑥∈𝑄

𝑘=0

Это с(︃ледуе∑︁т из вык)︃ладки
𝑁 𝑁

1 1 ∑︁ ∑︁𝑁
𝑓 𝜆𝑘𝑥𝑘 − 𝑓 (𝑢) ≤ 𝜆𝑘 · (𝑓 (𝑥𝑘)− 𝑓 (𝑢)) ≤ 1

𝜆𝑘 ⟨∇𝑓 (𝑥𝑘) , 𝑥𝑘 − 𝑢⟩ .
𝑆𝑁 𝑆𝑁 𝑆𝑁

𝑘=0 𝑘=0 𝑘=0

Аналогичную точность (для двойственной задачи) дает следующая аппроксимация реше-
ния двойственной задачи:

𝑁
1 ∑︁

𝑦 = 𝜆𝑘𝑦𝑘.
𝑆𝑁

𝑘=0

Это сразу следует из того, что зазор двойственности оценивает сверху разность между по-
лучившимися значениями целевой функции в прямой задаче и двойственной [27], которую
мы будем называть двойственным зазором. Эта разность всегда неотрицательна, и на точ-
ных решениях прямой и двойственной задачи (и только на них) равна нулю. Заметим, что
контроль онлайн-зазора двойственност{︃и }︃

𝑁
1 ∑︁

Δ(𝜆, 𝑥;𝑁) = max 𝜆𝑘 ⟨∇𝑓𝑘 (𝑥𝑘) , 𝑥𝑘 − 𝑢⟩
𝑢∈𝑄 𝑆𝑁

𝑘=0

28В двойственном пространстве при этом генерируется последовательность соответствующих множите-
лей Лагранжа {𝑦𝑘} [27] или, в случае наличия модели у исходной прямой задачи (см. пример 4), после-
довательность {𝑦𝑘} генерируется по явным или расчетным формулам {𝑦𝑘 = 𝑦 (𝑥𝑘)} согласно этой модели
[18, 55, 59, 92, 110]. Такой подход также позволяет убрать логарифмический фактор в задачах энтропийно-
линейного программирования [55, 97] и аналогичных задачах, см. п. 5.2 [110] и [43, 55, 92].



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 63

позволяет в случае, когда удается выбрать 𝜆𝑘 ≡ 1, получать оценки регрета (псевдоре-
грета в стохастическом случае) в задачах онлайн-оптимизации (см. [32, 45] и конец этого
пункта). К сожалению, ограничение 𝜆𝑘 ≡ 1 существенно сужает класс методов. Скажем,
для рассматриваемых в этом пункте быстрых градиентных методов 𝜆𝑘 ∼ 𝑘𝑝. Кроме того,
даже если в онлайн-постановке допустить взвешивание с различными весами, все равно
требуется, чтобы способ получения оценки на зазор двойственности допускал бы обобще-
ние на онлайн-постановки. Быстрый градиентный метод, например, этого не допускает, что
несложно усмотреть из оценок работы [21].

Описанная выше конструкция, основанная на оценке зазора двойственности, работает в
случае ограниченного множества 𝑄. В случае неограниченного 𝑄 (это типичная ситуация,
когда необходимо решать двойственную задачу, по решению которой требуется восстанав-
ливать решение прямой задачи) можно искусственно компактифицировать 𝑄 [55, 60, 61,
110]. Однако в большинстве случаев такая компактификация не позволяет очевидным об-
разом оценивать настоящий (не обрезанный) двойственный зазор в исходной задаче, что
часто представляется важным ввиду наличия простых явных формул для этого настоящего
зазора, и возможности использования контроля зазора двойственности в качестве критерия
останова метода. Несмотря на отмеченную теоретическую проблему, на практике проблема
оказывается решаемой [55, 59, 60].

Более общий способ оценки разности между получившимися значениями целевых функ-
ций в прямой задаче и двойственной базируется на контроле сертификата точности [110,
111] (accuracy certificate), в который наряду с градиентами функционала входят градиен-
ты нарушенных ограничений или в общем случае вектора нормалей к гиперплоскостям,
отделяющим 𝑥𝑘 от множества 𝑄 (в ряде постановок «градиенты» стоит заменить на «суб-
градиенты»). Векторы двойственных множителей формируются из соответствующих (сер-
тификату точности) взвешенных сумм векторов нормалей отделяющих гиперплоскостей.
Собственно, такая интерпретация двойственных множителей следует из способа обоснова-
ния принципа множителей Лагранжа на основе следствия теоремы Хана–Банаха (теоремы
об отделимости) [112]. Причем в работе [111] за счет слейтеровской релаксации ограни-
чений (допущения возможности нарушения ограничений на 𝜀 [9, 97]) получаются оценки
скорости сходимости, не зависящие от размера двойственного решения, который может
быть большим.

Во многих (транспортно-) экономических приложениях при поиске равновесных кон-
фигураций требуется решать пару задач (прямую и двойственную), см., например, [58–62,
97, 104–109]. Причем интересны решения обеих задач (решения этих задач имеют содержа-
тельную интерпретацию и используются при принятии решений/управлении). Если у этой
пары задач, на которую можно смотреть, как на одну седловую задачу, есть определенная
структура (проявляющаяся, например, в сильной выпуклости функционала по части пере-
менных, наличии эффективно вычислимого линейного минимизационного оракула и т.п.),
то описанный выше формализм позволяет развить идею примера 4 таким образом, чтобы
одновременно (без дополнительных затрат) получать решения обеих задач. Даже в слу-
чае огромного размера одной из этих задач можно надеяться (при эффективном линейном
минимизационном оракуле), что эта размерность не войдет в сложность поиска решения
прямой и двойственной задачи [59, 60, 103].

В действительности, выбранный в данной статье класс проекционных методов с постро-
ением модели функции далеко не единственный возможный способ строить прямодвой-
ственные методы. Скажем, уже упоминавшиеся методы условного градиента также явля-
ются прямодвойственными [17, 18]. Еще более удивительным может показаться, что пря-
модвойственная интерпретация есть, например, у метода эллипсоидов [110]. Более того, в
ряде ситуаций мы можем за линейное время (с геометрической скоростью сходимости) на-
ходить одновременно решение прямой и двойственной задачи. Причем речь идет не только о
конструкциях типа [74], базирующихся на принципе (см. также замечание 6): сопряженная
функция к выпуклой функции с липшицевым градиентом – сильно выпуклая, и обратно,



64 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

сопряженная к сильно выпуклой функции – выпуклая функция с липшицевым градиентом;
но и о более общем контексте [43, 55, 74, 92, 110].

Возвращаясь к сказанному выше в связи с оценками (7) – (10) интересно заметить,
что если множество 𝑄 ⊂ R𝑛 есть шар 𝐵𝑛

𝑞 (𝑅) радиуса 𝑅 в 𝑞-норме29, то нижние оценки
(для случая 𝐷 = 𝛿 = 0) на точность (по функции), которую можно получить после 𝑁 ≤ 𝑛
итераций, имеют вид [113] (считаем, что30 ‖∇𝑓 (𝑥)−∇𝑓 (𝑦)‖𝑞′ ≤ 𝐿𝜈 ‖𝑥− 𝑦‖𝜈𝑞 , 1/𝑞+1/𝑞′ = 1,
𝜈 ∈ (0, 1]): (︂ )︂

1 𝐿𝜈𝑅
1+𝜈

Ω
min {𝑞, ln𝑛}𝜈

(2 ≤ 𝑞 ≤ ∞),

(︂ 𝑁𝜈+(𝜈+1)/𝑞)︂
1 𝐿 𝜈

𝜈𝑅
1+

Ω
ln𝜈

(1 ≤ 𝑞 < 2).
(𝑁 + 1)𝑁𝜈+(𝜈+1)/2

Приведенный результат хорошо соответствует тому, что написано в замечании 2
(см. также [114]).

Для 𝑞 = ∞ и 𝜈 = 1 (гладкий сл(︀учай)⧸︀пр)︀иведенная оценка с точностью до логарифмиче-
ского фактора будет иметь вид Ω 𝐿𝑅2 𝑁 . Эта оценка достигается, например, на методе
условного градиента Франк–Вульфа [17, 115]31. Исходя из только что написанного и тезиса
о неулучшаемости оценок (7) ((8), (9)) (при 𝐷 = 𝛿 = 𝜇 = 0, 𝑝 = 1), может возникнуть
ощущение противоречия. Это ощущение дополнительно усиливается примером 2 из п. 2.
Действительно, исходя из этого примера, может сложиться ощущение, что проблема вы-
бора прокс-структуры в задаче не очень актуальна, поскольку можно исходить просто из
самой нормы. И это действительно так, если мы ограничиваемся не ускоре(︀нными⧸︀гр)︀адиент-
ными методами (PGM, метод Франк–Вульфа), которые схо(︀дятся как 𝑂 𝐿𝑞𝑅2

𝑞 𝑁 (здесь
𝑅𝑞 = 𝑅 – диаметр множества 𝑄, посчитанный в 𝑞-норме, в наш⧸︀ем с)︀лучае 𝑞 = ∞). Если
же мы хотим ускориться и достичь оптимальной оценки 𝑂 𝐿𝑅2 𝑁2 , то уже необходимо
существенно использовать прокс-функцию 𝑑 (𝑥) ≥ 0 со свойством сильной выпуклости от-
носительно выбранной нормы и с константой сильной выпуклости 𝛼 ≥ 1 [14]. Скажем (в
связи с примером 2), квадрат 1-нормы не есть сильно выпуклая функция относительно 1-
нормы, т.е. 𝑑 (𝑥) = ‖𝑥‖21 не может быть прокс-функцией при выборе 1-нормы для симплекса.
В классе удовлетворяющих условию 1-сильной выпуклости прокс-функций (относительно
выбранной нормы) подбирае(︀тся та⧸︀кая)︀, которая минимизирует 𝑅2 := max 𝑑 (𝑥). Именно это

𝑥∈𝑄
𝑅2 входит в оценку FGM 𝑂 𝐿𝑅2 𝑁2 . И как уже отмечалось (см. п. 2), для 𝑄 = 𝐵𝑛

∞ (𝑅)

29Если о выпуклом замкнутом множестве 𝑄 известно только то, что оно содержит 𝐵𝑛
𝑞 (𝑅), то все сказанное

далее также остается в силе.
30В случае дос⟨︀таточной гл⟩︀адкости функции 𝑓 (𝑥) можно выписать следующее представление для кон-

станты Липшица градиента (верхний индекс 𝑞 соответствует выбору нормы в прямом пространстве):
𝐿𝑞 = max ℎ,∇2𝑓 (𝑥)ℎ . В частности, 𝐿1 ≤ 𝐿2 ≤ 𝑛𝐿1, 𝐿2 ≤ 𝐿∞ ≤ 𝑛𝐿2. Эти формулы вместе со

𝑥∈𝑄,‖ℎ‖𝑞≤1

сказанным ранее относите⧸︀льно тог⧸︀о, как может меняться 𝑀 – обычная константа Липшица 𝑓 (𝑥) – при
изменении нормы в прямом пространстве, поясняют, почему в «устойчивые сочетания» эти константы вхо-
дят таким образом: 𝑀2𝑅2 𝜀2, 𝐿𝑅2 𝜀. Если ввести «физические размерности», скажем, считать⧸︀, что 𝑓 (𝑥)
– это рубли (руб), а 𝑥 – это килограммы (кг), то 𝜀 [ руб ], 𝑅 [ кг ], 𝑀 [ руб/кг ], 𝐿 [ руб/кг2 ]. Поскольк⧸︀у
число итераций 𝑁 должно быть безразмерной величиной, то возникновение агрегатов 𝑀2𝑅2 𝜀2, 𝐿𝑅2 𝜀
вполне закономерно. Аналогичные рассуждения можно провести и для оценок в сильно выпуклом слу-
чае. Все(︁это п⧸︀риводит к довольно интересным следствиям [92]. Например, что шаг метода в негладком
случае ℎ ∼ 𝜀 𝑀2)︁, в гладком случае ℎ определяется из соотношения вида (𝑊 (),?̃? () – какие-то функ-

ℎ𝑀2
ции) 𝑊 ,ℎ𝐿 =(︁1. В стохасти)︁ческом случае (вместо градиента получаем стохастический градиент с

𝜀

дисперсией 𝜎2) из ?̃? ℎ𝑀2
, ℎ𝐿, ℎ 𝜎 = 1.

𝜀 𝑅
31Отметим также, что этот метод допускает обобщение на случай неточного оракула, и неулучшаемость

оценок может быть проинтерпретирована с точки зрения сохранения свойства разреженности решения [17].
Это неудивительно, поскольку аналогичный метод (с линейным минимизационным оракулом, см. пример 4)
с аналогичными оценками скорости можно получить (см. п. 5.5.1 [9], [57]) из композитного варианта FGM
в концепции неточного оракула (суть метода в том, что в композитном варианте FGM на каждой итерации
решается задача, в которой коэффициент при прокс-слагаемом равен нулю, т.е. оно просто отсутствует).



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 65

имеет место следующая оценка на прокс-диам(︀етр 𝑅⧸︀2 :=)︀ max 𝑑 (𝑥) =
𝑥∈ (︀𝑅2Ω (⧸︀𝑛). О)︀тсюда, с уче-

𝑄

том того, что 𝑁 ≤ 𝑛, получаем, что оценка 𝑂 𝐿𝑅2 𝑁 и оценка 𝑂 𝐿𝑅2𝑛 𝑁2 , приводят, в
общем-то, к одному результату, но в случае использования FGM требуется дополнительно
искать оптимальную прокс-структуру. Только в таком случае будет совпадение результа-
тов. Более того, также как и в замечании 2, здесь хорошо видно, что при 𝑞 ≥ 2 можно
ограничиться рассмотрением только евклидовой прокс-структуры для FGM и евклидовой
нормы для метода Франк–(︀Вульфа⧸︀. В )︀частности, для 𝑄 = 𝐵𝑛

∞ (𝑅), действуя так, мы по-
лучим для FGM оценку 𝑂 (︀ (︀ ⧸︀ )︀

𝐿2𝑅2𝑛 𝑁2 вместо ранее полученн⧸︀ой оценки 𝑂 𝐿∞𝑅2𝑛 𝑁2 ,
соответствующей при 𝑁 ≤ 𝑛 неулучшаемой оценке 𝑂 𝐿∞ )︀

𝑅2 𝑁 (здесь мы проставили
верхние индексы у 𝐿, поскольку они различаются). Дальше можно написать все то же по
поводу неулучшаемости оценок, что и в конце замечания 2.

Отметим также, что параметры 𝑅 и 𝜇 могут быть не известны априорно или проце-
дуры их оценивания приводят к слишком (соответственно) завышенным и заниженным
результатам. Это может быть проблемой, поскольку в ряде случаев знание этих и других
параметров требуется методу для расчета величин шагов и условий остановки. Из этой си-
туации можно выйти за логарифмическое (по этим параметрам) число рестартов метода.
Стартуя, скажем, с 𝑅 = 1 и делая число шагов, вычисленное из оценки скорости сходимости
при выбранном 𝑅, мы проверяем, выполняется ли для вектора, выдаваемого алгоритмом,
условие 𝜀-близости по функции (при условии, что мы можем сделать такую проверку). Если
условие 𝜀-близости не выполняется, то полагаем 𝑅 := 2𝑅 и т.д. Все эти перезапуски увели-
чат общее число обращений к оракулу лишь в 𝑂 (1) раз [14, 31, 38]32. Аналогичное можно
сказать про33 𝐿, 𝑀 , 𝜇 и 𝐷. Однако, если убрать стохастичность, тогда 𝐿, 𝑀 можно не толь-
ко эффективнее адаптивно подбирать (аналогично правилу Армихо [16] в независимости
от того, можем ли мы сделать проверку условия 𝜀-близости значения функции в текущей
точке к оптимальному) по ходу самих итераций (увеличив в среднем число обращений к
оракулу не более чем в 4 раза), но и в некотором смысле оптимально самонастраиваться
(используя формулу (10)) на гладкость функционала на текущем участке пребывания ме-
тода [116]. Это означает, что в детерминированном случае без учета сильной выпуклости
функционала существует универсальный метод, работающий по оценкам (8) с 𝐿, рассчи-
танной по формуле (10) (в которой 𝛿 берется из (9)), и оптимальным в смысле скорости
сходимости выбором параметра 𝜈 ∈ [0, 1]. Причем выбор 𝜈 осуществляется не нами заранее
исходя из знания всех констант и минимизации выписанных оценок, а самим алгоритмом
(здесь выбрано 𝑝 = 1): (︃ )︃ 2

3+5𝜈
2 1 3

2 𝐿 1 𝜈 +
𝜈𝑅

+ 𝜈

𝑁 (𝜀) = inf .
𝜈∈[0,1] 𝜀

Это соответствует (с точностью до логарифмического фактора) нижним оценкам [110], вы-
писанным выше для случая 𝑞 ∈ [1, 2]. Отметим, что здесь при определении 𝑅 используется
соответствующая прокс-функция, см. замечание 2. К сожалению, пока не очень понятно,

32В свою очередь можно поиграть и на этом 𝑂 (1), стараясь его минимизировать. Для этого шаг, который
мы для простоты положили равным 2, подбирают оптимально исходя из того, с каким показателем степени
входит неизвестный (прогоняемый) параметр в оценку числа итераций [56, 97].

33Впрочем, в детерминированных постановках мы можем явно наблюдать за последовательностью выда-
ваемых оракулом субградиентов и отслеживать условие на норму субградиентов. Как только наше предпо-
ложение нарушилось (при этом мы не успели сделать предписанное текущему 𝑀 число шагов), мы увели-
чиваем 𝑀 в два раза и перезапускаем весь процесс с новым значением 𝑀 . Число таких перезапусков будет
не более чем логарифмическим от истинного значения 𝑀 . Все эти рассуждения с небольшими оговорками
(типа равномерной п.н. ограниченности стохастического субградиента) переносятся и на стохастические по-
становки, в которых наблюдается стохастический субградиент. Для определенного класса задач, в которые
неизвестные параметры входят только в критерий останова, но не в сам метод (к таким задачам, например,
относится задача поиска равновесия в модели Бэкмнана методом Франк–Вульфа и неизвестной константе
𝐿) можно обходиться и без перезапусков [60]. Заметим также, что у ряда популярных методов (например,
метода зеркального спуска) есть варианты, в которые входит не оценка супремума нормы субградиента
(или градиента), а норма субградиента на текущей итерации, которая известна [9, 27, 60].



66 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

можно ли что-то похожее сделать с параметром 𝜇 и с введенным нами в начале этого
пункта параметром метода 𝑝 ∈ [0, 1] и можно ли идеи универсальности (самонастраиваемо-
сти) распространить на задачи стохастической оптимизации. Обзор других работ на тему
самонастройки алгоритмов в гладком детерминированном случае имеется в [20].

Приведенную оценку можно обобщить, если дополнительно известно, что функция 𝑓 (𝑥)
𝜇-сильно выпукла. Можно дополнительно к искусственно введенной игре на неточности
оракула допустить, что имеет место и настоящая неточность. В этом случае также можно
выписать соответствующие оценки [61]. Не играя на выборе 𝜈 ∈ [0, 1], можно распростра-
нить все, что описано выше в этом абзаце на стохастические постановки. Аналогичное
можно сделать для стохастических безградиентных и покомпонентных методов с неточ-
ным оракулом (см. п. 4 и [43]). Соответствующие обобщающие формулы собраны в работе
[117], мы не будем их здесь приводить. Такие обобщения востребованы, например, в связи
с приложениями к поиску равновесий в многостадийных моделях равновесного распреде-
ления транспортных потоков [58, 59, 61, 62, 107–109]. В основе этих приложений лежит
конструкция, изложенная в примере 4, с универсальным методом [116] вместо FGM для
решения внешней задачи.

Выше мы сделали обременительное предположение о возможности выполнять проверку
условия 𝜀-близости по функции. Такое заведомо возможно только при известном значении
функционала в точке оптимума. Как правило, такой информации у нас априорно нет. Один
из способов выхода из этой ситуации для задач стохастической оптимизации описан в п. 7.7
работы [79]. Другой способ – контролировать зазор двойственности (со стохастическими
градиентами). Для применимости этого способа требуется, чтобы числовая последователь-
ность {𝜆𝑘/𝑆𝑁}𝑁𝑘=0 не зависела от неизвестных параметров. Во многих задачах, приходящих
из транспортных и экономических приложений, нужно одновременно находить решения
прямой и двойственной задачи, которые можно явно выписать. В таких случаях имеется
эффективный способ проверки условия 𝜀-близости по функции. Нужно проверить условие
𝜀-малости разницы между полученным (приближенным) значением функционалов прямой
и двойственной задачи (т.е. двойственного зазора) [59–61, 109].

Отметим также, что в детерминированном 𝜇-сильно выпуклом случае, когда в точке
минимума 𝑥* выполняется условие34 ∇𝑓 (𝑥*) = 0, критерий 𝜀-близости по функции может
быть переписан в терминах малости рассчитываемого на итерациях градиента:

𝑓 (𝑥𝑘)− 𝑓* ≤
1 ‖∇𝑓 (𝑥𝑘)‖2* ≤ 𝜀.
2𝜇

В постановках с сильно выпуклой/вогнутой двойственной задачей (этого можно добить-
ся искусственно, вводя регуляризацию в двойственную задачу, см. главу 3 [79] и [92, 97])
также можно оценивать точность решения прямой задачи по точности решения двойствен-
ной задачи, применяя к двойственной задаче неравенство35

1 ‖∇𝑓 (𝑥𝑘)‖2
2 * ≤ 𝑓 (𝑥𝑘)− 𝑓*.
𝐿

В частности, это обстоятельство используется в критерии остановки двойственного метода
из [97], см. также пример 4 и [55, 92].

Все сказанное выше, по-видимому, переносится в полной мере на задачи композитной
оптимизации [9, 14, 78, 119] и некоторые их обобщения, например, [96, 101, 102].

34От этого условия можно избавиться, используя в приведенных далее формулах вместо градиента гра-
диентное отображение [10, 55].

35В замечании 5 (см. также [92]) был приведен пример, ко(︀ (︀
гда ‖∇𝑓 (𝑥𝑘)‖2 = 𝑂 𝑘− )︀

2 . Из выписанного
неравенства мы можем гарантировать лишь ‖∇𝑓 (𝑥𝑘)‖22 = 𝑂 𝑘− )︀

2 . Ситуацию можно улучшить, если ре-
гуляризовать функционал (см. кон(︁ец п. 2 и [92, 97]), сд

√︀ ⌈︀ (︀ )︀⌉︀)︁
елав его(︀ сильно вы)︀пуклым, и применить FGM [10,

14, 92, 118] к регуляризованной задаче, тогда ‖∇𝑓 (𝑥𝑘)‖2 = 𝑂 (ln 𝑘)2 /𝑘2 (если использовать, например,
FGM с оценкой числа итераций 𝑂 𝐿/𝜇 ln 𝜇𝑅2/𝜀 , 𝜇 ∼ 𝜀/𝑅2). В негладком случае ситуация проще,
см. [27].



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 67

Замечание 6. Композитные задачи имеют вид: 𝑓 (𝑥) + 𝜆ℎ (𝑥) → min, где 𝜆 > 0, ℎ (𝑥)
𝑥∈𝑄

– выпуклая функция простой структуры, скажем, ℎ (𝑥) = ‖𝑥‖1. Хочется, чтобы сложность
решения этой задачи всецело определялась только гладкостью выпуклого функционала
𝑓 (𝑥), а сильная выпуклость – обоими слагаемыми. Если не лианеризовывать функцию
ℎ (𝑥) при подсчете на каждой итерации градиентного отображения [14], а просто оставлять
это слагаемое как есть, то, конечно, сложность решения вспомогательной задачи на каж-
дой итерации увеличится (впрочем, ввиду простой структуры функции ℎ (𝑥), ожидается,
что не намного), зато в оценку необходимого числа итераций уже не будут входить ни-
какие константы, характеризующие гладкость ℎ (𝑥), только константы, характеризующие
сильную выпуклость (если имеется). На такие задачи также можно смотреть следующим
образом (принцип множителей Лагранжа): 𝑓 (𝑥) → min . Поскольку функция ℎ (𝑥)

𝑥∈𝑄, ℎ(𝑥)≤𝐶(𝜆)
простой структуры, то проектироваться на множество Лебега этой функции несложно.
Отсюда можно усмотреть независимость числа итераций от ℎ (𝑥). Другой способ «борьбы»
с композитным членом ℎ (𝑥) (А. С. Немировский) заключается в переписывании задачи в
«раздутом» (на одно измерение) пространстве: 𝑓 (𝑥) + 𝑦 → min . Норма в раздутом

𝑥∈𝑄, ℎ(𝑥)≤𝑦

пространстве задается как ‖(𝑥, 𝑦)‖ = ‖𝑥‖+𝛼 |𝑦|. Функционал имеет такой вид, что в незави-
симости от гладкости 𝑓 (𝑥) в оценки супремума нормы субградиента/константы Липшица
градиента не будет входить что-либо, связанное с 𝑦. В гладком случае все ясно сразу из
определения, а в случае негладкой 𝑓 (𝑥) это связано с тем, что в действительности в оценку
необходимого числа итераций входит не супремум нормы субградиента, а супремум нор-
мы разностей субградиентов [25] (см. также начало п. 2). За счет возможности выбирать
сколь угодно маленьким 𝛼 > 0, можно считать независящим от 𝑦 и прокс-расстояние (от
точки старта до решения раздутой задачи), входящее в оценку необходимого числа ите-
раций. Таким образом, можно сделать оценку числа итераций независящей от 𝑦 и ℎ (𝑥).
В связи с написанным выше полезно заметить, что гладкость (липшицевость градиента) и
сильная выпуклость функционала являются взаимодвойственными друг к другу для задач
безусловной оптимизации (константа Липшица градиента переходит в константу сильной
выпуклости и наоборот, отсюда, кстати сказать, можно усмотреть, что оценка скорости схо-
димости для таких задач должны зависеть от отношения 𝐿/𝜇, другой способ понять это –
соображения «физической» размерности), что активно используется в приложениях, см.,
например, [43, 55, 73, 74]. Однако для задач условной оптимизации остается только один
переход: двойственная (сопряженная) задача к сильно выпуклой – гладкая (см., напри-
мер, [77] и замечание 3), обратное не верно даже в случае сильно выпуклой функции ℎ (𝑥).
Собственно, мы уже сталкивались с «неравноправностью» гладкости и сильной выпукло-
сти. При рассмотрении универсального метода мы отмечали, что на гладкость можно на-
страиваться адаптивно, чего нельзя сказать про сильную выпуклость. Замечание 6 немного
проясняет (с учетом лагранжева формализма) соотношения между этими свойствами за-
дачи. Впрочем, до окончательного понимания, к сожалению, сейчас еще довольно далеко.
Не ясно даже, принципиальны ли эти различия или их можно в перспективе устранить.
По-видимому, принципиальны, но строгого обоснования мы здесь не имеем.

Также нам видится, что сказанное выше переносится на седловые задачи и монотон-
ные вариационные неравенства [4, 14]. Причем речь идет не о том, что было описано в
примере 4, а о том, как скажется неточность оракула на оптимальные методы для сед-
ловых задач и монотонных вариационных неравенств [4, 14]. Ответ более-менее известен:
неточность оракула не будет накапливаться на оптимальных методах (в отличие от задач
обычной выпуклой оптимизации). Отметим, что концепцию неточного оракула еще необхо-
димо должным образом определить36 – предположение 1 нуждается в корректировке для

36Например, для монотонного вариационного неравенства: найти такой 𝑥 ∈ 𝑄, что для всех 𝑦 ∈ 𝑄
выполняется ⟨𝑔 (𝑦) , 𝑦 − 𝑥⟩ ≥ 0, достаточные условия на (𝛿, 𝐿)-оракул будут иметь вид: для любых 𝑥, 𝑦 ∈ 𝑄
⟨𝑔 (𝑦)− 𝑔 (𝑥) , 𝑦 − 𝑥⟩ ≥ −𝛿, ‖𝑔 (𝑦)− 𝑔 (𝑥)‖* ≤ 𝐿 ‖𝑥− 𝑦‖ + 𝛿. Вероятно, в ряде ситуаций эти условия можно
ослабить (доказательства в этом случае нам не известны) −𝛿 ≤ ⟨𝑔 (𝑦)− 𝑔 (𝑥) , 𝑦 − 𝑥⟩ ≤ 𝐿 ‖𝑦 − 𝑥‖2 + 𝛿.



68 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

данного класса задач. Отсутствие накопления неточностей связано с тем, что для таких
задач оценка (7) будет оптимальна (с некоторыми оговорками) при 𝑝 = 0. Другие 𝑝 ∈ (0, 1]
рассматривать не стоит (такие оценки просто не достижимы). Впрочем, пока про это име-
ются лишь частичные результаты [96, 101, 102].

В оценку числа итераций для достижения заданной точности решения в описанных
методах не входит явно размерность пространства 𝑛. Это наталкивает на мысль (подоб-
ные мысли, по-видимому, впервые были высказаны и реализованы для класса обычных
градиентных методов в кандидатской диссертации Б. Т. Поляка [1], см. также [2, 15]) о
возможности использовать эти методы, например, в гильбертовых пространствах [16, 42].
Оказывается это, действительно, можно делать при определенных условиях (см., например,
[117] в контексте использованных в данной работе обозначений). В частности, концепция
неточного оракула позволяет привнести сюда элемент новизны, существенно мотивирован-
ный практическими нуждами – принципиальной невозможностью (в типичных случаях нет
явных формул) решать с абсолютной (очень хорошей) точностью вспомогательную задачу
на каждом шаге градиентного спуска. Например, решение такой вспомогательной задачи
для класса задач оптимального управления со свободным правым концом приводит к двум
начальным задачам Коши для систем обыкновенных дифференциальных уравнений (важ-
но, чтобы СОДУ для фазовых переменных и сопряженных решались, скажем, методом
Эйлера, на одной и той же сетке), которые необходимо решить для вычисления градиента
функционала [16]. Однако в действительности почти все практически интересные задачи
(за редким исключением, к коим можно отнести класс ляпуновских задач [112]) в беско-
нечномерных пространствах не являются выпуклыми, поэтому здесь имеет смысл говорить
лишь о поиске локальных минимумов (локальной теории) [120]. Если ограничиться неуско-
ренными методами (например, PGM), то можно показать, что при весьма общих условиях
эти методы могут быть использованы в гильбертовом пространстве в концепции неточного
оракула и для невыпуклых (но гладких) функционалов, причем с аналогичными оцен-
ками скорости сходимости (отличие от выпуклого случая будет в том, что метод сходится
лишь к стационарной точке (локальному экстремуму), в бассейне притяжения которой ока-
жется точка старта). Заметим, что задачи оптимального управления можно численно ре-
шать, построив соответствующую (аппроксимирующую) задачу оптимального управления
с дискретным временем, что приводит к конечномерным задачам, для решения которых
можно использовать конечномерный вариант PGM в невыпуклом случае (с точным ораку-
лом). Этот путь, как правило, и предлагается в большинстве пособий (см., например, [16]).
Однако при таком подходе мы должны уметь (по возможности точно) решать сложную
задачу оценки качества аппроксимации исходной задачи оптимального управления ее дис-
кретным по времени вариантом. Более теоретически обоснованный способ рассуждений, по
сути, приводящий к необходимости решать все те же конечномерные задачи, заключается
в рассмотрении исходной задачи оптимального управления и ее решения бесконечномер-
ным вариантом PGM в невыпуклом случае (с неточным оракулом). Неточность оракула
существенна. Поскольку на каждой итерации этого градиентного метода необходимо ре-
шать две задачи Коши для СОДУ, что в общем случае можно сделать лишь приближенно,
но с лучшим контролем точности, чем при подходе с дискретизацией задачи оптимально-
го управления. Отметим, что во многих «физических» приложениях схема Эйлера имеет
хорошие теоретические свойства сходимости (устойчивости). Связано это с тем, что на оп-
тимальном режиме, как правило, наблюдается некоторая стабилизация поведения системы
управления, что приводит к устойчивости якобиана прямой и обратной системы диффе-
ренциальных уравнений.

Покажем в заключение, как приведенные результаты переносятся на задачи стохасти-
ческой онлайн-оптимизации. Для этого напомним вкратце, в чем состоит постановка за-
дачи (см., например, [9, 26, 32, 45, 121–126]). Требуется подобрать последовательность37

37Если 𝑄 = {𝑥 : 𝑔 (𝑥) ≤ 0} и на это множество сложно проектироваться, то можно обобщить, сохранив
оценку (11), конструкцию прямодвойственного метода из работы [111] (см. также [44]) на онлайн-контекст
с таким множеством 𝑄.



Т{︀РУ}︀ДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 69

𝑥𝑘 ∈ 𝑄 так, чтобы минимизировать псевдорегрет:

1 ∑︁𝑁 [︁ (︁ )︁]︁ 𝑁

𝐸 𝑘
𝜉𝑘 𝑓𝑘 𝑥 , 𝜉𝑘 − 1 ∑︁ [︁ (︁ )︁]︁

min 𝐸 𝑘
𝑁 𝑥∈𝑄 𝑁 𝜉 𝑓𝑘 𝑥, 𝜉𝑘

𝑘=1 {︁ (︀ )︀ 𝑘=1 (︀ }︁
на основе доступной информации ∇𝑓 𝑥𝑘−

)︀
1

1 𝑥 , 𝜉1 ; ...;∇𝑓 1
𝑘−1 , 𝜉𝑘−1 при расчете 𝑥𝑘,

где38 ⃦⃦⃦ (︁ )︁ (︁ )︁⃦⃦⃦
∇𝑓 𝑘

𝑘 [︁𝑥 , 𝜉(︁𝑘 −∇)︁𝑓]︁ 𝑘
𝑘 𝑥 , 𝜉𝑘(︁ ≤ 𝛿,

*)︁
{︀ }︀ 𝐸𝜉 ∇𝑓 𝑥𝑘, 𝜉𝑘 𝑓

𝑘 𝑘 = ∇ 𝑘 𝑥𝑘 .

Здесь с.в. 𝜉𝑘 могут считаться независимыми одинаково распределенными. В онлайн-
постановке подразумевается, что на каждом шаге 𝑘 функция 𝑓𝑘 может подбираться из
рассматриваемого класса функц{︀ий}︀враждебно по отношению к используемому нами методу
генерации последователь{︁ности 𝑥𝑘 . В частности, 𝑓𝑘 может зав}︁исеть от

𝑥1, 𝜉1, 𝑓1 ( · ) ; ...;𝑥𝑘−1, 𝜉𝑘−1, 𝑓𝑘−1 ( · ) ;𝑥𝑘 .

В стохастической онлайн-оптимизации с неточным оракулом можно получить следу-
ющие оценки псевдорегрета (см., например, [124], случай неточного оракула в похожем
контексте ранее уже част{︃ичн(︃о√︂прорабатывал)︃ся в [(︂31]): )︂}︃

𝑀2𝑅2 𝑀2 ln𝑁
min 𝑂 +𝑅𝛿 , 𝑂 +𝑅𝛿 , (11)

𝑁 𝜇𝑁

где ‖∇𝑓𝑘 (𝑥, 𝜉)‖* ≤ 𝑀 – равномерно по 𝑥, 𝑘 и п.н. по 𝜉. Эти оценки достигаются (факти-
чески на тех же методах, что и в п. 2 с небольшой оговоркой в сильно выпуклом случае
[39, 124]) и неулучшаемы (в том числе для детерминированных постановок с 𝛿 = 0 и с
линейными функциями 𝑓𝑘 (𝑥)). Как видно из этих оценок, наличие гладкости не позволя-
ет получить более высокую скорость сходимости. То есть никакого аналога формулы (7)
здесь нет. Все, что ранее говорилось про прокс-структуру39 и большие отклонения, на-
сколько нам известно, полностью и практически без изменений переносится и на задачи
онлайн-оптимизации.

4. Стохастические безградиентные и покомпонентные методы
с неточным оракулом

Рассматривается задача стохастической выпуклой оптимизации (1)

𝑓 (𝑥) = 𝐸𝜉 [𝑓 (𝑥, 𝜉)] → min .
𝑥∈𝑄

Предположения те же, что и в первом абзаце п. 2. В частности, п.н. ‖∇𝑓 (𝑥, 𝜉)‖2 ≤𝑀 . Здесь
важно, что функция 𝑓 (𝑥) задана не только на множестве 𝑄, но и в его 𝜏0-окрестности (см.
ниже), и все предположения делаются не для 𝑥 ∈ 𝑄, а для 𝑥 из 𝜏0-окрестности множества
𝑄 (аналогичная оговорка потребуется далее, при перенесении результатов п. 3). Однако
теперь оракул не может выдавать стохастический субградиент функции. На каждой ите-
рации мы можем запрашивать у оракула только значения реализации функции 𝑓 (𝑥, 𝜉) в
нескольких точках 𝑥. Принципиальная разница есть только между запросом значения (ре-
ализации) функции в одной и запросом в двух точках [117, 127]. Здесь мы ограничимся

38Это условие можно заменить, считая, что вместо субградиента мы получаем 𝛿-субградиент [2, 126].
39За исключением сильно выпуклого случая, для которого нам известны только оценки в евклидовой

прокс-структуре. Кроме того, в сильно выпуклом случае в оценках вероятностей больших уклонений
ln (ln (𝑁)) → ln𝑁 – доказательство этого утверждения мы не смогли найти (впрочем, см. замечание 4).



70 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

рассмотрением случая двух точек – случай одной точки представляет интерес только в
онлайн-контексте (см. [126] и цитированную там литературу). Впрочем, есть достаточно
большой и популярный класс одноточечных не онлайн-постановок, которого мы здесь не
касаемся (см., например, [128, 129]).

Предположение 2. 𝛿-оракул выдает (на запрос, в котором указывается только одна
точка 𝑥) 𝑓 (𝑥, 𝜉)+𝛿 (𝑥, 𝜉), где с.в. 𝜉 независимо разыгрывается из одного и того же распре-
деления, фигурирующего в постановке (1), случайная величина 𝛿 (𝑥, 𝜉) = 𝛿 (𝑥) + 𝛿 (𝜉), где
𝛿 (𝜉) – независимая от 𝑥 случайная величина с неизвестным распределением (случайность
которой может быть обусловлена не только зависимостью от 𝜉), ограниченная по мо-
дулю 𝛿/2 (число 𝛿 – допустимый уровень шума), 𝛿 (𝑥) / (𝑅𝛿) – неизвестная 1-липшицева
функция.

Далее в изложении мы будем во многом следовать [2, 33, 45, 76, 124–131]. По полученным
от оракула зашумленным значениям 𝑓 (𝑥, 𝜉)+𝛿 (𝑥, 𝜉) мы можем определить стохастический
субградиент (важно, что можно обратиться с запросом к оракулу в двух разных точках
при одной и той же реализации 𝜉):

𝑛
𝑔𝜏,𝛿 (𝑥, 𝑠, 𝜉) = (𝑓 (𝑥+ 𝜏𝑠, 𝜉) + 𝛿 (𝑥+ 𝜏𝑠, 𝜉)− (𝑓 (𝑥, 𝜉) + 𝛿 (𝑥, 𝜉))) 𝑠, (12)

𝜏

где 𝑠 – случайный вектор (независимый от 𝜉), равномерно распределенный на 𝑆𝑛
2 (1) – еди-

ничной сфере в 2-норме в пространстве R𝑛.40 Из этого представления можно усмотреть,
что липшицева составляющая шума 𝛿2 из предположения 2 и уровень шума 𝛿1 из предпо-
ложения 1 связаны соотношением 𝛿2 ∼ 𝛿1/𝑛 (см. формулу (24)). В действительности, для
обоснования этой связи требуются значительно более громоздкие рассуждения.

Приведем одну из возможных мотивировок введенной в предположении 2 концепции 𝛿-
оракула. Предположим, что оракул может считать абсолютно точно значение липшицевой
функции, но вынужден нам выдавать лишь конечное (предписанное) число первых бит.
Таким образом, в последнем полученном бите есть некоторая неточность (причем мы не
знаем, по какому правилу оракул формирует этот последний выдаваемый значащий бит).
Однако мы всегда можем прибавить (по mod 1) к этому биту случайно приготовленный
(независимый) бит. В результате, не ограничивая общности, можно считать, что оракул
последний бит выбирает просто случайно в независимости от отброшенного остатка. То,
что в итоге выдает оракул, соответствует концепции 𝛿-оракула.

Перейдем к получению оценок. В отличие от пп. 2, 3, везде далее в этом пункте мы
будем считать, что имеет место обратное неравенство на требуемое число итераций 𝑁 ≥ 𝑛
[127]. Прежде всего заметим, что41

𝐸𝑠,𝜉,𝛿 [𝑔𝜏,𝛿 (𝑥, 𝑠, 𝜉)] = ∇𝑓𝜏 (𝑥) +∇𝑥𝐸𝑠,𝜉,𝛿 [𝛿 (𝑥+ 𝜏𝑠, 𝜉)] , (13)

где 𝑠 – случайный вектор, равномерно распределенный на 𝐵𝑛
2 (1) – единичном шаре в 2-

норме, а 𝑓𝜏 (𝑥) = 𝐸𝑠,𝜉 [𝑓 (𝑥+ 𝜏𝑠, 𝜉)] – сглаженная42 версия функции 𝑓 (𝑥) = 𝐸𝜉 [𝑓 (𝑥, 𝜉)].
Причем

0 ≤ 𝑓𝜏 (𝑥)− 𝑓 (𝑥) ≤(︂𝑀𝜏, )︂ (14)

‖𝑔𝜏,𝛿 (𝑥, 𝑠, 𝜉)‖2 ≤
2𝛿

𝑛 𝑀 + . (15)
𝜏

40С помощью леммы Пуанкаре [133] такой вектор можно сгенерировать за 𝑂 (𝑛), разыгрывая 𝑛 незави-
симых одинаково распределенных стандартных нормальных случайных величин и нормируя их на корень
из суммы их квадратов.

41Взятие математического ожидания по 𝛿 подчеркивает, что 𝛿 (𝑥, 𝜉) может быть случайной величиной не
только потому, что может зависеть от 𝜉, но и потому, что может иметь собственную случайность.

42Все свойства функции 𝑓 (𝑥) при переходе к 𝑓𝜏 (𝑥) могут только улучшиться. В частности, 𝑓𝜏 (𝑥) – также
выпуклая функция (можно перенести и на сильную выпуклость с не меньшей константой), с константой
Липшица и константой Липшица градиента (если таковая существует у 𝑓 (𝑥)), не большей, чем у 𝑓 (𝑥).



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 71

Основная идея [2] заключается в подмене задачи (1) следующей задачей:

𝑓𝜏 (𝑥) = 𝐸𝑠,𝜉 [𝑓 (𝑥+ 𝜏𝑠, 𝜉)] → min, (16)
𝑥∈𝑄

𝜀/2-решение которой при 𝜏 = 𝜀/ (2𝑀) будет 𝜀-решением исходной задачи (1).
Считая 𝛿 = 𝑂 (𝜀) и43 (приведенное условие выполняется, если мы имеем доступ к 𝛿-

оракулу из предположения 2)

‖∇𝑥𝐸𝑠,𝜉,𝛿 [𝛿 (𝑥+ 𝜏𝑠, 𝜉)]‖2 = 𝑂 (𝜀/𝑅) ,

можно получить для среднего числа итераций (используя те же алгоритмы для задачи (16),
что и в п. 2, со стохастическим гр(︂адиентом ()︂12)) со(︂ответств)︂ующие аналоги оценок (2), (4)44:

𝑛2𝑀2𝑅2 𝑛2𝑀2
𝑂 , 𝑂 . (17)

𝜀2 𝜇𝜀

Если дополнительно известно, что 𝑓 (𝑥, 𝜉) – равномерно гладкая по 𝑥 функция (это
условие можно ослабить [125]) и п.н. по 𝜉

‖∇𝑓 (𝑥, 𝜉)−∇𝑓 (𝑦, 𝜉)‖2 ≤ 𝐿 ‖𝑥− 𝑦‖2 , (18)
то вместо (14) будем иметь

0 ≤ 𝑓𝜏 (𝑥)− 𝑓 (𝑥) ≤ 𝐿𝜏2
. (19)

2
Из формулы (19) следует, что можно ос√︀лабить требование к неточности: допускать неточ-
ность оракула масштаба45 𝛿 ∼𝑀𝜏 ∼𝑀 𝜀/𝐿.

При сделанных дополнительных предположениях о гладкости (18) за счет ужесточе-
ния требований к масштабу допускаемой неточности 𝛿 (как именно требуется это сделать,
можно усмотреть из формулы (21); ниже мы вернемся к этому вопросу) можно улучшить
скорость сходимости (фактор 𝑛2 п(︂ерейдет )︂в 𝑛): (︂ )︂

𝑛𝑀2𝑅2 𝑛𝑀2
𝑂 , 𝑂 . (20)

𝜀2 𝜇𝜀

Оценки (20) в общем случае не улучшаемы (даже при 𝛿 = 0) для гладких стохастических и
негладких задач [127]. Фактически это означает, что мы можем выбрать настолько малое 𝜏
(насколько малым мы можем его выбрать, определяется 𝜀 и 𝛿), что конечная разность в (12)
«превращается» (с нужной точностью) в производную по направлению. Для объяснения
отмеченного перехода пол[︁езно заметить,]︁что [76, 125–127] (см. также (22))

‖ 𝛿2 2
𝑔𝜏,𝛿 (𝑥, 𝑠, 𝜉)‖22 ≤ 𝑛𝑀2 + 𝐿2𝜏2

8 𝑛
𝐸𝑠,𝜉 4 𝑛2 + . (21)

𝜏2

Замечание 7 (техника двойного сглаживания негладких задач Б. Т. Поляка
[2], см. также [127, 132]). За счет подмены изначально негладкого функционала в зада-
че (1) на

𝑓 (𝑥) := 𝑓𝛾 (𝑥) = 𝐸𝑠1,𝜉 [𝑓 (𝑥+ 𝛾𝑠1, 𝜉)] , 𝛾 ≤ 𝜀/ (2𝑀),

43Если это условие не выполняется, то все, что написано далее, останется верным, правда, при более огра-
ничительных условиях на допустимый уровень шума (это касается(︀ и⧸︀всего посл

√ )︀едующего из(︁ложени√я). Так)︁,
если не налагать это ограничение, то потребуется считать 𝛿 = 𝑂 𝜀2 ( 𝑛𝑀𝑅) или 𝛿 = 𝑂 𝜀3/2/( 𝑛𝐿𝑅)

в случае, если 𝑓 (𝑥) имеет 𝐿-липшицев градиент. Это можно получить с помощью замечания 8.
44Аналогично (2), (4) можно переписать оценку (17) не в среднем, как сейчас, а с учетом вероятностей

больших уклонений. Это замечание касается и последующих вариаций формулы (17). Нам неизвестно,
являются ли оценки (17) оптимальными при заданном уровне шума 𝛿 = 𝑂 (𝜀).

45Здесь мы дополнительно считаем, что ∇𝑥𝐸𝑠,𝜉,𝛿 [𝛿 (𝑥+ 𝜏𝑠, 𝜉)] = 0. В частности, это условие выполняется,
если неточность 𝛿 (𝑥, 𝜉) имеет независимое от 𝑥 распределение.



72 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

где 𝑠1 – случайный вектор (независимый от 𝜉), равномерно распределе⧸︀нный на 𝐵𝑛
2 (1),

получим новую задачу (𝜀/2-аппроксимирующую исходную), для которой при достаточно
малом 𝜏 будет иметь место оценка (21) с достаточно большим 𝐿 ≥ 2𝑛𝑀2 𝜀. Далее, решая
с помощью уже описанной техники с точностью 𝜀 := 𝜀/2 задачу стохастической оптимиза-
ции (1) с

𝜉 := (𝑠1, 𝜉) , 𝑓 (𝑥, 𝜉) := 𝑓 (𝑥+ 𝛾𝑠1, 𝜉) ,

𝑛
𝑔𝜏,𝛿 (𝑥; 𝑠2, 𝜉) := (𝑓 (𝑥+ 𝛾𝑠1 + 𝜏𝑠2, 𝜉) + 𝛿 (𝑥+ 𝛾𝑠1 + 𝜏𝑠2, 𝜉)−

𝜏
− (𝑓 (𝑥+ 𝛾𝑠1, 𝜉) + 𝛿 (𝑥+ 𝛾𝑠1, 𝜉))) 𝑠2,

где 𝑠2 – случайный вектор (независимый от 𝜉 и 𝑠1), равномерно распределенный на 𝑆𝑛
2 (1),

получим те же оценки (20), только при существенно более жестких условиях на уровень
шума 𝛿. К сожалению, получить конструктивное описание этих условий на данный момент
не удалось.

Оценки (17) и (20) переносятся и на задачи стохастической онлайн-оптимизации (см.,
например, [43, 124–127, 130]) с возникновением дополнительного фактора ln𝑁 в сильно
выпуклом случае (см. формулу (11)). При этом даже в гладком случае не обязательно тре-
бовать дополнительно стохастичность исходной постановки для оптимальности оценок (20).

Далее рассматривается нестохастический вариант постановки задачи (1) (необобщае-
мый на онлайн-постановки) с 𝑄 = R𝑛 (обобщения на произвольные выпуклые множества
𝑄 ⊂ R𝑛 представляются интересными, но на данный момент нам неизвестны такие обоб-
щения46 – в последующих рассуждениях существенным образом используется то, что в
точке минимума ∇𝑓 (𝑥*) = 0). Так что теперь 𝑅 – расстояние от точки старта до решения
в 2-норме. В этом вари[︁анте выписан]︁ная оценка (21) может быть уточнена

2 2
‖𝑔𝜏,𝛿 (𝑥, 𝑠)‖22 ≤ 4𝑛 ‖∇𝑓 (𝑥)‖2 8𝛿 𝑛

𝐸 2 + 𝐿2𝜏2𝑛2𝑠 + . (22)
𝜏2

Последняя оценка следует из явления концентрации равномерной меры на 𝑆𝑛
2 (1) с выделен-

ными полюсами вокруг экватора (см. [133] – в случае покомпонентных методов эта оценка
особенно просто получается [43], 𝑠 в приводимой формуле, и только в ней, соответствует
покомпонентной рандомизации):[︁ ]︁

𝐸𝑠 ⟨∇ 1
𝑓 (𝑥) , 𝑠⟩2 = ‖∇𝑓 (𝑥)‖2

𝑛 2 .

Считая для простоты формулировок, что

∇𝑥𝐸𝑠,𝛿 [𝛿 (𝑥+ 𝜏𝑠)] = 0,

можно распространить мет√︀од [87], дающий оценки (8), на текущий контекст и получить
следующие оценки (с 𝜏 ∼ 𝛿/𝐿) числа итераций для достижения точности 𝜀 для случая
выпуклой и сильно выпукло(︂й целе)︂вой функции соотве

1 (︃т(︂стве)︂нно
1 (︂ )︂)︃

𝐿𝑅2 𝑝+1 𝐿 𝑝+1 𝐿𝑅2
𝑁1 (𝜀) = 𝑛 ·𝑂 ,𝑁2 (𝜀) = 𝑛 ·𝑂 ln (23)

𝜀 𝜇 𝜀

при (условия на допустимый уровень шума, при котором оценки (23) имеют такой же вид,
с точностью до 𝑂 (1), как если бы шума не было47)

46По-видимому, такие обобщения возможны. Также возможно перенесение концепции универсальных
методов (см. п. 3) на безградиентные методы и спуски по направлению (покомпонентные спуски) для
детерминированных задач (не задач стохастической оптимизации).

47В отсутствиe шума оракул нам фактически может выдавать производную по направлению 𝑠
𝑔 (𝑥, 𝑠) = 𝑛 ⟨∇𝑓 (𝑥) , 𝑠⟩ 𝑠, точнее ⟨∇𝑓 (𝑥) , 𝑠⟩, 𝑠 мы генерируем сами. Если, в свою очередь, считать, что
⟨∇𝑓 (√𝑥) , 𝑠⟩ оракул выдает с аддитивным шумом (для простоты считаем, независящим от 𝑠) масштаба
𝛿 := 𝐿𝛿 (𝛿 в правой части определяется исходя из формулы (24)), то формула (23) останется верной [117].



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 73

(︂ (︁ 𝑝 )︂
𝜀 )︁ (︂ )︁ )︂

𝑝+1
𝛿1 (𝜀) ≤

1
𝑂 𝜀 · , 𝛿2 (𝜀) ≤

1 (︁ 𝑝
1

𝑂 𝜀 · 𝜇 𝑝+
. (24)

𝑛 𝐿𝑅2 𝑛 𝐿

По-видимому (строгим доказательством мы не располагаем на данный момент), и в
стохастическом случае имеет мест{︃о ан(︂алог ф)︂ормул (23), (24) с заменой в формуле (23)

1 (︂ )︂}︃
𝐿𝑅2 𝑝+1 𝐷𝑅2

𝑁1 (𝜀) = 𝑛 ·max{︃𝑂(︃ , 𝑂 ,

(︂𝜀 )︂ 𝜀2

1 (︂ )︂)︃ (︂ )︂}︃
𝐿 𝑝+1 𝐿𝑅2 𝐷

𝑁2 (𝜀) = 𝑛 ·max 𝑂 ln , 𝑂 .
𝜇 𝜀 𝜇𝜀

Можно продолжать переносить все написанное в п. 3 на рассматриваемую ситуацию
(частично это уже сделано в [43, 117]). Однако мы остановимся лишь на наиболее интерес-
ном (на наш взгляд) месте. А именно, на согласовании прокс-структуры с рандомизацией,
порождающей сглаживание.

Основным результатом (ввиду замечания 7) в негладком и(или) стохастическом случае
с точным оракулом здесь является следующее наблюдение [125, 126]: независимо от вы-
бора прокс-структуры рандомизацию всегда стоит выбирать согласно (12) (если ставить
цель – минимизировать число итераций), т.е. с помощью разыгрывания случайного век-
тора 𝑠, равномерно распределенного на 𝑆𝑛

2 (1). В случае неточного оракула, по-видимому,
это утверждение уже перестает быть верным [125]. Ограничимся далее обобщением оценок
(20) на случай использования общих прокс-структур.

Приведем соответствующее обобщение формулы (21) (здесь и далее нижний индекс «2»
у констант Липшица подчеркивает, что они считаются согласно евклидовой норме из-за
сделанного нами[︁выбора способ]︁а ранд(︂о(︂мизации) )︂

2𝑛2 [︁ ]︁)︂
𝐸𝑠,𝜉 ‖𝑔𝜏,𝛿 (𝑥, 𝑠, 𝜉)‖2

8𝛿
𝑞′ = 𝑂 4𝑀2 2 2

2𝑛+ 𝐿2
2𝜇 𝑛 + 𝐸 2

𝑠 ‖𝑠‖ ′ ,
𝜇2 𝑞

где в прямом пространстве выбрана 𝑞-норма и 1/𝑞+1/𝑞′ = 1. Согласно замечанию 2 можно
считать, что 2 ≤ 𝑞′ ≤[︁∞ – в]︁ыбира(︁ть друг)︁ие нормы, как пра[︁вило, быва]︁ет не в

‖𝑠‖2 𝑞′
𝑞′ = ?̃? 𝑛2/ −1 , в частности 𝐸 2 (︀ыгод

− )︀но. Для
такого диапазона 𝐸 𝑠 ‖𝑠‖ 1

𝑠 Ω(log𝑛) = ?̃? 𝑛 (?̃? () с
точностью до логарифмического фактора от 𝑛 совпадает с 𝑂 (), аналогично с Ω̃ ()). Исходя
из такого обобщения, можно привести следующую таблицу, распространяющую оценку (20)
на произвольные прокс-структуры (𝑅 – расстояние брэгмана, согласованное с 𝑞-нормой, см.
замечание 1).

(︁𝑓 (𝑥) –)︁вып(︁уклая )︁ 𝑓 (𝑥) – 𝜇𝑞-с(︁ильно)︁вы(︁пуклая )︁в 𝑞-норме
𝑛𝑀2

2𝑅
2

𝑂 ?̃? 2/𝑞′− 𝑛𝑀2
1 ′

𝜀2
𝑛 ?̃? 2 2

𝜇 𝑛 /𝑞 −
𝑞𝜀

?̃? 1

Выпишем условия, из которых можно получить требования на шум (нам представляется,
что здесь{︀это может⧸︀хо}︀рошо прояснить суть дела):

1) min 𝑀2𝜏, 𝐿2𝜏
2 2 = 𝑂 (𝜀) – условие достаточной точности аппроксимации исходной

функции ее сглажен(︀ной версией;

2) 𝐿2
2𝜏

2𝑛2 + 8𝛿2𝑛2 )︀
𝜏2

= 𝑂 𝑀2
2𝑛 – условие «правильной» ограниченности квадрата нормы

аппроксимации стохастического градиента.

Выписанные условия позволяют для всех полей таблицы (с оценками) написать соответ-
ствующие условия на допустимый уровень шума и параллельно подобрать оптимальный
размер параметра сглаживания 𝜏 .



74 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

Замечание 8 (см. [126]). Если не делать никаких предположений о шуме 𝛿 (𝑥, 𝜉)
в предположении 2, кроме |𝛿 (𝑥, 𝜉)| ≤ 𝛿, то для получения требований на уровень шу-
ма 𝛿 потребуется еще воспользоваться следующим утверждением. Пусть последователь-
{︁ност(︁ь незави)︁си}︁мых случайных векторов {𝑠 }𝑁𝑘=0, равн мерно распределенных на 𝑆𝑛

2 (1), и
𝑁 [︁𝑘 ]︁о

𝑥 2
𝑘 {𝑠 𝑘−1

𝑙}𝑙=0 обладают свойством 𝐸 ‖𝑥𝑘 − 𝑥 𝑅2
=1 [︃ *‖]︃2 ≤ . Тогда

𝑘

1 ∑︁𝑁
𝐸 |⟨𝑠𝑘, 𝑥𝑘 − 𝑥*⟩| ≤ √2𝑅 .

𝑁 𝑛
𝑘=1

В виду замечаний 2, 4 при использовании этого утверждения можно считать, что
𝑅2 = 𝑂 (𝑉 (𝑥*, 𝑥0)). Причем константа в 𝑂 () может быть сделана ∼ 1.

Приведенная в первом столбце таблицы оценка при определенных условиях может быть
лучше нижней оценки [127]. Здесь ситуация аналогична той, о которой написано в конце
замечания 2 (будем использовать те же обозначения) и в п. 3. Например, если 𝑄 = 𝐵𝑛

1 (1),
то в нижней о⧸︀цен)︀ (︀ ⧸︀ )︀ [︁ ]︁

(︀ ке [127] стоит Ω̃ 𝑛𝑀2 2
1 𝜀 (𝐸 2

𝜉 ‖∇𝑓 (𝑥, 𝜉)‖2∞ ≤ 𝑀1 ), а в таблице будет
стоять ?̃? 𝑀2

2 𝜀2 . Осталось заметить, что 𝑀2
2 ≤ 𝑛𝑀2

1 , причем в определенных ситуациях
может быть 𝑀2

2 ≪ 𝑛𝑀2
1 .

Основные конкурирующие рандомизации в гладком случае – это рандомизация на ев-
клидовой сфере и покомпонентная рандомизация [43, 125–127], которая используется в
основном только с евклидовой прокс-структурой [43]. Исследования последних нескольких
лет показали (см., например, [43, 50, 55, 63, 65]), что для довольно большого класса глад-
ких задач выпуклой оптимизации в пространствах огромной размерности48, возникающих
в самых разных приложениях [50, 55, 60, 63], покомпонентные методы являются наиболее
эффективным способом решения (с точки зрения общего числа арифметических операций
для достижения заданной точности по функции). Покомпонентные методы, безусловно, за-
служивают отдельного подробного обзора. Поэтому здесь мы ограничимся только ссылкой
на такие обзоры [43, 134].

Приведем далее несколько примеров, демонстрирующих важность изучения безгради-
ентных методов (часто эти методы называют прямыми методами [2] или методами нулевого
порядка [76]).

Пример 5 (двухуровневая оптимизация [135]). Требуется решить задачу, возни-
кающую, например, при поиске равновесия по Штакельбергу [106]:

𝜓 (𝑥, 𝑢) → max,
𝑢∈𝑈

𝑓 (𝑥, 𝑢 (𝑥)) → min .
𝑥

Из первой задачи находится зависимость 𝑢 (𝑥), которая входит во вторую (внешнюю) за-
дачу. Проблема здесь в том, что явная зависимость 𝑢 (𝑥) в общем случае может быть недо-
ступна. Как следствие, могут быть проблемы с расчетом ∇𝑢 (𝑥). Поэтому предлагается
приближенно решать первую задачу и использовать безградиентный метод с неточным
оракулом для второй. Насколько точно надо решать первую задачу и какой именно без-
градиентный метод (с точки зрения чувствительности к неточности) выбирать для второй
– определяется сложностью решения первой задачи и свойствами второй.

Рассмотренная двухуровневая задача может быть сильно упрощена, если удается найти
ее седловое представление [14, 58, 61, 62, 101, 102, 107–109]. В частности, если функции
𝜓 (𝑥, 𝑢), 𝑓 (𝑥, 𝑢) – выпуклы по 𝑥 и вогнуты по 𝑢, и 𝜓 (𝑥, 𝑢) – простой структуры, то можно
(для достаточно большого 𝜆) заменить исходную задачу на следующую:

minmax [𝑓 (𝑥, 𝑢) + 𝜆𝜓 (𝑥, 𝑢)] .
𝑥 𝑢∈𝑈

48Во всех этих задачах можно считать полные градиенты и строить на их базе различные методы. То
есть для таких задач выбор покомпонентного метода – осмысленный выбор наиболее быстрого способа
решения, а не следствие каких-то (в том числе вычислительных) ограничений на задачи.



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 75

Полученную седловую задачу стоит решать методами композитной оптимизации (см. за-
мечание 6 и [9, 14, 101, 102]), чтобы параметр 𝜆 либо совсем не входил в оценки числа
итераций, либо входило очень слабо.

К сожалению, седловое представление возможно далеко не всегда.
Пример 6 (огромная скрытая размерность). Пусть 𝑦 (𝑥) ∈ R𝑚, 𝑥 ∈ R𝑛, 𝑛 ≪ 𝑚.

Требуется решить задачу
𝑓 (𝑥, 𝑦 (𝑥)) → min .

𝑥

Мы предполагаем, что можем эффективно посчитать с необходимой точностью 𝑦 (𝑥) и
𝑓 (𝑥, 𝑦 (𝑥)) за 𝑂 (𝑚). Если для решения этой задачи оптимизации мы будем использовать
безградиентный метод, то общее число сделанных арифметических операций пропорцио-
нально 𝑚𝑛 (см. (20), (23)). Заметим, что если бы мы могли использовать обычный гра-
диентный метод, то общее число сделанных арифметических операций также было бы
пропорционально 𝑚𝑛, однако вычисление градиента по разным причинам может быть за-
труднено (см. пример 5 и метод MCMC [52] для расчета PageRank в подходе [136, 137]).
В действительности часто имеет место следующее полезное наблюдение [136]: если мы мо-
жем вычислить значения 𝑦 (𝑥) и 𝑓 (𝑥, 𝑦 (𝑥)) за 𝑂 (𝑚), то мы можем с такой же по порядку
сложностью (и затратами памяти) вычислить и производные по фиксированному направ-
лению ℎ: ⟨ ⟩ ⟨ ⟩

𝑑𝑦 (𝑥) 𝜕𝑓 (𝑥, 𝑦) 𝜕𝑓 (𝑥, 𝑦) 𝑑𝑦 (𝑥)
ℎ, , ℎ + , ℎ .

𝑑𝑥 𝜕𝑥 𝜕𝑦 𝑑𝑥

Тем не менее тут требуется много оговорок, в том числе про точность расчетов. Если не
вдаваться в детали, то такие рассуждения также приводят к затратам, пропорциональным
𝑚𝑛, где 𝑛 возникло в виду оценок (20), (23) для спусков по направлению. Только в отличие
от полноградиентного метода для покомпонентного метода константа Липшица градиента
функционала в оценке числа итераций уже будет рассчитываться не по худшему направ-
лению, а в среднем (это может давать выгоду, по порядку равную корню квадратному из
размерности пространства [43, 138]), да и, как правило, будет ощутимая выгода в затрачи-
ваемых ресурсах машинной памяти [136]. Оговорки о точности здесь все же необходимы,
поскольку для безградиентных методов и спусков по направлению требования к точно-
сти могут существенно отличаться (об этом ранее уже было немного написано в данном
пункте). Как следствие, в оценку 𝑂 (𝑚) необходимо явно вводить зависимость от точности
вычисления 𝑦 (𝑥) и 𝑓 (𝑥, 𝑦 (𝑥)). Об этом планируется написать отдельно.

В примерах 5, 6 в действительности требуются некоторые оговорки о невозможности
или неэффективности использования БАД для полноградиентного метода (см. п. 2, а так-
же [41, 42]). Нам известны случаи, подпадающие под разобранные примеры, в которых не
понятно, как можно было бы воспользоваться БАД [106, 136, 137]. В частности, в работах
[136, 137], соответствующих примеру 6, сложность в том, что БАД хочется использовать
для ускорения вычисления матрицы Якоби отображения (вектор функции) 𝑦 (𝑥) ∈ 𝑆𝑚 (1),
неявно заданного уравнением 𝑦 = 𝑃 (𝑥) 𝑦, со стохастической (по(︀стол(︀бцам) эргодической
матрицей 𝑃 (𝑥) со спектральной щелью 𝛼 и числом ненулевых элементов 𝑠𝑚. Ме(︀тод)︀п)︀р)︀о-
стой итерации позволяет с точностью 𝜀 найти 𝑦 (𝑥) за время 𝑂 𝑠𝑚 𝑛+ 𝛼−1 ln 𝜀−1 с
затратами памяти 𝑂 (𝑠𝑚). Нам неизвестно более эффективного способа расчета матри-
цы(︀ Якоби ото(︀браж)︀)︀ения 𝑦 (𝑥), чем естественное обобщение метода простой итерации (для
продифференцированного по 𝑥 уравнения 𝑦 (𝑥) = 𝑃 (𝑥) 𝑦 (𝑥)), требующее затрат времени
𝑂 𝑠𝑚𝑛𝛼−1 ln 𝜀−1 и памяти 𝑂 (𝑠𝑚𝑛). Для реальных приложений [136, 137]: 𝑚 ∼ 109,
𝑠 ∼ 102, 𝑛 ∼ 103, 𝛼 ∼ 10−1, 𝜀 ∼ 10−12 Отсюда ясно, что при использовании полноградиент-
ного метода просто невозможно будет выделить даже у 64-битной операционной системы,
стоящей на самом современном персональном компьютере, необходимой памяти под рабо-
тающую программу, в основе которой лежит полноградиентный подход.

Кроме того, в примерах 5, 6 важно уметь эффективно пересчитывать значения 𝑢 (𝑥)
или 𝑦 (𝑥), а не рассчитывать их каждый раз заново (на каждой итерации внешнего цик-
ла). Поясним сказанное. Предположим, что мы уже как-то посчитали, скажем, 𝑢 (𝑥), ре-



76 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

шив с какой-то точностью соответствующую задачу оптимизации. Тогда для вычисления
𝑢 (𝑥+Δ𝑥) (на следующей итерации внешнего цикла) у нас будет хорошее начальное при-
ближение 𝑢 (𝑥). А как известно (см. пп. 2–4), расстояние от точки старта до решения (не
в сильно выпуклом случае) существенным образом определяет время работы алгоритма
оптимизции. Эта конструкция (hot/warm start) напоминает фрагмент обоснования сходи-
мости методов внутренней точки при изучении движения по центральному пути [8–11]. Тем
не менее известные нам приложения (пример 4 п. 3 и [61, 62, 136, 137]) пока как раз всеце-
ло соответствуют сильно выпуклой ситуации. Связано это с тем, что если расчет 𝑢 (𝑥) или
𝑦 (𝑥) с точностью 𝜀 осуществляется за 𝑂 (C ln (𝑅/𝜀)) операций, то для внешней задачи мож-
но выбирать самый быстрый метод (а стало быть, и самый требовательный к точности), и
с точностью до того, что стоит под логарифмом, общая трудоемкость будет просто прямым
произведением трудоемкостей решения внутренней и внешних задач по отдельности. Как
правило, такое сочетание оказывается недоминируемым.

Также необходимо отметить, что, как правило, итоговые задачи оптимизации (после
подстановки зависимости 𝑢 (𝑥) или 𝑦 (𝑥) в задачу верхнего уровня) в этих примерах по-
лучаются не выпуклыми. В этой связи можно лишь говорить о локальной сходимости к
стационарной точке. В отсутствие выпуклости даже если ограничиться локальной сходи-
мостью, многое из того, что описано в данной статье, требует отдельного рассмотрения
[76, 96].

Отметим в заключение, что если немного по-другому посмотреть на описанное в этом
пункте, то можно заметить следующее. Какой бы большой (но равномерно ограниченный по
итерациям) шум ни был, если 𝛿 (𝑥+ 𝜏𝑠, 𝜉) имеет распределение, не зависящее от 𝑠, то (воз-
можно, через очень большое число итераций) мы сможем сколь угодно точно (по функции)
решить задачу! Аналогичное можно сказать, если мы изначально исходим из концепции
оракула, выдающего зашумленное значение ⟨∇𝑓 (𝑥) , 𝑠⟩, причем зашумленность не зависит
от 𝑠. Все это восходит к идеям Р. Фишера, развитым О.Н. Граничиным и Б. Т. Поляком [33].

5. Заключение

Авторы выражают благодарность А.С. Антипину, С. Бойду, А. Ю. Горнову, Ф. Глинёру,
О. Н. Граничину, А.И. Голикову, О. Деволдеру, Н. К. Животовскому, А. В. Назину,
Е. А. Нурминскому, А. Рахлину, П. Рихтарику, А. Содину, В. Г. Спокойному, С. П. Тарасову,
Э. Хазану, С.В. Чуканову, А. Г. Шапиро, А. Б. Юдицкому и особенно А. С. Немировскому
за возможность обсуждения разных частей данного текста в разное время, а также Ильнуре
Усмановой, обнаружившей несколько опечаток.

Особо хотелось бы отметить то позитивное влияние, которое на каждого из авторов
оказал Борис Теодорович Поляк, отметившим в 2015 году свое восьмидесятилетие [139].
Так, Ю. Е. Нестеров защищал кандидатскую диссертацию под руководством Б. Т. Поляка
в 1983 г. Два других соавтора в значительной степени являются учениками Ю. Е. Нестерова
по части, связанной с численными методами выпуклой оптимизации. Набор идей, здоровый
оптимизм, понятность и открытость Бориса Теодоровича всегда делают общение и работу
с ним чрезвычайно интересной и полезной. Настоящая статья во многом была вдохновлена
его книгой [2] и попыткой ее переосмыслить с современных позиций. Несмотря на то, что
большей частью эта книга была написана почти 40 лет назад, она до сих пор не утратила
свою актуальность, о чем говорит, например, недавний выход ее нового издания.

Настоящая статья, в основу которой положено выступление [140], была написана уже к
осени 2014 года. К сожалению, из-за объема и стиля у нас возникли проблемы с ее публи-
кацией. Мы хотели бы поблагодарить Леонида Васильевича Стрыгина, любезно согласив-
шегося взять данную статью (несмотря на ее большой объем) в журнал «Труды МФТИ»
в марте 2016 года. Третий пункт настоящей статьи получил продолжение в другой публи-
кации в журнале «Труды МФТИ» [141].



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 77

Исследование А.В. Гасникова и П. Е. Двуреченского в части 3 выполнено в ИППИ РАН
за счет гранта Российского научного фонда (проект №14-50-00150), а в частях 2 и 4 при
поддержке гранта РФФИ 15-31-20571-мол_а_вед; исследование Ю.Е. Нестерова в частях
2 и 4 выполнено при поддержке гранта РФФИ 14-01-00722-а.

Литература

1. Поляк Б.Т. Градиентные методы минимизации функционалов, решения уравне-
ний и неравенств: диссертация на соискание ученой степени кандидата физико-
математических наук. МГУ, механико-математический факультет, 1963.

2. Поляк Б.Т. Введение в оптимизацию. М.: Наука, 1983; М.: УРСС, 2014.
3. Хачиян Л.Г. Избранные труды / сост. С. П. Тарасов. М.: МЦНМО, 2009.
4. Немировский А.С., Юдин Д.Б. Сложность задач и эффективность методов оптимиза-

ции. М.: Наука, 1979.
5. Поляк Б.T., Цыпкин Я.З. Оптимальные псевдоградиентные алгоритмы адаптации //

Автоматика и телемеханика. 1980. № 8. С. 74–84.
6. Цыпкин Я.З., Позняк А.С. Оптимальные поисковые алгоритмы стохастической опти-

мизации // Докл. АН СССР. 1981. Т. 260, № 3. С. 550–553.
7. Нестеров Ю.Е. Эффективные методы в нелинейном программировании. М.: Радио и

связь, 1989.
8. Nesterov Y., Nemirovsky A. Interior-point polynomial methods in convex programming.

Studies in applied mathematics. V. 13. SIAM, Philadelphia, 1994.
9. Nemirovski A. Lectures on modern convex optimization analysis,

algorithms, and engineering applications. Philadelphia: SIAM, 2013.
http://www2.isye.gatech.edu/˜nemirovs/Lect_ModConvOpt.pdf

10. Нестеров Ю.Е. Введение в выпуклую оптимизацию. М.: МЦНМО, 2010.
11. Bubeck S. Convex optimization: algorithms and complexity // In Foundations and Trends

in Machine Learning. 2015. V. 8, N 3–4. P. 231–357. arXiv:1405.4980
12. http://cvxr.com/cvx/
13. http://www.cvxpy.org/en/latest/ ; https://github.com/cvxgrp/scs
14. Нестеров Ю.Е. Алгоритмическая выпуклая оптимизация: диссертация

на соискание степени д.ф.-м.н. по специальности 01.01.07 – вычисли-
тельная математика. Долгопрудный, МФТИ 26 декабря 2013 г. 367 c.
http://www.mathnet.ru/php/seminars.phtml?option_lang=rus&presentid=8313

15. Левитин Е.С., Поляк Б.Т. Методы минимизации при наличии ограничений // ЖВМ
и МФ. 1966. Т. 6, № 5. С. 787–823.

16. Васильев Ф.П. Методы оптимизации. М.: МЦНМО, 2011.
17. Jaggi M. Revisiting Frank–Wolfe: Projection-free sparse convex optimization // Proceedings

of the 30th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013.
https://sites.google.com/site/frankwolfegreedytutorial/

18. Nesterov Yu. Complexity bounds for primal-dual methods minimizing the model of objective
function // CORE Discussion Papers. 2015/03. 2015.

19. Tseng P. On accelerated proximal gradient methods for convex-concave optimization //
SIAM J. Optim. 2008. (submitted) http://www.mit.edu/˜dimitrib/PTseng/papers.html

20. Neumaier A. OSGA: A fast subgradient algorithm with optimal complexity // e-print, 2014.
arXiv:1402.1125



78 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

21. Allen-Zhu Z., Orecchia L. Linear coupling: An ultimate unification of gradient and mirror
descent // e-print, 2014. arXiv:1407.1537

22. Ермольев Ю.М. Методы стохастического программирования. М.: Наука, 1976.
23. Нурминский Е.А. Численные методы решения детерминированных и стохастических

минимаксных задач. Киев: Наукова думка, 1979.
24. Shapiro A., Dentcheva D., Ruszczynski A. Lecture on stochastic programming. Modeling

and theory. MPS-SIAM series on Optimization, 2014.
25. Nesterov Y. Minimizing functions with bounded variation of subgradients // CORE

Discussion Papers. 2005/79. 2005.
26. Гасников А.В., Нестеров Ю.Е., Спокойный В.Г. Об эффективности одного метода ран-

домизации зеркального спуска в задачах онлайн-оптимизации // ЖВМ и МФ. Т. 55,
№ 4. 2015. С. 55–71. arXiv:1410.3118

27. Nesterov Y. Primal-dual subgradient methods for convex problems // Math. Program. Ser.
B. 2009. V. 120(1). P. 261–283.

28. Поляк Б.Т. Новый метод типа стохастической аппроксимации // Автоматика и теле-
механика. 1990. № 7. C. 98–107.

29. Polyak B.T., Juditsky A.B. Acceleration of stochastic approximation by averaging // SIAM
J. Control Optim. 1992. V. 30. P. 838–855.

30. Juditsky A., Lan G., Nemirovski A., Shapiro A. Stochastic approximation approach to
stochastic programming // SIAM Journal on Optimization. 2009. V. 19, N 4. P. 1574–1609.

31. Juditsky A., Nemirovski A. First order methods for nonsmooth convex large-scale
optimization, I, II. In: Optimization for Machine Learning. Eds. S. Sra, S. Nowozin, S.
Wright. MIT Press, 2012.

32. Sridharan K. Learning from an optimization viewpoint. PhD Thesis, Toyota Technological
Institute at Chicago, 2011. http://ttic.uchicago.edu/˜karthik/thesis.pdf

33. Граничин О.Н., Поляк Б.Т. Рандомизированные алгоритмы оценивания и оптимизации
при почти произвольных помехах. М.: Наука, 2003.

34. Spokoiny V. Parametric estimation. Finite sample theory // The Annals of Statistics. 2012.
V. 40, N 6. P. 2877–2909. arXiv:1111.3029v5

35. Ибрагимов И.А., Хасьминский Р.З. Асимптотическая теория оценивания. М.: Наука,
1977.

36. Lacost-Julien S., Schmidt M., Bach F. A simpler approach to obtaining 𝑂 (1/𝑡) convergence
rate for the projected stochastic subgradient method // e-print, 2012. arXiv:1212.2002

37. Rakhlin A., Shamir O., Sridharan K. Making gradient descent optimal for strongly convex
stochastic optimization // ICML, 2012. arXiv:1109.5647

38. Juditsky A., Nesterov Yu. Deterministic and stochastic primal-dual subgradient algorithms
for uniformly convex minimization // Stoch. System. 2014. V. 4, N 1. P. 44–80.
arXiv:1401.1792

39. Hazan E., Kale S. Beyond the regret minimization barrier: Optimal algorithms for stochastic
strongly-convex optimization // JMLR. 2014. V. 15. P. 2489–2512.

40. Боровков А.А., Боровков К.А. Асимптотический анализ случайных блужданий. Т. 1.
Медленно убывающие распределения скачков. М.: Физматлит, 2008.

41. Ким К., Нестеров Ю., Скоков В., Черкасский Б. Эффективные алгоритмы для диф-
ференцирования и задачи экстремали // Экономика и математические методы. 1984.
Т. 20. С. 309–318.



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 79

42. Евтушенко Ю.Г. Оптимизация и быстрое автоматическое дифференцирование. М.:
ВЦ РАН, 2013.

43. Гасников А.В., Двуреченский П.Е., Усманова И.Н. О нетривиальности быстрых
(ускоренных) рандомизированных методов // Труды МФТИ. 2016. Т. 8. (в печати)
arXiv:1508.02182

44. Аникин А.С., Гасников А.В., Горнов А.Ю. Рандомизация и разреженность в зада-
чах huge-scale оптимизации на примере работы метода зеркального спуска // Труды
МФТИ. 2016. Т. 8. (в печати) arXiv:1602.00594

45. Bubeck S., Cesa-Bianchi N. Regret analysis of stochastic and nonstochastic multi-armed
bandit problems // Foundation and Trends in Machine Learning. 2012. V. 5, № 1. P. 1–122.
http://www.princeton.edu/s̃bubeck/SurveyBCB12.pdf

46. Гасников А.В., Лагуновская А.А., Морозова Л.Э. О связи имитационной логит-
динамики в популяционной теории игр и метода зеркального спуска в онлайн-
оптимизации на примере задачи выбора кратчайшего маршрута // Труды МФТИ.
2015. Т. 7, № 4. С. 104–113. arXiv:1511.02398

47. Agarwal A., Bartlett P.L., Ravikumar P., Wainwright M.J. Information-theoretic lower
bounds on the oracle complexity of stochastic convex optimization // IEEE Transaction
of Information. 2012. V. 58, N 5. P. 3235–3249. arXiv:1009.0571

48. Аникин А.С., Гасников А.В., Горнов А.Ю., Камзолов Д.И., Максимов Ю.В., Нестеров
Ю.Е. Эффективные численные методы решения задачи PageRank для дважды разре-
женных матриц // Труды МФТИ. 2015. Т. 7, № 4. С. 74–94. arXiv:1508.07607

49. Назин А.В., Поляк Б.Т. Рандомизированный алгоритм нахождения собственного век-
тора стохастической матрицы с приложением к задаче PageRank // ДАН РАН. 2009.
Т. 426, № 6. С. 734–737.

50. Nesterov Y.E. Efficiency of coordinate descent methods on large scale optimization problem
// SIAM Journal on Optimization. 2012. V. 22, N 2. P. 341–362.

51. Nesterov Y.E. Subgradient methods for huge-scale optimization problems // CORE
Discussion Paper 2012/2. 2012.

52. Гасников А.В., Дмитриев Д.Ю. Об эффективных рандомизированных алгоритмах по-
иска вектора PageRank // ЖВМ и МФ. 2015. Т. 55, № 3. С. 355–371. arXiv:1410.3120

53. Fercoq O., Richtarik P. Accelerated, parallel and proximal coordinate descent // SIAM
Journal on Optimization. 2015. V. 25, N 4. 1997–2023. arXiv:1312.5799

54. Qu Z., Richtarik P. Coordinate Descent with Arbitrary Sampling I: Algorithms and
Complexity // e-print, 2014. arXiv:1412.8060

55. Anikin A., Dvurechensky P., Gasnikov A., Golov A., Gornov A., Maximov Yu., Mendel
M., Spokoiny V. Modern efficient numerical approaches to regularized regression problems
in application to traffic demands matrix calculation from link loads // Proceedings of
International conference ITAS-2015. Russia, Sochi, September, 2015. arXiv:1508.00858

56. Аникин А.С., Гасников А.В., Горнов А.Ю. О неускоренных эффективных методах ре-
шения разреженных задач квадратичной оптимизации // Труды МФТИ. 2016. Т. 8.
(в печати). arXiv:1602.01124

57. Nesterov Yu., Nemirovski A. On first order algorithms for 𝑙1 / nuclear norm minimization
// Acta Numerica. 2013. V. 22. P. 509–575.

58. Гасников А.В., Дорн Ю.В., Нестеров Ю.Е, Шпирко С.В. О трехстадийной версии
модели стационарной динамики транспортных потоков // Математическое моделиро-
вание. 2014. Т. 26:6. C. 34–70. arXiv:1405.7630



80 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

59. Гасников А.В., Гасникова Е.В., Ершов Е.И., Двуреченский П.Е., Лагуновская А.А.
Поиск стохастических равновесий в транспортных моделях равновесного распределе-
ния потоков // Труды МФТИ. 2015. Т. 7, № 4. С. 114–128. arXiv:1505.07492

60. Гасников А.В., Двуреченский П.Е., Дорн Ю.В., Максимов Ю.В. Численные методы
поиска равновесного распределения потоков в модели Бэкмана и модели стабильной
динамики // Математическое моделирование. 2016. Т. 28. (в печати). arXiv:1506.00293

61. Гасников А.В., Двуреченский П.Е., Камзолов Д.И., Нестеров Ю.Е., Спокойный
В.Г., Стецюк П.И., Суворикова А.Л., Чернов А.В. Поиск равновесий в многоста-
дийныйх транспортных моделях // Труды МФТИ. 2015. Т. 7, № 4. С. 143–155.
https://mipt.ru/upload/medialibrary/ffe/143-155.pdf

62. Гасников А.В., Двуреченский П.Е., Спокойный В.Г., Стецюк П.И., Суворикова А.Л.
Суперпозиция метода балансировки и универсального градиентного метода для по-
иска энтропийно-сглаженного барицентра Вассерштейна и равновесий в многоста-
дийных моделях транспортных потоков // Труды МФТИ. 2016. Т. 8. (в печати).
arXiv:1506.00292

63. Richtarik P. http://www.maths.ed.ac.uk/˜richtarik/
64. Shalev-Shwartz S. http://www.cs.huji.ac.il/˜shais/
65. Zhang T. http://www.stat.rutgers.edu/home/tzhang/
66. Le Roux N., Schmidt M., Bach F. A stochastic gradient method with an exponential

convergence rate for strongly-convex optimization with finite training sets // In Advances
in Neural Information Processing Systems (NIPS). 2012. arXiv:1202.6258

67. Johnson B., Zhang T. Accelerating stochastic gradient descent using predictive
variance reduction // In Advances in Neural Information Processing Systems (NIPS).
2013.http://www.stat.rutgers.edu/home/tzhang/pubs.html

68. Konecny J., Richtarik P. Semi-Stochastic gradient descent methods // e-print, 2013.
arXiv:1312.1666

69. Konecny J., Liu J., Richtarik P., Takac M. Mini-batch semi-stochastic gradient descent in
the proximal setting // e-print, 2015. arXiv:1504.04407

70. Lan G., Zhou Y. An optimal randomized incremental gradient methods // Technical Report,
Department of Industrial and Systems Engineering, University of Florida, July 7, 2015,
updated in October, 2015.http://www.ise.ufl.edu/glan/files/2015/10/OptRandom10-18.pdf

71. Lin Q., Lu Z., Xiao L. An Accelerated Randomized Proximal Coordinate Gradient Method
and its Application to Regularized Empirical Risk Minimization // SIAM J. Optim. 2015.
V. 25, N 4. P. 2244–2273.http://research.microsoft.com/pubs/228730/spdc_paper.pdf,
http://research.microsoft.com/pubs/258430/APCG_ERM_2015.pdf

72. Agarwal A., Bottou L. A lower bound for the optimization of finite sums // e-print, 2014.
arXiv:1410.0723

73. Shalev-Shwartz S., Zhang T. Accelerated proximal stochastic dual coordinate ascent for
regularized loss minimization // In Proceedings of the 31th International Conference on
Machine Learning, ICML 2014, Beijing, China, 21-26 June 2014. P. 64–72. arXiv:1309.2375

74. Zheng Q., Richtarik P., Zhang T. Randomized dual coordinate ascent with arbitrary
sampling // e-print, 2014. arXiv:1411.5873

75. Bartlett P.L., Mendelson S. Empirical minimization // Probability theory and related fields.
2006. V. 135(3). P. 311–334.

76. Nesterov Yu., Spokoiny V.Random gradient-free minimization of convex functions //
Foundations of Computational Mathematics, 2015; CORE Discussion Paper 2011/1. 2011.



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 81

77. Nesterov Y. Smooth minimization of non-smooth function // Math. Program. Ser. A. 2005.
V. 103, N 1. P. 127–152.

78. Devolder O., Glineur F., Nesterov Yu. First order methods of smooth convex optimization
with inexact oracle // Math. Progr. Ser. A. 2014. V. 146(1–2). P. 37–75.

79. Devolder O. Exactness, inexactness and stochasticity in first-order methods for large-scale
convex optimization. CORE UCL, PhD thesis, March 2013.

80. D’Aspermont A. Smooth optimization with approximate gradient // SIAM Journal of
Optimization. 2008. V. 19(3). P. 1171–1183.

81. Baes M. Estimate sequence methods: extensions and approximations. IFOR Internal report.
ETH Zurich, Switzerland, 2009.

82. Devolder O., Glineur F., Nesterov Yu. First order methods with inexact oracle: the smooth
strongly convex case // CORE Discussion Paper 2013/16. 2013.

83. Devolder O., Glineur F., Nesterov Yu. Intermediate gradient methods for smooth convex
problems with inexact oracle // CORE Discussion Paper 2013/17. 2013.

84. Ghadimi S., Lan G. Optimal stochastic approximation algorithms for strongly convex
stochastic composite optimization I: A generic algorithmic framework // SIAM J. Optim.
2012. V. 22(4). P. 1469–1492.

85. Ghadimi S., Lan G. Optimal stochastic approximation algorithms for strongly convex
stochastic composite optimization II: Shrinking procedures and optimal algorithms // SIAM
J. Optim. 2013. V. 23(4). P. 2061–2089.

86. Гасников А.В., Двуреченский П.Е. Стохастический промежуточный метод для задач
выпуклой оптимизации // ДАН РАН. 2016. Т. 467, № 2. С. 131–134.

87. Dvurechensky P., Gasnikov A. Stochastic Intermediate Gradient Method for Convex
Problems with Inexact Stochastic Oracle // Journal Optimization Theory and Applications.
2016. (подана) arXiv:1411.2876

88. Ортега Дж., Рейнболдт В. Итерационные методы решения нелинейных систем урав-
нений со многими неизвестными. М.: Мир, 1975.

89. Евтушенко Ю.Г. Методы решения экстремальных задач и их применение в системах
оптимизации. М.: Наука, 1982.

90. Wu S., Boyd S., Candes E. A differential equation for modeling Nesterov’s
accelerated gradient method: Theory and insight // NIPS, December 2014.
http://stanford.edu/˜boyd/papers/ode_nest_grad.html

91. Wibisono A., Wilson A.C. On accelerated methods in optimization // e-print, 2015.
arXiv:1509.03616

92. Аникин А.С., Гасников А.В., Двуреченский П.Е., Тюрин А.И., Чернов А.В.
Двойственные подходы к задачам минимизации сильно выпуклых функционалов про-
стой структуры при аффинных ограничениях // ЖВМ и МФ. 2016. Т. 56. (подана).
arXiv:1602.01686

93. Nesterov Yu., Shikhman V. Convergent subgradient methods for
nonsmooth convex minimization // CORE Discussion Paper 2014/5. 2014.
https://www.uclouvain.be/cps/ucl/doc/core/documents/coredp2014_5web.pdf

94. Lin H., Mairal J., Harchaoui Z. A universal catalyst for first-order optimization //
Advances in Neural Information Processing Systems (NIPS), 2015. https://hal.inria.fr/hal-
01160728

95. Lan G. Gradient sliding for composite optimization // Math. Progr. 2014. (submitted).
http://pwp.gatech.edu/guanghui-lan/wp-content/uploads/sites/330/2016/02/GS-
nonsmooth-stochastic6-11-submit.pdf



82 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

96. Lan G. http://www.ise.ufl.edu/glan/publications/
97. Гасников А.В., Гасникова Е.В., Нестеров Ю.Е., Чернов А.В. Об эффективных чис-

ленных методах решения задач энтропийно-линейного программирования // ЖВМ и
МФ. 2016. Т. 56, № 4. С. 523–534. arXiv:1410.7719

98. Spielman D. Algorithms, graph theory, and linear equations in Laplacian matrices // Proc.
of the International Congress of Mathematicians. Hyderabad, India, 2010. P. 1–23.

99. Никайдо Х. Выпуклые структуры и математическая экономика. М.: Мир, 1972.
100. Nesterov Yu. Excessive gap technique in nonsmooth convex minimization // SIAM Journal

of Optimization. 2005. V. 16, N 1. P. 235–249.
101. Nemirovski A. http://www2.isye.gatech.edu/˜nemirovs/
102. Juditsky A. http://ljk.imag.fr/membres/Anatoli.Iouditski/
103. Cox B., Juditsky A., Nemirovski A. Decomposition techniques for bilinear saddle point

problems and variational inequalities with affine monotone operators on domains given by
linear minimization oracles // e-print, 2015. arXiv:1506.02444

104. Nesterov Y., de Palma A. Stationary dynamic solutions in congested transportation
Networks: Summary and Perspectives // Networks Spatial Econ. 2003. N 3(3). P. 371–395.

105. Nesterov Yu., Shikhman V. Algorithmic models of market equilibrium // CORE
Discussion Paper 2013/66. 2013.

106. Ващенко М.П., Гасников А.В., Молчанов Е.Г., Поспелова Л.Я., Шананин
А.А. Вычислимые модели и численные методы для анализа тарифной политики же-
лезнодорожных грузоперевозок. М.: ВЦ РАН, 2014. arXiv:1501.02205

107. Гасников А.В. Заметка об эффективной вычислимости конкурентных равновесий в
транспортно-экономических моделях // Математическое моделирование. 2015. Т. 27,
№ 12. С. 121–136. arXiv:1410.3123

108. Бабичева Т.С., Гасников А.В., Лагуновская А.А., Мендель М.А. Двухстадийная мо-
дель равновесного распределения транспортных потоков // Труды МФТИ. 2015. Т. 7,
№ 3. С. 31–41. https://mipt.ru/upload/medialibrary/971/31-41.pdf

109. Гасников А.В., Гасникова Е.В., Мациевский С.В., Усик И.В. О связи моделей дис-
кретного выбора с разномасштабными по времени популяционными играми загрузок
// Труды МФТИ. 2015. Т. 7, № 4. С. 129–142. arXiv:1511.02390

110. Nemirovski A., Onn S., Rothblum U.G. Accuracy certificates for computational problems
with convex structure // Mathematics of Operation Research. 2010. V. 35, № 1. P. 52–78.

111. Nesterov Yu. New primal-dual subgradient methods for convex optimization
problems with functional constraints // International Workshop «Optimization
and Statistical Learning». January 11–16. France, Les Houches, 2015.
http://lear.inrialpes.fr/workshop/osl2015/program.html

112. Магарил-Ильяев Г.Г., Тихомиров В.М. Выпуклый анализ и его приложения. М.:
УРСС, 2011.

113. Guzman C., Nemirovski A. On lower complexity bounds for large-scale smooth convex
optimization // Journal of Complexity. 2015. V. 31. P. 1–14. arXiv:1307.5001

114. Немировский А.С., Нестеров Ю.Е. Оптимальные методы гладкой выпуклой опти-
мизации // ЖВМ и МФ. 1985. Т. 25, № 3. С. 356–369.

115. Harchaoui Z., Juditsky A., Nemirovski A. Conditional gradient algorithms for norm-
regularized smooth convex optimization // Math. Program. Ser. B. 2015. V. 152. P. 75–112.
http://www2.isye.gatech.edu/˜nemirovs/ccg_revised_apr02.pdf

116. Nesterov Yu. Universal gradient methods for convex optimization problems // Math.
Prog. 2015, V. 152, N 1. P. 381–404; CORE Discussion Paper 2013/63. 2013.



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 83

117. Гасников А.В., Двуреченский П.Е., Камзолов Д.И. Градиентные и прямые мето-
ды с неточным оракулом для задач стохастической оптимизации // Динамика си-
стем и процессы управления. Труды Международной конференции, посвященой 90-
летию со дня рождения академика Н.Н. Красовского. Екатеринбург, 15–20 сентября
2014. Издательство: Институт математики и механики УрО РАН им. Н.Н. Красовского
(Екатеринбург), 2015. С. 111–117. arXiv:1502.06259

118. Nesterov Yu. How to make the gradients small // OPTIMA 88. 2012. P. 10–11.
http://www.mathopt.org/Optima-Issues/optima88.pdf

119. Nesterov Yu. Gradient methods for minimizing composite functions // Math. Prog. 2013.
V. 140, N 1. P. 125–161.

120. Горнов А.Ю. Вычислительные технологии решения задач оптимального управления.
Новосибирск: Наука, 2009.

121. Lugosi G., Cesa-Bianchi N. Prediction, learning and games. New York: Cambridge
University Press, 2006.

122. Shalev-Shwartz S. Online learning and online convex optimization //
Foundation and Trends in Machine Learning. 2011. V. 4, N 2. P. 107–194.
http://www.cs.huji.ac.il/˜shais/papers/OLsurvey.pdf

123. Rakhlin A., Sridharan K. Statistical Learning Theory and Sequential Prediction // e-
print, 2015. http://stat.wharton.upenn.edu/˜rakhlin/book_draft.pdf

124. Hazan E. Introduction to online convex optimization // e-print, 2015.
http://ocobook.cs.princeton.edu/OCObook.pdf

125. Гасников А.В., Лагуновская А.А., Усманова И.Н., Федоренко Ф.А. Безградиентные
прокс-методы с неточным оракулом для негладких задач выпуклой стохастиче-
ской оптимизации на симплексе // Автоматика и телемеханика. 2016 (в печати).
arXiv:1412.3890

126. Гасников А.В., Крымова Е.А., Лагуновская А.А., Усманова И.Н., Федоренко Ф.А.
Стохастическая онлайн-оптимизация. Одноточечные и двухточечные нелинейные
многорукие бандиты. Выпуклый и сильно выпуклый случаи // Автоматика и
Телемеханика. 2016 (подана). arXiv:1509.01679

127. Duchi J.C., Jordan M.I., Wainwright M.J., Wibisono A. Optimal rates
for zero-order convex optimization: the power of two function evaluations
// IEEE Transaction of Information. 2015. V. 61, N 5. P. 2788–2806.
http://www.eecs.berkeley.edu/˜wainwrig/Papers/DucZero15.pdf

128. Поляк Б.Т., Цыбаков А.Б. Оптимальные порядки точности поисковых алгоритмов
стохастической оптимизации // Проб. перед. информ. 1990. Т. 26, № 2. С. 45–53.

129. Spall J.C. Introduction to stochastic search and optimization: estimation, simulation and
control. Wiley, 2003.

130. Agarwal A., Dekel O., Xiao L. Optimal algorithms for online convex optimization with
multi-point bandit feedback // Proceedings of 23 Annual Conference on Learning Theory.
2010. P. 28–40.

131. Граничин О.Н. Об одной стохастической рекуррентной процедуре при зависимых
помехах в наблюдении, использующей на входе пробные возмущения // Вестник
Ленинградского университета. 1989. Cер. 1. Bып. 1. С. 19–21.

132. Shamir O. An Optimal Algorithm for Bandit and Zero-Order Convex Optimization with
Two-Point Feedback // e-print, 2015. arXiv:1507.08752

133. Ledoux M. Concentration of measure phenomenon. Providence, RI, Amer. Math. Soc.,
2001 (Math. Surveys Monogr. V. 89).



84 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

134. Wright S.J. Coordinate descent algorithms // e-print, 2015. arXiv:1502.04759
135. Dempe S. Foundations of bilevel programming. Dordrecht: Kluwer Academic Publishers,

2002.
136. Bogolubsky L., Dvurechensky P., Gasnikov A., Gusev G., Nesterov Yu., Raigorodskii A.,

Tikhonov A., Zhukovskii M. Learning supervised PageRank with gradient-free optimization
methods // e-print, 2014. arXiv:1411.4282

137. Bogolubsky L., Dvurechensky P., Gasnikov A., Gusev G., Nesterov Yu., Raigorodskii
A., Tikhonov A., Zhukovskii M. Learning Supervised PageRank with Gradient-Based and
Gradient-Free Optimization Methods // e-print, 2016. arXiv:1603.00717

138. Nesterov Yu. Structural Optimization: New Perspectives for Increasing Efficiency of
Numerical Schemes // International conference «Optimization and Applications in Control
and Data Science» on the occasion of Boris Polyak’s 80th birthday, Moscow, May, 2015.
http://www.mathnet.ru/php/presentation.phtml?option_lang=rus&presentid=11909

139. http://www.mathnet.ru/php/conference.phtml?option_lang=rus&eventID=1&confid=699
140. Гасников А.В. «Алгебра» над эффективными методами выпуклой оптимизации (эле-

ментарное введение) // Математический кружок. ФУПМ МФТИ. 8 февраля 2014 г.
http://www.mathnet.ru/php/seminars.phtml?option_lang=rus&presentid=8395

141. Гасников А.В., Камзолов Д.И., Мендель М.С. Основные конструкции над алгорит-
мами выпуклой оптимизации и их приложения к получению новых оценок для сильно
выпуклых задач // Труды МФТИ. 2016. Т. 8 (в печати). arXiv:1603.07701

References

1. Polyak B.T. Gradient methods for minimization of functionals, solving equations and
inequalities. PhD Thesis. MSU, 1963.

2. Polyak B.T. Introduction to Optimization, New York, Optimization Software, 1987, 464
pages.

3. Khachiyan L.G. Selected works. Editor S. P. Tarasov. M.: MCCME, 2009.
4. Nemirovsky A.S., Yudin D.B. Problem Complexity and Method Efficiency in Optimization.

J. Wiley & Sons, New York, 1983.
5. Polyak B.T., Tsypkin Y.Z. Optimal pseudogradient algorithms of adaptation. Automation

and remote control. 1980. N 8. P. 74–84.
6. Tsypkin Y.Z., Poznyak A.S. Optimal search algorithms for stochastic optimization //

Doklady AN USSR. 1981. Т. 260, N 3. С. 550–553.
7. Nesterov Y.E. Efficient methods in nonlinear programming. M.: Radio and

Communications, 1989.
8. Nesterov Y., Nemirovsky A. Interior-point polynomial methods in convex programming.

Studies in applied mathematics. V. 13. SIAM, Philadelphia, 1994.
9. Nemirovski A. Lectures on modern convex optimization analysis,

algorithms, and engineering applications. Philadelphia: SIAM, 2013.
http://www2.isye.gatech.edu/˜nemirovs/Lect_ModConvOpt.pdf

10. Nesterov Y. Introductory lectures on convex optimization: A basic course. Springer Science
& Business Media, 2004.

11. Bubeck S. Convex optimization: algorithms and complexity // In Foundations and Trends
in Machine Learning. 2015. V. 8, N 3–4. P. 231–357. arXiv:1405.4980

12. http://cvxr.com/cvx/



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 85

13. http://www.cvxpy.org/en/latest/ ; https://github.com/cvxgrp/scs
14. Nesterov Y.E. Algorithmic convex optimization. D.Sc. Thesis, 2013, 367 p.

http://www.mathnet.ru/php/seminars.phtml?option_lang=rus&presentid=8313
15. Levitin E.S., Polyak B.T. Minimization methods in presence of constraints. Comp.Mat &

Mat. Phys. 1966. V. 6, N 5. P. 787–823.
16. Vasiliev F.P. Optimization methods. M.: MCCME, 2011.
17. Jaggi M. Revisiting Frank–Wolfe: Projection-free sparse convex optimization. Proceedings

of the 30th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013.
https://sites.google.com/site/frankwolfegreedytutorial/

18. Nesterov Yu. Complexity bounds for primal-dual methods minimizing the model of objective
function. CORE Discussion Papers. 2015/03. 2015.

19. Tseng P. On accelerated proximal gradient methods for convex-concave optimization. SIAM
J. Optim. 2008 (submitted). http://www.mit.edu/˜dimitrib/PTseng/papers.html

20. Neumaier A. OSGA: A fast subgradient algorithm with optimal complexity. e-print, 2014.
arXiv:1402.1125

21. Allen-Zhu Z., Orecchia L. Linear coupling: An ultimate unification of gradient and mirror
descent. e-print, 2014. arXiv:1407.1537

22. Ermoliev Y.M. Methods for stochastic programming. M.: Nauka, 1976.
23. Nurminsky E.A. Numerical methods for solving deterministic and stochastic minimax

problems. Kiev: Naukova dumka, 1979.
24. Shapiro A., Dentcheva D., Ruszczynski A. Lecture on stochastic programming. Modeling

and theory. MPS-SIAM series on Optimization, 2014.
25. Nesterov Y. Minimizing functions with bounded variation of subgradients. CORE Discussion

Papers. 2005/79. 2005.
26. Gasnikov A.V., Nesterov Y.E., Spokoiny V.G. On the efficiency of a randomized mirror

descent algorithm in online optimization problems. Comp.Mat & Mat. Phys. V. 55, N 2015.
P. 55–71. arXiv:1410.3118

27. Nesterov Y. Primal-dual subgradient methods for convex problems. Math. Program. Ser. B.
2009. V. 120(1). P. 261–283.

28. Polyak B.T. New method of stochastic approximation type. Automation and remote control.
1990. N 7. P. 98–107.

29. Polyak B.T., Juditsky A.B. Acceleration of stochastic approximation by averaging. SIAM
J. Control Optim. 1992. V. 30. P. 838–855.

30. Juditsky A., Lan G., Nemirovski A., Shapiro A. Stochastic approximation approach to
stochastic programming. SIAM Journal on Optimization. 2009. V. 19, N. P. 1574–1609.

31. Juditsky A., Nemirovski A. First order methods for nonsmooth convex large-scale
optimization, I, II. In: Optimization for Machine Learning. Eds. S. Sra, S. Nowozin, S.
Wright. MIT Press, 2012.

32. Sridharan K. Learning from an optimization viewpoint. PhD Thesis, Toyota Technological
Institute at Chicago, 2011. http://ttic.uchicago.edu/˜karthik/thesis.pdf

33. Granichin O.N., Polyak B.T. Randomized algorithms for estimation and optimization with
nearly arbitrary noise. M.: Nauka, 2003.

34. Spokoiny V. Parametric estimation. Finite sample theory // The Annals of Statistics. 2012.
V. 40, N 6. P. 2877–2909. arXiv:1111.3029v5

35. Ibragimov I.A., Khas’minski R.Z. Asymptotic theory of estimation. M.: Nauka, 1977.



86 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

36. Lacost-Julien S., Schmidt M., Bach F. A simpler approach to obtaining 𝑂 (1/𝑡) convergence
rate for the projected stochastic subgradient method. e-print, 2012. arXiv:1212.2002

37. Rakhlin A., Shamir O., Sridharan K. Making gradient descent optimal for strongly convex
stochastic optimization. ICML, 2012. arXiv:1109.5647

38. Juditsky A., Nesterov Yu. Deterministic and stochastic primal-dual subgradient algorithms
for uniformly convex minimization. Stoch. System. 2014. V. 4, N 1. P. 44–80.
arXiv:1401.1792

39. Hazan E., Kale S. Beyond the regret minimization barrier: Optimal algorithms for
stochastic strongly-convex optimization. JMLR. 2014. V. 15. P. 2489–2512.

40. Borovkov A.A., Borovkov K.A. Asymptotic analysis of random walks. V. 1. Slowly
decreasing jump distributions. M.: Fizmatlit, 2008.

41. Kim K., Nesterov Y., Skokov V. Cherkasski B. Efficient algorithms for differentiation and
extremal problem. Economics and nathematical methods. 1984. V. 20. P. 309–318.

42. Evtushenko Y. G. Optimization and fast automatic differentiation. M.: CC RAS, 2013.
43. Gasnikov A.V., Dvurechensky P.E., Usmanova I.N.About accelerated randomized methods.

Proceedings of MIPT. 2016. V. 8. (in print) arXiv:1508.02182
44. Anikin A.S., Gasnikov A.V., Gornov A.Y. Randomozation and sparsity in huge-scale

optimization problems on an example of Mirror Descent method. Proceedings of MIPT.
2016. V. 8. (in print) arXiv:1602.00594

45. Bubeck S., Cesa-Bianchi N. Regret analysis of stochastic and nonstochastic multi-armed
bandit problems. Foundation and Trends in Machine Learning. 2012. V. 5, N. P. 1–122.
http://www.princeton.edu/s̃bubeck/SurveyBCB12.pdf

46. Gasnikov A.V., Lagunovskaia A.A., Morozova L.E. On the connection between imitation
logit dynamics in population game theory and Mirror Descent method in online optimization
on an example of shortest path choice. Proceedings of MIPT. 2015. V. 7, N 4. P. 104–113.
arXiv:1511.02398

47. Agarwal A., Bartlett P.L., Ravikumar P., Wainwright M.J. Information-theoretic lower
bounds on the oracle complexity of stochastic convex optimization. IEEE Transaction of
Information. 2012. V. 58, N 5. P. 3235–3249. arXiv:1009.0571

48. Anikin A.S., Gasnikov A.V., Gornov A.Y., Kamzolov D.I., Maximov Y.V., Nesterov
Y.E.Efficient numerical methods for solving PageRank problem with double sparse matrices.
Proceedings of MIPT. 2015. V. 7, N 4. P. 74–94. arXiv:1508.07607

49. Nazin A.V., Polyak B.T. Randomized algorithm for finding eigenvector of stochastic matrix
in application to PageRank problem. Doklady Mathematics. 2009. V. 426, N 6. P. 734–737.

50. Nesterov Y.E. Efficiency of coordinate descent methods on large scale optimization problem.
SIAM Journal on Optimization. 2012. V. 22, N 2. P. 341–362.

51. Nesterov Y.E. Subgradient methods for huge-scale optimization problems. CORE Discussion
Paper 2012/2. 2012.

52. Gasnikov A.V., Dmitriev D.Y. On efficient randomized algorithms for finding the PageRank
vector. Comp.Mat & Mat. Phys. V. 55, N 3. 2015. P. 355–371. arXiv:1410.3120

53. Fercoq O., Richtarik P. Accelerated, parallel and proximal coordinate descent. SIAM Journal
on Optimization 2015 V. 25, N 4. 1997–2023 ; arXiv:1312.5799

54. Qu Z., Richtarik P. Coordinate Descent with Arbitrary Sampling I: Algorithms and
Complexity. e-print, 2014. arXiv:1412.8060

55. Anikin A., Dvurechensky P., Gasnikov A., Golov A., Gornov A., Maximov Yu., Mendel
M., Spokoiny V. Modern efficient numerical approaches to regularized regression problems



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 87

in application to traffic demands matrix calculation from link loads. Proceedings of
International conference ITAS-2015. Russia, Sochi, September, 2015. arXiv:1508.00858

56. Anikin A.S., Gasnikov A.V., Gornov A.Y.On non-accelerated efficient methods for solving
sparse problems of quadratic optimization. Proceedings of MIPT. 2016. V. 8 (in print).
arXiv:1602.01124

57. Nesterov Yu., Nemirovski A. On first order algorithms for 𝑙1 / nuclear norm minimization.
Acta Numerica. 2013. V. 22. P. 509–575.

58. Gasnikov A.V., Dorn Y.V., Nesterov Y.E., Shpirko S.V. On the three-stage version
of stable dynamic model. Math. Model. & Comp. Simul. 2014. V. 26:6. P. 34–70.
arXiv:1405.7630

59. Gasnikov A.V., Gasnikova E.V., Ershov E.I., Dvurechensky P.E., Lagunovskaia A.A.
Searching stochastic equilibriums in transport models of equilibrium flow distribution.
Proceedings of MIPT. 2015. V. 7, N 4. P. 114–128. arXiv:1505.07492

60. Gasnikov A.V., Dvurechensky P.E., Dorn Y.V., Maximov Y.V.. Computational methods
for equilibrium traffic flow distribution in Beckman’s and stable dynamics models. Math.
Model. & Comp. Simul. 2016. V. 28 (in print). arXiv:1506.00293

61. Gasnikov A.V., Dvurechensky P.E., Kamzolov D.I., Nesterov Y.E., Spokoiny V.G.,
Stetsyuk P.I., Suvorikova A.L., Chernov A.V. Searching for equilibrium in multi-
stage transport models. Proceedings of MIPT. 2015. V. 7, N 4. P. 143–155.
https://mipt.ru/upload/medialibrary/ffe/143-155.pdf

62. Gasnikov A.V., Dvurechensky P.E., Spokoiny V.G., Stetsyuk P.I., Suvorikova
A.L.Superposition of balancing method and universal gradient method for searching the
entropy-regularized Wasserstein barycenter and equilibrium in multi-stage transport models.
Proceedings of MIPT. 2016. V. 8 (in print). arXiv:1506.00292

63. Richtarik P. http://www.maths.ed.ac.uk/˜richtarik/
64. Shalev-Shwartz S. http://www.cs.huji.ac.il/˜shais/
65. Zhang T. http://www.stat.rutgers.edu/home/tzhang/
66. Le Roux N., Schmidt M., Bach F. A stochastic gradient method with an exponential

convergence rate for strongly-convex optimization with finite training sets. Advances in
Neural Information Processing Systems (NIPS). 2012. arXiv:1202.6258

67. Johnson B., Zhang T. Accelerating stochastic gradient descent using predictive
variance reduction. Advances in Neural Information Processing Systems (NIPS).
2013.http://www.stat.rutgers.edu/home/tzhang/pubs.html

68. Konecny J., Richtarik P. Semi-Stochastic gradient descent methods. e-print, 2013.
arXiv:1312.1666

69. Konecny J., Liu J., Richtarik P., Takac M. Mini-batch semi-stochastic gradient descent in
the proximal setting. e-print, 2015. arXiv:1504.04407

70. Lan G., Zhou Y. An optimal randomized incremental gradient methods. Technical Report,
Department of Industrial and Systems Engineering, University of Florida, July 7, 2015,
updated in October, 2015.http://www.ise.ufl.edu/glan/files/2015/10/OptRandom10-18.pdf

71. Lin Q., Lu Z., Xiao L. An Accelerated Randomized Proximal Coordinate Gradient Method
and its Application to Regularized Empirical Risk Minimization. SIAM J. Optim. 2015.
V. 25, N 4. P. 2244–2273.http://research.microsoft.com/pubs/228730/spdc_paper.pdf,
http://research.microsoft.com/pubs/258430/APCG_ERM_2015.pdf

72. Agarwal A., Bottou L. A lower bound for the optimization of finite sums // e-print, 2014.
arXiv:1410.0723



88 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

73. Shalev-Shwartz S., Zhang T. Accelerated proximal stochastic dual coordinate ascent for
regularized loss minimization // In Proceedings of the 31th International Conference on
Machine Learning, ICML 2014, Beijing, China, 21-26 June 2014. P. 64–72. arXiv:1309.2375

74. Zheng Q., Richtarik P., Zhang T. Randomized dual coordinate ascent with arbitrary
sampling // e-print, 2014. arXiv:1411.5873

75. Bartlett P.L., Mendelson S. Empirical minimization // Probability theory and related fields.
2006. V. 135(3). P. 311–334.

76. Nesterov Yu., Spokoiny V.Random gradient-free minimization of convex functions //
Foundations of Computational Mathematics, 2015; CORE Discussion Paper 2011/1. 2011.

77. Nesterov Y. Smooth minimization of non-smooth function. Math. Program. Ser. A. 2005.
V. 103, N 1. P. 127–152.

78. Devolder O., Glineur F., Nesterov Yu. First order methods of smooth convex optimization
with inexact oracle. Math. Progr. Ser. A. 2014. V. 146 (1–2). P. 37–75.

79. Devolder O. Exactness, inexactness and stochasticity in first-order methods for large-scale
convex optimization. CORE UCL, PhD thesis, March 2013.

80. D’Aspermont A. Smooth optimization with approximate gradient. SIAM Journal of
Optimization. 2008. V. 19(3). P. 1171–1183.

81. Baes M. Estimate sequence methods: extensions and approximations. IFOR Internal report.
ETH Zurich, Switzerland, 2009.

82. Devolder O., Glineur F., Nesterov Yu. First order methods with inexact oracle: the smooth
strongly convex case. CORE Discussion Paper 2013/16. 2013.

83. Devolder O., Glineur F., Nesterov Yu. Intermediate gradient methods for smooth convex
problems with inexact oracle. CORE Discussion Paper 2013/17. 2013.

84. Ghadimi S., Lan G. Optimal stochastic approximation algorithms for strongly convex
stochastic composite optimization I: A generic algorithmic framework. SIAM J. Optim.
2012. V. 22(4) P. 1469–1492.

85. Ghadimi S., Lan G. Optimal stochastic approximation algorithms for strongly convex
stochastic composite optimization II: Shrinking procedures and optimal algorithms. SIAM
J. Optim. 2013 V. 23(4). P. 2061–2089.

86. Gasnikov A.V., Dvurechensky P.E. Stochastic Intermediate Gradient Method for Convex
Problems. Doklady athematics. 2016. V. 467, N 2. P. 131–134.

87. Dvurechensky P., Gasnikov A. Stochastic Intermediate Gradient Method for Convex
Problems with Inexact Stochastic Oracle // Journal Optimization Theory and Applications.
2016. (submitted) arXiv:1411.2876

88. Ortega J. M. , Rheinboldt W. C. Iterative Solution of Nonlinear Equations in Several
Variables. Elsevier, 1970.

89. Evtushenko Y.G. Methods for solving extremal problems and their application in
optimization systems M.: Nauka, 1982.

90. Wu S., Boyd S., Candes E. A differential equation for modeling Nesterov’s
accelerated gradient method: Theory and insight. NIPS, December 2014.
http://stanford.edu/˜boyd/papers/ode_nest_grad.html

91. Wibisono A., Wilson A.C. On accelerated methods in optimization // e-print, 2015.
arXiv:1509.03616

92. Anikin A.S., Gasnikov A.V., Dvurechensky P.E., Tyurin A.I., Chernov A.V. Dual
approaches for problems of minimization of strongly convex functionals with simple
structure with affine constraints. Comp.Mat & Mat. Phys. 2016. V. 56. (submitted)
arXiv:1602.01686



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 89

93. Nesterov Yu., Shikhman V. Convergent subgradient methods for
nonsmooth convex minimization. // CORE Discussion Paper 2014/5. 2014.
https://www.uclouvain.be/cps/ucl/doc/core/documents/coredp2014_5web.pdf

94. Lin H., Mairal J., Harchaoui Z.A universal catalyst for first-order optimization. Advances
in Neural Information Processing Systems (NIPS), 2015. https://hal.inria.fr/hal-01160728

95. Lan G. Gradient sliding for composite optimization // Math. Progr. 2014 (submitted).
http://pwp.gatech.edu/guanghui-lan/wp-content/uploads/sites/330/2016/02/GS-
nonsmooth-stochastic6-11-submit.pdf

96. Lan G. http://www.ise.ufl.edu/glan/publications/
97. Gasnikov A.V., Gasnikov E.V., Nesterov Y.E., Chernov A.V. On efficient numerical

methods for entropy-linear programming problems. Comp.Mat & Mat. Phys. 2016. V. 56,
N 4. P. 523–534. arXiv:1410.7719

98. Spielman D. Algorithms, graph theory, and linear equations in Laplacian matrices. Proc. of
the International Congress of Mathematicians. Hyderabad, India, 2010. P. 1–23.

99. Nikaido H.. Convex structures and mathematical economics. M.: Mir, 1972.
100. Nesterov Yu. Excessive gap technique in nonsmooth convex minimization. SIAM Journal

of Optimization. 2005. V. 16, N 1. P. 235–249.
101. Nemirovski A. http://www2.isye.gatech.edu/˜nemirovs/
102. Juditsky A. http://ljk.imag.fr/membres/Anatoli.Iouditski/
103. Cox B., Juditsky A., Nemirovski A. Decomposition techniques for bilinear saddle point

problems and variational inequalities with affine monotone operators on domains given by
linear minimization oracles. e-print, 2015. arXiv:1506.02444

104. Nesterov Y., de Palma A. Stationary dynamic solutions in congested transportation
Networks: Summary and Perspectives. Networks Spatial Econ. 2003. N 3(3). P. 371–395.

105. Nesterov Yu., Shikhman V. Algorithmic models of market equilibrium. CORE Discussion
Paper 2013/66. 2013.

106. Vashenko M.P., Gasnikov A.V., Molchanov E.G., Pospelova L.Y., Shananin
A.A. Computable models and numerical schen=mts for analysis of tariff policy of railway
transportation. M.: CC RAS, 2014. arXiv:1501.02205

107. Gasnikov A.V. A note on efficient computability of competitive equilibrium in the
transport and economic models. Math. Model. & Comp. Simul. 2015. V. 27, N 12. P. 121–
136. arXiv:1410.3123

108. Babicheva T.S., Gasnikov A.V., Lagunovskaia A.A., Mendel M.A. Two-stage model of
equilibrium distribution of traffic flows.Proceedings of MIPT. 2015. V. 7, N 3. P. 31–41.
https://mipt.ru/upload/medialibrary/971/31-41.pdf

109. Gasnikov A.V., Gasnikov E.V., Matsievsky S.V., Usik I.V. On the relationship between
the discrete choice models with population games with different scale time loads.
Proceedings of MIPT. 2015. V. 7, N 4. P. 129–142. arXiv:1511.02390

110. Nemirovski A., Onn S., Rothblum U.G. Accuracy certificates for computational problems
with convex structure. Mathematics of Operation Research. 2010. V. 35, N 1. P. 52–78.

111. Nesterov Yu. New primal-dual subgradient methods for convex optimization
problems with functional constraints. International Workshop «Optimization
and Statistical Learning». January 11–16. France, Les Houches, 2015.
http://lear.inrialpes.fr/workshop/osl2015/program.html

112. Magaril-Ilyaev G.G., Tikhomirov V.M. Convex analysis and its applications. M.: URSS,
2011.



90 Информатика, вычисл. техника и управление ТРУДЫ МФТИ. 2016. Том 8, № 1

113. Guzman C., Nemirovski A. On lower complexity bounds for large-scale smooth convex
optimization. Journal of Complexity. 2015. V. 31. P. 1–14. arXiv:1307.5001

114. Nemirovski A.S., Nesterov Y.E. Optimal methods for smooth convex optimization.
Comp.Mat & Mat. Phys. 1985. V. 25, N 3. P. 356–369.

115. Harchaoui Z., Juditsky A., Nemirovski A. Conditional gradient algorithms for norm-
regularized smooth convex optimization // Math. Program. Ser. B. 2015. V. 152. P. 75–112.
http://www2.isye.gatech.edu/˜nemirovs/ccg_revised_apr02.pdf

116. Nesterov Yu. Universal gradient methods for convex optimization problems // Math.
Prog. 2015, V. 152, N 1. P. 381–404; CORE Discussion Paper 2013/63. 2013.

117. Gasnikov A.V., Dvurechensky P.E., Kamzolov D.I. Gradient and dirext methods with
inexact oracle for stochastic optimization problems. Dynamics of systems and management
processes. Proceedings of the International Conference dedicated to the 90th birthday of
academician N.N. Krasovsky. Ekaterinburg, 15–20 September 2014 Publisher: Institute
of Mathematics and Mechanics, Ural Branch of the Russian Academy of Sciences.
(Ekaterinburg), 2015. P. 111–117. arXiv:1502.06259

118. Nesterov Yu. How to make the gradients small. OPTIMA 88. 2012. P. 10–11.
http://www.mathopt.org/Optima-Issues/optima88.pdf

119. Nesterov Yu. Gradient methods for minimizing composite functions // Math. Prog. 2013.
V. 140, N 1. P. 125–161.

120. Gornov A.Y. Computation technologies for solving optimal control problems. Novosibirsk:
Nauka, 2009.

121. Lugosi G., Cesa-Bianchi N. Prediction, learning and games. New York: Cambridge
University Press, 2006.

122. Shalev-Shwartz S. Online learning and online convex optimization //
Foundation and Trends in Machine Learning. 2011. V. 4, N 2. P. 107–194.
http://www.cs.huji.ac.il/˜shais/papers/OLsurvey.pdf

123. Rakhlin A., Sridharan K. Statistical Learning Theory and Sequential Prediction. e-print,
2015. http://stat.wharton.upenn.edu/˜rakhlin/book_draft.pdf

124. Hazan E. Introduction to online convex optimization. e-print, 2015.
http://ocobook.cs.princeton.edu/OCObook.pdf

125. Gasnikov A.V., Lagunovskaia A.A., Usmanova I.N., Fedorenko F.A. Gradient-free prox-
methods with inexact oracle for non-smooth problems of convez stochastic optimization
problems on a simplex. Automation and remote control. 2016. (in print) arXiv:1412.3890

126. Gasnikov A.V., Krymova E.A., Lagunovskaia A.A., Usmanova I.N., Fedorenko
F.A.Stochastic onlineo ptimization. Single-point and multi-point non-linear multi-armed
bandits. The convex and strongly convex cases. Automation and remote control. 2016.
(submitted) arXiv:1509.01679

127. Duchi J.C., Jordan M.I., Wainwright M.J., Wibisono A. Optimal rates
for zero-order convex optimization: the power of two function evaluations.
IEEE Transaction of Information. 2015. V. 61. № 5. P. 2788–2806.
http://www.eecs.berkeley.edu/˜wainwrig/Papers/DucZero15.pdf

128. Polyak B.T., Csybakov A.B. Optimal order of accuracy of search algorithms in stochastic
optimization. Prob. Pered. Inf. 1990. V. 26, N 2. P. 45–53.

129. Spall J.C. Introduction to stochastic search and optimization: estimation, simulation and
control. Wiley, 2003.

130. Agarwal A., Dekel O., Xiao L. Optimal algorithms for online convex optimization with
multi-point bandit feedback. Proceedings of 23 Annual Conference on Learning Theory.
2010. P. 28–40.



ТРУДЫ МФТИ. 2016. Том 8, № 1 А.В. Гасников, П.Е. Двуреченский, Ю.Е. Нестеров 91

131. Granichin O.N. On one stochastic recurrent procedure with dependent noise in the
observation using trial observations as input. Vestnik Leningrad University. 1989. V. 1.
I. 1. P. 19–21.

132. Shamir O. An Optimal Algorithm for Bandit and Zero-Order Convex Optimization with
Two-Point Feedback. e-print, 2015. arXiv:1507.08752

133. Ledoux M. Concentration of measure phenomenon. Providence, RI, Amer. Math. Soc.,
2001 (Math. Surveys Monogr. V. 89).

134. Wright S.J. Coordinate descent algorithms. e-print, 2015. arXiv:1502.04759
135. Dempe S. Foundations of bilevel programming. Dordrecht: Kluwer Academic Publishers,

2002.
136. Bogolubsky L., Dvurechensky P., Gasnikov A., Gusev G., Nesterov Yu., Raigorodskii A.,

Tikhonov A., Zhukovskii M. Learning supervised PageRank with gradient-free optimization
methods. e-print, 2014. arXiv:1411.4282

137. Bogolubsky L., Dvurechensky P., Gasnikov A., Gusev G., Nesterov Yu., Raigorodskii
A., Tikhonov A., Zhukovskii M. Learning Supervised PageRank with Gradient-Based and
Gradient-Free Optimization Methods. e-print, 2016. arXiv:1603.00717

138. Nesterov Yu. Structural Optimization: New Perspectives for Increasing Efficiency of
Numerical Schemes. International conference «Optimization and Applications in Control
and Data Science» on the occasion of Boris Polyak’s 80th birthday, Moscow, May, 2015.
http://www.mathnet.ru/php/presentation.phtml?option_lang=rus&presentid=11909

139. http://www.mathnet.ru/php/conference.phtml?option_lang=rus&eventID=1&confid=699
140. Gasnikov A.V. «Algebra» on efficient methods for convex optimization (basic

introduction)
http://www.mathnet.ru/php/seminars.phtml?option_lang=rus&presentid=8395

141. Gasnikov A.V., Kamzolov D.I., Mendel M.A. The basic design of the convex optimization
algorithms and their applications to obtain new estimates for strongly convex problems.
Proceedings of MIPT. 2016. V. 8 (in print). arXiv:1603.07701

Поступила в редакцию 07.03.2016