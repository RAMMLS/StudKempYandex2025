Программные продукты и системы / Software & Systems                1 (30) 2017 

УДК 004.048                     Дата подачи статьи: 19.07.16 
DOI: 10.15827/0236-235X.030.1.085-099                2017. Т. 30. № 1. С. 85–99 

МЕТОДЫ АВТОМАТИЧЕСКОЙ КЛАССИФИКАЦИИ ТЕКСТОВ 
 

Т.В. Батура, к.ф.-м.н., ведущий научный сотрудник, tatiana.v.batura@gmail.com 
(Новосибирский государственный университет, ул. Пирогова, 2, г. Новосибирск, 630090, Россия); 

старший научный сотрудник (Институт систем информатики им. А.П. Ершова СО РАН,  
просп. Лаврентьева, 6, г. Новосибирск, 630090, Россия) 

 
 

 

Классификация текстов является одной из основных задач компьютерной лингвистики, поскольку к ней сводится 
ряд других задач: определение тематической принадлежности текстов, автора текста, эмоциональной окраски выска-
зываний и др. Для обеспечения информационной и общественной безопасности большое значение имеет анализ в те-
лекоммуникационных сетях контента, содержащего противоправную информацию (в том числе данные, связанные с 
терроризмом, наркоторговлей, подготовкой протестных движений или массовых беспорядков).  

Данная статья представляет собой обзор методов классификации текстов, целями которого являются сравнение 
современных методов решения задачи классификации текстов, обнаружение тенденций развития данного направле-
ния, а также выбор наилучших алгоритмов для применения в исследовательских и коммерческих задачах. 

Широко известный современный подход к классификации основывается на методах машинного обучения. В дан-
ной статье описываются наиболее распространенные алгоритмы построения классификаторов, проводимые с ними 
эксперименты и результаты этих экспериментов. Обзор подготовлен на основе выполненных за 2011–2016 гг. научных 
работ, находящихся в открытом доступе в сети Интернет и опубликованных в авторитетных журналах или в трудах 
международных конференций, высоко оцениваемых научным сообществом. 

В статье произведены анализ и сравнение качества работы различных методов классификации по таким характе-
ристикам, как точность, полнота, время работы алгоритма, возможность работы алгоритма в инкрементном режиме, 
количество предварительной информации, необходимой для классификации, независимость от языка. 

Ключевые слова: классификация текстов, анализ текстовой информации, обработка данных, машинное обуче-
ние, нейронные сети, качество классификации. 

 

Прогресс в области микроэлектроники и инфор- представления самих документов и способах 
мационных технологий обусловил широкое рас- оценки качества алгоритмов. На сегодняшний день 
пространение обработки в реальном времени боль- разработано большое количество методов и их раз-
ших потоков данных. Например, многие простые личных вариаций для классификации текстов. Каж-
операции повседневной жизни, такие как использо- дая группа методов имеет свои преимущества и не-
вание кредитной карты или телефона, требуют ав- достатки, области применения, особенности и 
томатизированного создания, анализа и обработки ограничения. 
различных данных. Поскольку эти операции часто Особый интерес представляет случай, когда 
выполняются большим числом участников, необ- данные поступают в виде потока, например в теле-
ходимы распределенные и массовые потоки дан- коммуникационных сетях. Определенные трудно-
ных. Точно так же социальные сети содержат боль- сти возникают из-за того, что обучение модели все-
шое количество специфических сетевых и тексто- гда основывается на совокупности свойств набора 
вых потоков данных. Поэтому актуальна проблема документов. Эти совокупные свойства могут изме-
создания моделей и алгоритмов, позволяющих эф- няться с течением времени, и при построении по-
фективно обрабатывать большие потоки данных, токового классификатора необходимо учитывать 
особенно в условиях ограниченных временных и возможные изменения исходного распределения 
других ресурсов. данных [1]. Желательно, чтобы выбранный метод 

Для обеспечения информационной и обще- мог поддерживать инкрементное обучение, то есть 
ственной безопасности важное значение имеет ана- чтобы классификатор обучался на каждом от-
лиз в телекоммуникационных сетях контента, со- дельно взятом образце в режиме реального вре-
держащего противоправную информацию (в том мени. При инкрементном обучении обучающие 
числе данных, связанных с терроризмом, наркотор- примеры поступают последовательно в процессе 
говлей, сетевым экстремизмом, подготовкой про- работы алгоритма, так что классификатор должен 
тестных движений или массовых беспорядков).  постоянно корректировать результаты обучения и 

Целями данного обзора являются сравнение со- дообучаться. При неинкрементном обучении вся 
временных методов решения задачи классифика- обучающая выборка предоставляется сразу полно-
ции текстов, обнаружение тенденций развития дан- стью. Ясно, что в случае инкрементного обучения 
ного направления, а также выбор наилучших алго- поведение классификатора в процессе работы ме-
ритмов для применения в исследовательских и няется, что уменьшает его предсказуемость и мо-
коммерческих задачах. жет осложнить настройку системы. В то же время 

Методы классификации текстов лежат на стыке инкрементное обучение делает систему гораздо бо-
двух областей – информационного поиска и ма- лее гибкой, адаптируемой к изменяющимся усло-
шинного обучения. Их сходство состоит в способах виям. 

 85 



Программные продукты и системы / Software & Systems                1 (30) 2017 

Особенности процесса классификации в потоке тестовой выборкой примеров T. При этом необхо-
связаны еще с тем, что не всегда удается контроли- димо, чтобы выполнялись условия  
ровать скорость поступления данных. Некоторые L  T = ,          (4) 
классы документов могут встречаться в потоке  = L  T  C  D.        (5) 
только время от времени. Обнаружить этот редкий Для множества примеров  известны значения 
класс бывает непросто, и классификация текстов в целевой функции . 
таких случаях становится чрезвычайно сложной за- Если в задаче каждому документу d  D может 
дачей. 

соответствовать только одна категория c  C, то 
Сравнение методов построения классификато-

имеет место однозначная классификация, а если 
ров является довольно сложной задачей по при-

произвольное количество категорий, то многознач-
чине того, что разные входные данные могут при-

ная классификация. 
водить к различным результатам. Поэтому необхо-

Частным случаем однозначной классификации 
димо осуществить их программную реализацию и является бинарная классификация, когда коллек-
вычисление эффективности на одинаковых набо- цию документов нужно разбить на две непересека-
рах документов для обучения и тестирования. 

ющиеся категории. Например, задача определения 
 тональности высказываний (положительная или 

Формальная постановка задачи  отрицательная окраска) или задача обнаружения 
классификации текстов спама (является сообщение спамом или нет) реша-

 ется при помощи бинарного классификатора. 
Следует отличать классификацию от кластери- Решение задачи классификации состоит из че-

зации. При классификации документов категории тырех последовательных этапов: 
определены заранее, при кластеризации они не за-  предобработка и индексация документов; 
даны и даже информация об их количестве может  уменьшение размерности пространства при-
отсутствовать. знаков; 

Формально постановку задачи классификации  построение и обучение классификатора с по-
можно записать следующим образом.  мощью методов машинного обучения; 

Имеются множество документов D = {d1, …,  оценка качества классификации. 
d|D|} и множество возможных категорий (классов) При выборе конкретного алгоритма классифи-
C = {c1, …, c|C|}. Неизвестная целевая функция : кации следует учитывать особенности каждого из 
D  C  {0, 1} задается формулой них. По-прежнему остается нерешенным вопрос 

 определения набора классифицирующих призна-
0,  если  d  c ,

  j i
Ф d , c 

j i       (1) ков, их количества и способов вычисления весов.  
1,  если d  c .

j i В алгоритмах глубокого обучения точность класси-
Требуется построить классификатор , макси- фикации сильно зависит от наличия обучающей 

мально близкий к .  выборки подходящего размера. Подготовка такой 

В такой постановке задачи следует отметить, выборки – очень трудоемкий процесс. До сих пор 

что о категориях и документах нет никакой допол- остается также открытой проблема подбора пара-

нительной информации, кроме той, которую метров некоторых алгоритмов на этапе обучения.  

можно извлечь из самого документа. Далее подробно рассмотрен каждый из этапов, 

Если классификатор выдает точный ответ: описаны различные алгоритмы построения класси-
фикаторов, проводимые с ними эксперименты и ре-

: D  C  {0, 1},        (2) 
зультаты этих экспериментов. 

то классификация называется точной.  
Если классификатор определяет степень подо- Описание методов классификации 

бия (Categorization Status Value) документа:  
CSV: D  [0, 1],         (3) На рисунке 1 представлена общая схема про-

то классификация называется пороговой. цесса классификации. Рассмотрим каждый из его 
В общем случае процесс обучения с учителем этапов. 

(обучение по прецедентам, supervised learning) за- Предобработка и индексация документов. 
ключается в следующем. Системе предъявляется Предварительная обработка текста включает в себя 
набор примеров, связанных с какой-либо заранее токенизацию, удаление функциональных слов (се-
неизвестной закономерностью. Этот набор иногда мантически нейтральных слов, таких как союзы, 
называют обучающей выборкой L. Ее используют предлоги, артикли и пр.). Далее осуществляется 
для обучения классификатора и определения зна- морфологический анализ (производятся разметка 
чения его параметров, при которых классификатор по частям речи и стемматизация). Это позволяет 
выдает лучший результат. Далее в системе выраба- значительно сократить размерность пространства. 
тываются решающие правила, с помощью которых В результате в качестве признаков документа вы-
происходит разделение множества примеров на за- ступают все значимые слова, встречающиеся в до-
данные классы. Качество разделения проверяется кументе. 

86  



Программные продукты и системы / Software & Systems                1 (30) 2017 

Построение 
Выбор Оценка 

Предобработка Индексация и обучение 
признаков качества

классификатора

 TF-IDF   NB
 Bag-of-words  LSA   KNN
 Word2vec  PMI   DT
 n-grams  CRF   SVM

 IG   ANN
 

 

Рис. 1. Этапы процесса автоматической классификации текстов 
 

Fig. 1. The steps of text automatic classification process 

Индексация документов – это построение неко- получали слова с высокой частотой в пределах кон-
торой числовой модели текста, которая переводит кретного документа и с низкой частотой употреб-
текст в удобное для дальнейшей обработки пред- лений в других документах. 
ставление. Вычисляется частота термина TF (term frequen-

Например, модель «мешка слов» (bag-of-words) cy) – оценка важности слова в пределах одного до-
позволяет представить документ в виде многомер- кумента d по формуле 
ного вектора слов и их весов в документе [2]. Дру- TF = nt,d / nd,          (6) 
гими словами, каждый документ – это вектор  где nt, d – количество употреблений слова t в доку-
в многомерном пространстве, координаты кото- менте d; nd – общее число слов в документе d. 
рого соответствуют номерам слов, а значения коор- Обратная частота документа IDF (inverse 
динат – значениям весов. document frequency) – инверсия частоты, с которой 

Другая распространенная модель индексации – слово встречается в документах коллекции. IDF 
Word2vec [3]. Она представляет каждое слово в уменьшает вес общеупотребительных слов по фор-
виде вектора, который содержит информацию о муле 
контекстных (сопутствующих) словах. IDF = log(|D| / Dt),         (7) 

Еще одна модель индексации основана на учете где |D| – общее количество документов в коллек-
n-грамм [2], то есть последовательностей из сосед- ции; Dt  – количество всех документов, в которых 
них символов. встречается слово t. 

Очевидно, что для обучающих и тестовых доку- Итоговый вес термина в документе относи-
ментов должен применяться один и тот же метод тельно всей коллекции документов вычисляется по 
индексации. формуле 

Уменьшение размерности пространства 
Vt, d = TF  IDF.         (8) 

признаков. Вычислительная сложность различных 
Следует отметить, что по формуле (8) оценива-

методов классификации напрямую зависит от раз-
ется значимость термина только с точки зрения ча-

мерности пространства признаков. Поэтому для 
стоты вхождения в документ, без учета порядка 

эффективной работы классификатора часто прибе-
следования терминов в документе и их лексиче-

гают к сокращению числа используемых признаков 
ской сочетаемости. 

(терминов). 
Для уменьшения размерности пространства 

За счет уменьшения размерности пространства 
терминов также применяют латентно-семантиче-

терминов можно снизить эффект переобучения – 
ский анализ (LSA), использующий сингулярное 

явление, при котором классификатор ориентиру-
разложение матриц [3, 6], поточечную взаимную 

ется на случайные или ошибочные характеристики 
информацию (PMI) [6, 7] (разновидность ассоциа-

обучающих данных, а не на важные и значимые. 
тивной меры), условные случайные поля (CRF) [8] 

Переобученный классификатор хорошо работает 
(обобщение скрытой марковской модели). Встре-

на тех экземплярах, на которых он обучался, и зна-
чаются исследования [4, 9], в которых применя-

чительно хуже на тестовых данных. Чтобы избе-
ются статистические критерии и относительная эн-

жать переобучения, количество обучающих приме-
тропия для вероятностных распределений, называ-

ров должно быть соразмерно числу используемых 
емая коэффициентом усиления информации, или 

терминов. В некоторых случаях сокращение раз-
дивергенцией Кульбака–Лейблера. 

мерности пространства признаков в 10 раз (и даже 
в 100) может приводить лишь к незначительному Построение и обучение классификатора с по-

ухудшению работы классификатора. мощью методов машинного обучения. Можно 

Существуют несколько способов определения выделить следующие методы классификации: 

веса признаков документа. Наиболее распростра-  вероятностные (например NB [4, 6]); 
ненный – вычисление функции TF-IDF [2, 4, 5]. Его  метрические (например KNN [9]); 
основная идея состоит в том, чтобы больший вес  логические (например DT [6, 10]); 

 87 



Программные продукты и системы / Software & Systems                1 (30) 2017 

 линейные (например SVM [4, 5, 6, 9]; логи- дам классификации. Чтобы найти категорию, соот-
стическая регрессия [2, 8, 10]); ветствующую документу d, классификатор сравни-

 методы на основе искусственных нейрон- вает d со всеми документами из обучающей вы-
ных сетей (например FFBP [4, 10], RNN [8], DAN2 борки L, то есть для каждого dz  L вычисляется 
[9], CNN [2]). расстояние (dz , d). Далее из обучающей выборки 

Далее обобщенно описываются эти методы, выбираются k документов, ближайших к d. Со-
указываются преимущества и недостатки каждого гласно методу k ближайших соседей, документ d 
из них. считается принадлежащим тому классу, который 

Метод Байеса (Naive Bayes, NB) относится к является наиболее распространенным среди сосе-
вероятностным методам классификации. дей данного документа, то есть для каждого класса 

Пусть P(ci|d) – вероятность того, что документ, ci вычисляется функция ранжирования: 
представленный вектором d = (t1, …, tn), соответ-
ствует категории ci для i = 1, …, |C|. Задача класси- CSV (d )   (d , d ) (d , c )

z z i ,   (12) 
d zLk (d )

фикатора заключается в том, чтобы подобрать та-
кие значения ci и d, при которых значение вероят- где Lk (d) – ближайшие k документов из L к d; 

ности P(ci|d) будет максимальным: (dz , ci ) – известные величины, уже расклассифи-

CSV (d )  arg max P(c | d ).      (9) цированные по категориям документы обучающей 
i

ciC выборки. 
Для вычисления значений P(ci|d) пользуются Преимущества метода: 

теоремой Байеса:  возможность обновления обучающей вы-
P(c )Pd | c  борки без переобучения классификатора; 

Pc | d   i i
i ,      (10) 

P(d )  устойчивость алгоритма к аномальным вы-
бросам в исходных данных; 

где P(ci) – априорная вероятность того, что доку-
 относительно простая программная реализа-

мент отнесен к категории ci; P(d | ci) – вероятность 
ция алгоритма; 

найти документ, представленный вектором d = (t1, 
…, tn), в категории ci; P(d) – вероятность того, что  легкая интерпретируемость результатов ра-

произвольно взятый документ можно представить боты алгоритма; 

в виде вектора признаков d = (t1, …, tn). 
 хорошее обучение в случае с линейно нераз-

По сути P(ci) является отношением количества делимыми выборками. 

документов из обучающей выборки L, отнесенных Недостатки метода: 

в категорию ci , к количеству всех документов из L.  репрезентативность набора данных, исполь-

P(d) не зависит от категории ci, а значения t1, …, зуемого для алгоритма; 

t  высокая зависимость результатов классифи-
n заданы заранее, поэтому знаменатель – это кон-

станта, не влияющая на выбор наибольшего из зна- кации от выбранной метрики; 

чений P(ci|d).  большая длительность работы из-за необ- 
Вычисление P(d | ci) затруднительно из-за боль- ходимости полного перебора обучающей выбор- 

шого количества признаков t1, …, tn , поэтому де- ки; 
лают «наивное» предположение о том, что любые  невозможность решения задач большой раз-
две координаты, рассматриваемые как случайные мерности по количеству классов и документов. 
величины, статистически не зависят друг от друга. Метод деревьев решений (Decision Trees, DT) 
Тогда можно воспользоваться формулой относится к логическим методам классификации.  

n Деревом решений называют ациклический 
P d | c  P(t | c )

i  k i .      (11) граф, по которому производится классификация 
k 1 объектов (в нашем случае текстовых документов), 

Далее все вероятности подсчитываются по ме- описанных набором признаков. Каждый узел де-
тоду максимального правдоподобия. рева содержит условие ветвления по одному из 

Преимущества метода: признаков. У каждого узла столько ветвлений, 
 высокая скорость работы; сколько значений имеет выбранный признак.  
 поддержка инкрементного обучения; В процессе классификации осуществляются после-
 относительно простая программная довательные переходы от одного узла к другому в 

реализация алгоритма; соответствии со значениями признаков объекта. 
 легкая интерпретируемость результатов Классификация считается завершенной, когда до-

работы алгоритма. стигнут один из листьев (конечных узлов) дерева. 
Недостатки метода: относительно низкое ка- Значение этого листа определит класс, которому 

чество классификации и неспособность учитывать принадлежит рассматриваемый объект. На прак-
зависимость результата классификации от сочета- тике обычно используют бинарные деревья реше-
ния признаков. ний, в которых принятие решения перехода по ре-

Метод k ближайших соседей (k Nearest брам осуществляется простой проверкой наличия 
Neighbors, KNN) относится к метрическим мето- признака в документе. Если значение признака 

88  



Программные продукты и системы / Software & Systems                1 (30) 2017 

меньше определенного значения, выбирается одна Преимущества метода: 
ветвь, если больше или равно, другая.  относительно простая программная реализа-

В отличие от остальных подходов, представлен- ция алгоритма; 
ных ранее, подход, использующий деревья реше-  легкая интерпретируемость результатов ра-
ний, относится к символьным (то есть нечисловым) боты алгоритма. 
алгоритмам. Недостатки метода: неустойчивость алго-

Алгоритм построения бинарного дерева реше- ритма по отношению к выбросам в исходных дан-
ний состоит из следующих шагов. ных и большой объем данных для получения точ-

Создается первый узел дерева, в который вхо- ных результатов. 
дят все документы, представленные всеми имею- Метод опорных векторов (Support Vector 
щимися признаками. Размер вектора признаков для Machine, SVM) является линейным методом клас-
каждого документа равен n, так как d = (t1, …, tn). сификации. В настоящее время этот метод счи- 

Для текущего узла дерева выбираются наиболее тается одним из лучших. Рассмотрим множество 
подходящий признак tk и его наилучшее погранич- документов, которые необходимо расклассифици-
ное значение vk. ровать. Сопоставим ему множество точек в про-

На основе пограничного значения выбранного странстве размерности |D|. 
признака производится разделение обучающей вы- Выборку точек называют линейно разделимой, 
борки на две части. Далее выбранный признак не если принадлежащие разным классам точки мож- 
включается в описание фрагментов в этих частях, но разделить с помощью гиперплоскости (в двух-
то есть фрагменты в частях представляются векто- мерном случае гиперплоскостью является прямая 
ром с размерностью n – 1. линия). Очевидный способ решения задачи в таком 

Образовавшиеся подмножества обрабатыва- случае – провести прямую так, чтобы по одну  
ются аналогично до тех пор, пока в каждом из них сторону от нее лежали все точки одного класса, а 
не останутся документы только одного класса или по другую – все точки другого класса. Тогда для 
признаки для различения документов. классификации неизвестных точек достаточно бу-

Когда говорят о выборе наиболее подходящего дет посмотреть, с какой стороны прямой они ока-
признака, как правило, подразумевают частотный жутся. 
признак, то есть любой признак текста, допуска- В общем случае можно провести бесконечное 
ющий возможность нахождения частоты его появ- множество гиперплоскостей (прямых), удовлетво-
ления в тексте. Лучшим для разделения является ряющих нашему условию. Ясно, что лучше всего 
признак, дающий максимальную на данном шаге выбрать прямую, максимально удаленную от име-
информацию о категориях. Таким признаком для ющихся точек. В методе опорных векторов рассто-
текста может являться, например, ключевое слово. янием между прямой и множеством точек счита-
С этой точки зрения любой частотный признак ется расстояние между прямой и ближайшей к ней 
можно считать переменной. Тогда выбор между точкой из множества. Именно такое расстояние и 
двумя наиболее подходящими признаками сво- максимизируется в данном методе. Гиперплос-
дится к оценке степени связанности двух перемен- кость, максимизирующая расстояние до двух  
ных. Поэтому для выбора подходящего признака параллельных гиперплоскостей, называется разде-
на практике применяют различные критерии про- ляющей (на рисунке 2 обозначена буквой L). Бли-
верки гипотез, то есть критерии количественной жайшие к параллельным гиперплоскостям точки 
оценки степени связанности двух переменных, по- называются опорными векторами (рис. 2), через 
ставленных во взаимное соответствие, где 0 соот- них проходят пунктирные линии. Другими сло-
ветствует полной независимости переменных, а 1 – вами, алгоритм работает в предположении, что, 
их максимальной зависимости. чем больше разница или расстояние между этими 

Для исследования связи между двумя перемен- параллельными гиперплоскостями, тем меньше бу-
ными удобно использовать представление совмест- дет средняя ошибка классификатора, так как мак-
ного распределения этих переменных в виде таб- симизация зазора между классами способствует 
лицы сопряженности (факторной таблицы, или более уверенной классификации. 
матрицы частот появления признаков). Она явля- На практике структура данных зачастую бывает 
ется наиболее универсальным средством изучения неизвестна и очень редко удается построить разде-
статистических связей, так как в ней могут быть ляющую гиперплоскость, а значит, невозможно  
представлены переменные с любым уровнем изме- гарантировать линейную разделимость выборки. 
рения. Таблицы сопряженности часто использу- Могут существовать такие документы, которые ал-
ются для проверки гипотезы о наличии связи горитм отнесет к одному классу, а в действитель-
между двумя признаками при помощи различных ности они должны относиться к противополож-
статистических критериев: критерия Фишера (точ- ному. Такие данные называются выбросами, они 
ного теста Фишера), критерия согласия Пирсона создают погрешность метода, поэтому было бы 
(критерия хи-квадрат), критерия Крамера, крите- лучше их игнорировать. В этом заключается суть 
рия Стьюдента (t-критерия Стьюдента) и пр. проблемы линейной неразделимости. 

 89 



Программные продукты и системы / Software & Systems                1 (30) 2017 

Логистическая регрессия (logit model, logistic 
regression) является линейным методом классифи-

L
кации. Этот метод используется для предсказания 
вероятности возникновения некоторого события по 
значениям множества признаков. Для этого вво-
дятся так называемая зависимая переменная y,  
которая может принимать лишь одно из двух зна-
чений – как правило, это числа 0 (событие не про-
изошло) и 1 (событие произошло), и множество  
независимых переменных (также называемых при-
знаками, предикторами или регрессорами) – веще-
ственных x1, …, xn, на основе значений которых 
требуется вычислить вероятность принятия того 
или иного значения зависимой переменной. В слу-
чае классификации документов роль зависимой пе-
ременной выполняет категория ci, а роль независи-
мых переменных – набор документов d1, …, dn.  

 Для улучшения обобщающей способности ал-
 

Рис. 2. Разделяющая гиперплоскость  горитма, то есть для уменьшения эффекта переобу-

в методе опорных векторов чения, на практике часто рассматривается логисти-
 ческая регрессия с регуляризацией. Регуляризация 

Fig. 2. A separating hyperplane in the Support  заключается в том, что вектор параметров  рас-
Vector Machines 

сматривается как случайный вектор с некоторой за-
данной априорной плотностью распределения p(). 

Выборку называют линейно неразделимой, ес- Для обучения модели вместо метода наибольшего 
ли точки, принадлежащие разным классам, нельзя правдоподобия при этом используется метод мак-
разделить с помощью гиперплоскости. Когда такой симизации апостериорной оценки, то есть должны 
разделяющей гиперплоскости не существует, необ- быть найдены параметры , максимизирующие ве-
ходимо перейти от исходного пространства при- n

знаков документов к новому, в котором обучающая личину:  P{c | d ,}  p().       (13) 
i i

выборка окажется линейно разделимой. Для этого i1

каждое скалярное произведение необходимо заме- Мультиномиальная логистическая регрессия – 

нить на некоторую функцию, отвечающую опреде- это общий случай модели логистической регрес-

ленным требованиям. Например, можно назначать сии, в которой зависимая переменная имеет более 

некий штраф за каждый неверно расклассифициро- двух категорий. В модели мультиномиальной логи-

ванный документ. Эту функцию называют ядром. стической регрессии для каждой категории зависи-

Замена скалярного произведения функцией-ядром мой переменной строится уравнение бинарной ло-

позволяет перейти к другому пространству призна- гистической регрессии. При этом одна из катего-

ков, где данные уже будут разделимы. рий зависимой переменной становится опорной, а 

В случае линейной неразделимости проблема все другие категории сравниваются с ней. Уравне-

поиска оптимальной разделяющей гиперплоскости ние мультиномиальной логистической регрессии 

сводится к задаче, эквивалентной поиску седловой прогнозирует вероятность принадлежности к каж-

точки функции Лагранжа с условиями дополняю- дой категории зависимой переменной по значе-

щей нежесткости. Полученная система уравнений ниям независимых переменных. 

решается методами квадратичного программиро- Вообще говоря, логистическую регрессию 

вания. Это уже чисто вычислительная задача. можно представить в виде однослойной нейронной 

Этот вариант алгоритма называют алгоритмом сети с сигмоидальной функцией активации, веса 

с мягким зазором (soft-margin SVM), тогда как в ли- которой – коэффициенты логистической регрес-

нейно разделимом случае говорят о жестком зазоре сии, а вес поляризации – константа регрессионного 

(hard-margin SVM). уравнения: 

Преимущества метода: P{y = 1| x} = f (z).        (14) 

 один из наиболее качественных методов; Преимущества метода: 
 возможность работы с небольшим набором  является одним из наиболее качественных; 

данных для обучения;  поддерживает инкрементное обучение; 
 сводимость к задаче выпуклой оптимизации,  имеет относительно простую программную 

имеющей единственное решение. реализацию алгоритма. 
Недостатки метода: сложная интерпретируе- Недостатки метода: сложная интерпретируе-

мость параметров алгоритма и неустойчивость по мость параметров алгоритма и неустойчивость по 
отношению к выбросам в исходных данных. отношению к выбросам в исходных данных. 

90  



Программные продукты и системы / Software & Systems                1 (30) 2017 

1    .  .  .  .  .    m G1 Gk-1 Gk

1
.
.
.

. . . . I F0 F1 Fk-1 Fk
.
.

n

H1 Hk-1 Hk

Входная матрица

C C C
Входной слой Выходной слой

Промежуточные слои  
 

Рис. 3. Обобщенная схема нейронной сети с динамической архитектурой 
 

Fig. 3. A general diagram of a dynamic architecture neural network  

Методы на основе искусственных нейронных Количество промежуточных слоев нейронной 
сетей. Существует большое количество разновид- сети может быть не задано заранее, такую архитек-
ностей нейронных сетей, основные из них – сети туру называют динамической. В этом случае слои 
прямого распространения, рекуррентные сети, ра- последовательно динамически генерируются до 
диально-базисные функции и самоорганизующи- тех пор, пока не будет достигнут нужный уровень 
еся карты. Настройка весов может быть фиксиро- точности. 
ванной или динамической. Обобщенная схема DAN2 приведена на рисун- 

В классических нейронных сетях прямого рас- ке 3, взятом из статьи [9]. Каждый элемент Fk пред-
пространения (Feed Forward Back Propagation, ставляет собой функцию, которая содержит теку-
FFBP) присутствуют входной слой, выходной слой щий элемент накопленных знаний (Current Accu-
и промежуточные слои: сигнал идет последова- mulated Knowledge Element), полученный на 
тельно от входного слоя нейронов по промежуточ- предыдущем шаге обучения сети. C обозначают 
ным слоям к выходному. Примером такой струк- константы. Вершины Gk и Hk представляют собой 
туры является многослойный перцептрон. текущие остаточные нелинейные компоненты про-

Для классификации документа di при помощи цесса по передаточной функции взвешенной и нор-
нейронной сети прямого распространения веса мализованной суммы входных переменных (Cu-
признаков документа подаются на соответствую- rrent Residual Nonlinear Element). 
щие входы сети. Активация распространяется по Сверточная нейронная сеть – однонаправленная 
сети; значения, получившиеся на выходах, и есть многослойная сеть с применением операции 
результат классификации. Стандартный метод обу- свертки, при которой каждый фрагмент входных 
чения такой сети – метод обратного распростране- данных умножается на матрицу (ядро) свертки  
ния ошибки. Суть его в следующем: если на одном поэлементно, а результат суммируется и запи- 
из выходов для одного из обучающих документов сывается в аналогичную позицию выходных дан-
получен неправильный ответ, то ошибка распро- ных. 
страняется обратно по сети и веса ребер меняются Обобщенная схема CNN приведена на рисун- 
так, чтобы уменьшить ошибку. ке 4, взятом из статьи [2]. 

Длина
Текст

...

Чередование 
операций свертки и 

Свертка Полная 
Субдискретизация субдискретизации связь

 
 

Рис. 4. Обобщенная схема сверточной нейронной сети 
 

Fig. 4. A general diagram of a convolution neural network 

 91 

Индексация

Признаки



Программные продукты и системы / Software & Systems                1 (30) 2017 

Рекуррентная нейронная сеть получается из отобранные признаки уже оптимизируют качество, 
многослойного перцептрона введением обратных поэтому оценка будет слишком оптимистичной. 
связей. Одна из широко распространенных разно- Чтобы оценка качества классификатора была объ-
видностей рекуррентных нейронных сетей – сеть ективной, необходимо правильно выбрать соотно-
Элмана – изображена на рисунке 5 [8]. В ней обрат- шение объемов этих выборок. Если взять очень ма-
ные связи идут не от выхода сети, а от выходов ленькую обучающую выборку, оценка качества  
внутренних нейронов. Это позволяет учесть будет слишком пессимистичной. Если тестовая вы-
предысторию наблюдаемых процессов и накопить борка будет маленькая, оценка окажется неточной. 
информацию для выработки правильной стратегии Как правило, обучающую и тестовую выборки бе-
обучения. Главной особенностью рекуррентных рут исходя из соотношения 70/30. 
нейронных сетей является запоминание последова- Однако есть более объективный способ оценки 
тельностей. качества классификатора – кросс-валидация. Суть 

ее состоит в следующем: все множество  разбива-

y(t) ется на k частей, каждая из них по очереди высту-
пает как тестовая. Здесь важно сделать оптималь-
ный выбор k. Обычно предпочитают брать k = 5 
или k = 10. Главный недостаток такого способа 

h(t)
оценки – большие трудозатраты. 

Основным критерием при оценке качества клас-
сификации является комбинация точности и пол-

x(t) ноты. 
 

 Точность (precision) классификации в пределах 
Рис. 5. Нейронная сеть Элмана  класса – это доля найденных классификатором до-

(разновидность рекуррентной сети) кументов, действительно принадлежащих данному 
 

Fig. 5. Elman neural network  классу, относительно всех документов, которые си-
(variety of a recurrent network) стема отнесла к этому классу. 

Полнота (recall) классификации – это доля 
Скрытый слой h(t) в период времени t вычисля- найденных классификатором документов, действи-

ется путем преобразования текущего входного тельно принадлежащих классу, относительно всех 
слоя x(t) и предыдущего скрытого слоя h(t – 1). Да- документов этого класса в тестовой выборке. 
лее из скрытого слоя h(t) результат поступает на Оценка качества работы классификатора произ-
выходной слой y(t). водится на тестовой выборке. Вместе с тем работу 

Преимущества метода: системы оценивает эксперт (см. табл. 1). 
 имеет очень высокое качество алгоритма Таблица 1 

при удачном подборе параметров; Оценка качества работы классификатора 
Table 1 

 является универсальным аппроксиматором 
Classification qualitaty assessment  

непрерывных функций;  

 поддерживает инкрементное обучение. Экспертная оценка 
Недостатки метода: Класс ci Положи- Отрица-

 вероятность возможной расходимости или тельная тельная 

медленной сходимости, поскольку для настройки Оценка  Положительная TP FP 

сети используются градиентные методы; системы Отрицательная FN TN 
 

 необходимость очень большого объема дан- В таблице приняты следующие условные обо-
ных для обучения, чтобы достичь высокой точно- значения: TP – истинно положительное решение; 
сти; TN – истинно отрицательное решение; FP – ложно 

 низкая скорость обучения; положительное решение; FN – ложно отрицатель-
 сложная интерпретируемость параметров ное решение. 

алгоритма. Согласно определению, точность вычисляется 
 следующим образом: 

Оценка качества классификации p = TP / (TP + FP).        (15) 
 Полнота вычисляется по формуле 
Для обучения и оценки качества классифика- r = TP / (TP + FN).         (16) 

ции, как уже отмечалось ранее, требуются обучаю- F-мера – характеристика качества работы алго-
щая и тестовая выборки:  = L  T. Прежде всего ритма, которая объединяет в себе информацию о 
нужно выбрать обучающую и тестовую выборки, точности и полноте: 
далее по обучающей выборке найти оптимальные 2

( 1) pr
признаки, а потом проверять качество на тестовой. F 

 ,         (17) 
2

  p  r
Если сначала найти оптимальные признаки по всей 
выборке, а потом оценивать качество алгоритма, то где 0   <  . 

92  



Программные продукты и системы / Software & Systems                1 (30) 2017 

При 0   < 1  большее значение имеет точ- Классификация проводилась на широко извест-
ность. ной коллекции данных Reuters-21578 (http://www.da 

При  = 1 точность и полнота равноправны, то- viddlewis.com/resources/testcollections/reuters21578/), 

гда F = 2pr / (p + r). собранной и размеченной в 2004 году Д. Льюисом. 

При 1 <  <  большее значение имеет полнота. Коллекция содержит 21 578 документов из ленты 

Часто можно встретить другую формулу для новостей Reuters. Обучающая выборка состоит из 

вычисления точности (accuracy). Эту величину 9 603 документов. Тестовая выборка включает в 

иногда называют правильностью или аккуратно- себя 3 299 документов. В эксперименте разбиение 

стью метода: производилось на десять наиболее часто встречаю-
щихся категорий, связанных с экономикой (нефть, 

TP TN
accuracy  .    (18) пшеница, кукуруза, торговля, деньги и пр.). Ав-

TP TN  FP  FN торы пришли к выводу, что оптимальное количе-
В некоторых случаях удобнее от долей перей- ство признаков для каждого из методов – около 

ти к процентам, умножив полученную величину  2 200. Сравнение качества алгоритмов осуществ- 
на 100. лялось при помощи точности, полноты, точки  

Иногда для сравнения алгоритмов классифика- безубыточности и F-меры. Установлено, что в за-
ции используют специфические характеристики, висимости от категории BEP для DAN2 – это  
такие как точка безубыточности, или сбалансиро- 83,17–99,23 %, для KNN – 74,00–97,30 %, для  
ванная точность. SVM – 75,00–98,50 %. Точность DAN2 для разных 

Точка безубыточности (break even point, BEP) – классов варьируется от 97,56 до 100 %, полнота – 
величина, заимствованная из экономики, отражаю- 68,52–99,66 %, F-мера – 80,63–99,23 %. 
щая объем производства и реализации продукции, Время, потраченное на обучение классифика-
при котором расходы будут компенсированы дохо- тора с использованием DAN2, варьируется в зави-
дами, а при производстве и реализации каждой по- симости от категории – 4,078–410,2969 с, время ра-
следующей единицы продукции предприятие боты уже обученного классификатора на тестовой 
начинает получать прибыль. В контексте рассмат- выборке для выбранных десяти категорий состав-
риваемой задачи точка безубыточности использу- ляет 0,0081–9,5859 с. Для экспериментов использо-
ется как мера качества классификации. Точка без- вался многоядерный сервер со следующей конфи-
убыточности наравне с F-мерой является сбаланси- гурацией: 2 Intel Quad Core Xeon @ 3,2 GHz, 16 GB 
рованной характеристикой точности и полноты. of RAM, Adaptec Raid Controller with 4 SAS hard 
Более подробное пояснение можно найти в [11]. drives in RAID 1/0 configurations. Операционная си-

Под быстродействием классификатора понима- стема SuSE Linux Enterprise Server (SLES, 11)  
ется время, затрачиваемое на отнесение документа 64-bit. Еще пробовали VMWare Server, OpenMPI. 
к одному из классов. Применительно к задачам На основе полученных экспериментальных дан-
классификации текстов быстродействие измеря- ных можно прийти к выводу, что DAN2 опережает 
ется как процессорное время (в секундах) или как KNN для всех десяти категорий и опережает SVM 
количество вычислительных операций, необходи- для девяти из десяти категорий. Вместе с тем сле-
мое для классификации. Измерение производят на дует отметить, что применение нейронных сетей 
обучающей выборке для оценки скорости процесса сильно замедляет работу классификатора на этапе 
обучения и отдельно на тестовой выборке. Следует обучения. 
отметить, что высокие затраты при обучении в В работе [4] утверждается, что формально SVM 
дальнейшем оправдываются за счет многократного и нейронная сеть прямого распространения (FFNN) 
использования настроенного классификатора. имеют похожую структуру, так как выходная функ-

Ясно, что увеличение точности классификации ция может быть представлена в виде линейной 
обычно приводит к снижению быстродействия из- комбинации простых функций, то есть 
за усложнения решающего правила, используемого M

в алгоритме классификации, а увеличение быстро- f (x)  b  h (w , x) .      (19) 
k k

действия сопровождается понижением точности k 1

из-за упрощения работы классификатора. В таком случае количество скрытых нейронов 

 является долей числа опорных векторов (табл. 2). 
Эксперименты по сравнению методов Более подробное описание используемой в таблице 

 общепринятой терминологии можно найти, напри-
В работе [9] предложен алгоритм классифика- мер, в [12]. 

ции на основе нейронных сетей с динамической ар- Кроме того, SVM используется в задаче выпук-
хитектурой DAN2. Этот вид сетей был выбран на лой оптимизации, которая всегда позволяет найти 
основании экспериментального сравнения DAN2 с глобальный минимум и единственное решение, в 
обычными нейронными сетями прямого распро- то время как FFNN тренируется при помощи ме-
странения (FFBP) и рекуррентными нейронными тода градиентного спуска, который не всегда схо-
сетями (RNN). Для сравнения качества классифи- дится к оптимальному (глобальному) решению.  
кации в [9] были рассмотрены DAN2, KNN и SVM. В статье [4] предложены техники для минимизации 

 93 



Программные продукты и системы / Software & Systems                1 (30) 2017 

случая локальной сходимости, а также показано, лучший результат, чем SVM, в 13 тестах (t-тест с 
что масштабированный метод сопряженных гради- p<0,05); SVM превзошел ANN только в 2, хотя в 
ентов не сходится реже, чем традиционный метод целом разница в результатах не превысила 3 %. 
сопряженных градиентов или метод обратного рас- Худшие результаты получены для класса 
пространения с использованием градиентного «книги». Точность 0,88 % при 3 000 терминов для 
спуска. SVM; 0,86 % при 3 000 и 4 000 терминов для SVM. 

Таблица 2 Полнота 0,8 при 1 000 терминов для ANN; 0,88 при 
Соотношение элементов SVM и FFNN 3 000 для SVM. Лучшая аккуратность (accuracy) 

Table 2 81,8 % при 1 000 терминов достигается для ANN. 
Correlation of SVM and FFNN Для остальных трех категорий результаты 

 

Элемент лучше. Для класса GPS лучшая точность 0,96 и луч-
SVM FFNN 

метода шая полнота 0,99 достигаются методом NB, луч-
M Количество опорных Количество вершин шая аккуратность (accuracy) 87,3 % – методом 

векторов в скрытом слое ANN. Для класса «фильмы» лучшая точность 0,95 
h Функция-ядро Функция активации достигается NB, на втором месте 0,87 – ANN, луч-

M
{w }  Опорные векторы Веса скрытого слоя шая полнота 0,98 – NB, на втором месте 0,87 – 

k k1
ANN, лучшая аккуратность (accuracy) 86,5 % полу-

M
{ }  Коэффициенты задачи Веса выходного 

k k1 чена методом ANN. Для класса «фотоаппараты» 
выпуклой оптимиза- слоя 

лучшая точность 0,94 получена методом NB, луч-
ции 

 шая полнота 0,96 – NB, лучшая аккуратность 
В подтверждение своих наблюдений авторы (accuracy) 90,3 % – ANN. 

приводят описание эксперимента по разделению Время работы зависит от количества векторов 
отзывов о фильмах, книгах, GPS и фотоаппаратах для SVM и количества слоев для ANN. Наравне с 
на положительные и отрицательные с использова- ними рассматривался Байес. Он, бесспорно, быст-
нием методов SVM, NB и ANN. В методе SVM в рее всех (0,01–0,02 с) при любом количестве тер-
качестве обычного нелинейного ядра была взята минов для любого класса и в некоторых случаях, 
радиальная базисная функция. В методе с искус- как ни странно, показывал лучшую точность. 
ственными нейронными сетями было отдано пред- Время на обучение для класса «книги»: SVM – 
почтение прямоточной нейронной сети (одно- 0,22–1,5 с, ANN – 3,7–69,4 с в зависимости от ко-
направленной сети с одним скрытым слоем). Для личества признаков (50–5 000). Время на обучение 
обучения нейронной сети использовался алгоритм для класса GPS: SVM – 0,2–1,3 с, ANN – 3,1–75,4 с. 
обратного распространения ошибки (Backpropaga- Время на обучение для класса «фильмы»: SVM – 
tion). Чтобы ускорить процесс обучения и сокра- 0,27–5,6 с, ANN – 2,3–65,5 с. Время на обучение 
тить риск переобучения, применялась технология для класса «фотоаппараты»: SVM – 0,2–1,1 с,  
«ранней остановки». ANN – 4,5–77,2 с. К сожалению, в статье отсут-

Результаты классификации сравнивались на ствуют данные об аппаратном обеспечении, на ко-
сбалансированных и несбалансированных данных. тором проводилось исследование. 
Данные для категории «фильмы» были взяты из по- В работе [10] рассматриваются методы обнару-
пулярной, часто цитируемой базы Movie Review жения ложных высказываний в текстах, когда 
Data (http://www.cs.cornell.edu/people/pabo/movie- люди намеренно говорят неправду, пытаясь обма-
review-data/), для остальных категорий авторы со- нуть. Авторы исследовали высказывания людей, 
бирали коллекции самостоятельно с сайта Amazon вовлеченных в преступления на военных базах. По-
(http://www.amazon.com/) по 2 000 отзывов для дозреваемые и свидетели описывали события сво-
каждого класса. ими словами. Сотрудники правоохранительных ор-

Характеристиками для сравнения являлись точ- ганов находили в архивных данных либо подтвер-
ность (precision), полнота (recall), аккуратность ждения, либо опровержения этим высказываниям. 
(accuracy) и время в секундах. Сравнение осу- Таким образом оценивали истинность высказыва-
ществлялось с помощью 10-проходной кросс-вали- ний либо их ложность. Проанализировано 371  
дации. Количество признаков в экспериментах ва- сообщение из специальных архивов о различных 
рьировалось от 50 до 5 000. В среднем наилучшие видах преступлений: дорожные нарушения, мага-
результаты были получены при 500–1 000. Было за- зинные кражи, нападения и поджоги. Большой про-
мечено, что на 5 000 терминов для ANN время на блемой было собрать такую коллекцию данных, 
обучение значительно увеличивается (с 3,70 с до для которой можно установить истинность/лож-
69,40 с), а время работы не меняется; для SVM, ность высказываний. 
наоборот, время на обучение не меняется, но слиш- Для классификации первоначально экспертами 
ком большое количество признаков сильно сказы- был составлен перечень из 31 признака. Далее при 
вается на длительности работы.  помощи критерия хи-квадрат было выбрано 13 

На сбалансированных данных было проведено наиболее подходящих признаков: количество гла-
28 тестов для четырех категорий. ANN показал голов движения, личных местоимений, количество 

94  



Программные продукты и системы / Software & Systems                1 (30) 2017 

слов с оттенком намерения, причины, с указанием из 800. Для проверки качества методов на русских 
времени, лексическое разнообразие и пр. Некото- текстах была использована коллекция отзывов о 
рые из отобранных признаков весьма специфичны ресторанах и автомобилях, собранная для проведе-
и требуют составления семантических словарей. ния соревнований SentiRuEval-2015 в рамках кон-

В эксперименте проводилось сравнение много- ференции «Диалог». Для проверки полученных  
слойного перцептрона (MLP, разновидность результатов применялась 7-проходная кросс-вали-
FFNN), модификации деревьев решений (CART), дация. 
логистической регрессии и ансамбля классифика- Лучшие результаты как при извлечении терми-
торов. Для построения ансамбля классификаторов, нов, так и при классификации отзывов показал ме-
как правило, используются два основных метода: тод LSTM. При извлечении терминов F-мера для 
бустинг (boosting) и бэггинг (bagging). При бу- LSTM составила 79,80 %. При классификации точ-
стинге происходит последовательное обучение ность – 69,70 %. Метод LSTM для русскоязычных 
классификаторов. Например, первый классифика- данных для класса «рестораны» показал точность 
тор обучается на всем наборе данных, второй – на 61,1 %, F-меру – 70,2 %. Для класса «автомобили» 
выборке примеров, а третий – на наборе тех дан- результаты хуже: точность – 58,0 %, F-мера – 
ных, в которых результаты первых двух классифи- 62,4 %. 
каторов разошлись. Бэггинг использует параллель- Проблема тематической классификации корот-
ное обучение базовых классификаторов, то есть ких текстовых сообщений (от нескольких слов до  
бэггинг является улучшающим объединением, а 2 предложений), например, смс-сообщений, ком-
бустинг – улучшающим пересечением. ментариев к новостям, на форумах, в социальных 

Для проверки использовалась 10-проходная сетях, рассматривается в [7]. Основная сложность, 
кросс-валидация. Для метода MLP достигнута точ- возникающая при решении этой проблемы, – опре-
ность 73,46 %, для CART – 71,60 %, для логистиче- деление набора признаков, по которым предстоит 
ской регрессии – 67,28 %. В результате был сделан классифицировать. В качестве признаков класси-
вывод, что наиболее высокая точность, 74,07 %, до- фикации принято рассматривать слова и словосо-
стигается на ансамбле классификаторов. Преиму- четания, буквы и буквосочетания. Один из недо-
ществом ансамблевых классификаторов является статков распространенных на сегодняшний день 
качество их работы на неравномерно распределен- методов – привязка к конкретному естественному 
ных данных. Эта особенность важна при потоковой языку и опора на словари. В данной публикации 
обработке данных, когда некоторые редкие классы уделяется внимание определению универсальных 
документов, появляющиеся и исчезающие в по- методов и дифференцирующих признаков для тек-
токе, порой непросто обнаружить. стов на различных естественных языках. 

В работе [8] рассмотрено решение сразу двух В данной работе также описан алгоритм постро-
задач: извлечение терминов и классификация для ения и обучения классификатора на основе метода 
англоязычного и русскоязычного корпусов. Необ- взаимной информации (PMI). Применялась проце-
ходимо было определить эмоциональную окраску дура POS-tagging, и для классификации были вы-
отзывов о ресторанах и автомобилях, то есть разде- браны следующие признаки: N – существительные, 
лить отзывы на положительные и отрицательные, NA – существительные и прилагательные, NAV – 
построив бинарный классификатор для каждой из существительные, прилагательные, глаголы, NNP – 
категорий «рестораны» и «автомобили».  существительные и именные группы, VVP – гла-

Для классификации использовались рекуррент- голы и глагольные группы, Stem – псевдоосновы 
ные нейронные сети, в частности, нейронные сети словоупотреблений текста, полученные алгорит-
Элмана (простые и двунаправленные BRNN) и мами аналитического морфологического анализа 
LSTM. Для извлечения аспектных терминов в срав- (имеются в виду широко известные алгоритмы 
нении участвовали несколько методов: два вида Портера, Ловинса, Пейса–Хаска и пр.). 
многослойного персептрона (MLP), логистическая Принадлежность текста к категории определя-
регрессия и условные случайные поля (CRF). Для ется наличием в нем признаков, релевантных дан-
условных случайных полей в качестве признаков ной категории и коррелирующих с признаками рас-
использовались основы слов и принадлежность ча- сматриваемой категории, а также отсутствием  
стям речи (проводилась процедура POS-tagging). нерелевантных признаков и признаков, не коррели-
Использовались две метрики для извлечения ас- рующих с признаками данной категории [7]. При 
пектных терминов: на основе точного количества и таком подходе тексту можно сопоставить инфор-
на основе пропорционального перекрытия. мационную матрицу I, элементы которой опреде-

Сравнение результатов классификации для ан- ляются как пара: Iij = {ij, ij}, где ij – коэффициент 
глийских текстов проводилось на недавно собран- релевантности; ij – коэффициент корреляции. 
ной коллекции SemEval-2014 ABSA Restaurants Для коэффициентов релевантности и корреля-
(http://metashare.ilsp.gr:8080/repository/search/?q=Se ции справедливо следующее утверждение: боль-
mEval-2014+ABSA+Restaurants). Обучающая вы- шие значения этих коэффициентов соответствуют 
борка состояла из 3 041 сообщения, тестовая –  признакам, наиболее точно характеризующим  

 95 



Программные продукты и системы / Software & Systems                1 (30) 2017 

выбранный класс. Пороговые значения релевант- вателей, данные из DBPedia, которая содержит 
ности и корреляции служат параметрами, опреде- структурированные данные из википедии. В ре-
ляющими точность. В процессе классификации  зультате были получены коллекции данных на ан-
вычисляются коэффициенты релевантности и кор- глийском и китайском языках. Объемы собранных 
реляции для каждого текста как суммы соответ- коллекций приведены в таблице 3: обучающие вы-
ствующих коэффициентов для данного класса по борки содержали от 120 000 до 3 600 000 текстов, 
всем вхождениям признаков. Документ считается тестовые – от 7 600 до 650 000 текстов. 
отнесенным к тем категориям, для которых произо- Таблица 3 
шло превышение пороговых значений по обеим ха- Количество классов и объем обучающей  

рактеристикам: как по коэффициенту корреляции, и тестовой выборок для реализации метода CNN 

так и по коэффициенту релевантности. Пороговые Table 3 
A number of classes, training and test set volume for 

значения для каждой категории могут быть заданы 
CNN method implementation  

пользователем или же рассчитаны автоматически  

по обучающей выборке. Название  Количество Обучающая Тестовая 
В работе [7] представлены результаты экспери- коллекции классов выборка выборка 

ментов для метода NB и метода на основе PMI. AG's News 4 120 000 7 600 
Обучение классификаторов проводилось на со-

Sogou News 5 450 000 60 000 
зданных экспертами выборках текстов с сайтов из 

DBPedia 14 560 000 70 000 
Интернета: для русского языка объемом 57,3 Мб, 
башкирского – 1,87 Мб, татарского – 2,68 Мб. В ка- Yelp Review 

2 560 000 38 000 
честве классов условно были выбраны «нарко- Polarity 

тики», «насилие», «национализм», «отрицание тра- Yelp Review 
5 650 000 50 000 

диционных ценностей», «порнография», «терро- Full 

ризм», «фашизм», «экстремизм». Yahoo!  
10 1 400 000 60 000 

Учет выбранных морфологических признаков Answers 

оказывает различное влияние на качество класси- Amazon  
5 3 000 000 650 000 

фикации в зависимости от класса. Для некоторых Review Full 

классов (например «фашизм») могут оказывать по- Amazon  
ложительное влияние существительные и именные Review  2 3 600 000 400 000 
группы, а на определение некоторых тематик Polarity 

(например «наркотики», «фашизм») отрицательное  

влияние оказывает учет глагольных групп. Наименьшие погрешности измерения 1,31–

Лучшие значения F-меры достигаются предло- 7,64 % были достигнуты для моделей, использую-

женным методом (на основе PMI, в качестве при- щих в качестве признаков n-граммы, а также свер-

знаков – псевдоосновы) для классов: «жесто- точные нейронные сети (погрешность измерения 

кость» – 0,913, «отрицание традиционных ценно- 4,93–40,43 %) в зависимости от коллекции. 

стей» – 0,862, «наркотики» – 0,765. В итоге можно Самые плохие результаты показала модель с 

сделать вывод, что псевдоосновы, выделенные ана- применением метода Word2vec. Это означает, что 

литическим алгоритмом морфологического ана- получивший широкое распространение метод 

лиза, могут считаться универсальными дифферен- представления слов Word2vec в виде векторов не 

цирующими признаками при классификации ко- дает преимуществ в задаче классификации текстов. 

ротких текстовых сообщений. Хотя авторам статьи [2] еще предстоит детально 

В работе [2] предложен алгоритм классифика- интерпретировать полученные результаты, а также 

ции с применением сверточных нейронных сетей продолжать эксперименты на коллекциях текстов 

(CNN), проведено сравнение этого метода с мето- для других языков, сейчас можно сделать вывод, 

дом на основе рекуррентных нейронных сетей что для задачи классификации текстов лучшим 

(LSTM) и мультиномиальной логистической ре- оказался символьный уровень, когда рассматрива-

грессией (logit model) в разных вариациях («мешок ются буквосочетания (без привязки к конкретному 

слов», TF-IDF, n-граммы, Word2vec). Тестирование языку). 

сверточных нейронных сетей проводилось на дан-  
ных, основанных на словах (word-based) и на сим- Результаты исследования 

волах (character-based).  
Особенность метода CNN заключается в необ- Классификация текстов является одной из ос-

ходимости использования очень больших коллек- новных задач компьютерной лингвистики, по-
ций для обучения. Большинство открытых кол- скольку к ней сводится ряд других задач: определе-
лекций для классификации текстов (даже на ан- ние тематической принадлежности текстов, автора 
глийском языке) слишком малы, поэтому для  текста, эмоциональной окраски высказываний и др.  
эксперимента авторы самостоятельно собрали тек- Формально задачу классификации текстов 
сты с новостных сайтов, обзоры и отзывы пользо- можно описать следующим образом. Имеется мно-

96  



Программные продукты и системы / Software & Systems                1 (30) 2017 

жество документов и множество возможных кате- выборки, далее по обучающей выборке найти оп-
горий (классов). Требуется построить классифика- тимальные признаки, а затем проверять качество на 
тор, относящий выбранный документ к одной из тестовой выборке. Чтобы оценка качества класси-
нескольких заранее определенных категорий на ос- фикатора была объективной, требуется правильно 
новании содержания документа. Наиболее распро- выбрать соотношение объемов этих выборок. Как 
страненный современный подход к классификации правило, обучающую и тестовую выборки берут 
основывается на методах машинного обучения. Со- исходя из соотношения 70/30. Более объективным 
гласно этим методам, набор правил или критерий способом оценки качества классификатора явля-
принятия решения текстового классификатора вы- ется кросс-валидация. 
числяется автоматически на основе обучающих Общепризнанными характеристиками качества 
данных. Обучающими данными являются образцы работы классификатора являются точность, пол-
документов из каждого класса. нота и их комбинация (F-мера). На основе прове-

Решение задачи классификации состоит из че- денного исследования можно сделать вывод, что 
тырех последовательных этапов: предобработка и наилучшее соотношение этих характеристик до-
индексация документов, уменьшение размерности стигается при использовании методов SVM (точ-
пространства признаков, построение и обучение ность 80–85 %, полнота 83–87 %) и CNN (точность 
классификатора с помощью методов машинного 90–95 %, полнота 80–85 %). Помимо характеристик 
обучения, оценка качества классификации. качества классификации, целесообразно учитывать 

Для предварительной обработки и индексации также другие факторы: время работы алгоритма, 
документа (то есть при построении некоторой чис- возможность работы алгоритма в инкрементном 
ловой модели текста) обычно применяется одна из режиме, количество предварительной информа-
трех моделей: модель «мешка слов», Word2vec и ции, необходимой для классификации, незави- 
модель, основанная на учете n-грамм. Для реализа- симость от языка. Скорость работы алгоритма  
ции первой и второй моделей необходимы допол- NB одна из самых высоких, однако точность для 
нительные знания о морфологической и синтакси- различных экспериментов сильно варьируется  
ческой структуре языка. Применение символьных (71–90 %). При потоковой обработке текстов клас-
n-грамм позволяет не накладывать ограничения на сификация документов должна осуществляться од-
использование конкретного языка, поэтому в ряде новременно с поступлением их из источника, по-
случаев является предпочтительным. этому предпочтение должно отдаваться инкре-

Вычислительная сложность различных методов ментным алгоритмам, таким как CNN или SVM. 
классификации напрямую зависит от размерности В настоящее время по-прежнему остается нере-
пространства признаков. За счет уменьшения раз- шенным вопрос определения набора классифици-
мерности пространства терминов можно снизить рующих признаков, их количества и способов вы-
эффект переобучения – явление, при котором клас- числения весов. При выборе определенного метода 
сификатор ориентируется на случайные или оши- следует помнить, что при большом количестве 
бочные характеристики обучающих данных, а не признаков (около 5 000) время на обучение для 
на важные и значимые. Переобученный классифи- нейронных сетей значительно увеличивается, а 
катор хорошо работает на тех экземплярах, на  время работы не меняется; для SVM, наоборот, 
которых он обучался, и значительно хуже на тесто- время на обучение не меняется, но слишком боль-
вых данных. Чтобы избежать переобучения, коли- шое количество признаков сильно сказывается  
чество обучающих примеров должно быть сораз- на длительности работы. Оптимальным является 
мерно числу используемых терминов, поэтому для 500–1 000 признаков, в некоторых случаях – до 
эффективной работы классификатора часто прибе- 2 200 признаков. В качестве признаков удобно рас-
гают к сокращению числа используемых признаков сматривать частоты символьных n-грамм, чтобы не 
(терминов). Для уменьшения размерности про- накладывать ограничения на использование кон-
странства терминов применяют такие методы, как кретного языка. 
LSA, TF-IDF, PMI, CRF, IG. Наибольшее распро- В алгоритмах глубокого обучения точность 
странение из них получил метод TF-IDF. классификации существенно зависит от наличия 

 обучающей выборки подходящего размера. Подго-
Выводы товка такой выборки – очень трудоемкий процесс. 

 Подбор параметров некоторых алгоритмов на 
В статье были рассмотрены следующие наибо- этапе обучения до сих пор также остается открытой 

лее распространенные методы построения и обуче- проблемой. Согласно результатам проведенного 
ния классификатора: NB, KNN, SVM, DT, логисти- исследования, для обучения и тестирования клас-
ческая регрессия и алгоритмы глубокого обучения, сификатора с использованием метода SVM на рус-
основанные на искусственных нейронных сетях ском языке нужна размеченная коллекция текстов 
(FFBP, RNN, DAN2, CNN).  объемом 1 000–2 000 текстов для достижения точ-

Для обучения и оценки качества классификации ности 80–85 %. Для обучения и тестирования клас-
необходимо подготовить обучающую и тестовую сификатора с применением метода CNN необхо- 

 97 



Программные продукты и системы / Software & Systems                1 (30) 2017 

димо собрать и подготовить коллекцию текстов на 3. Ju R. et al. An Efficient Method for Document Categoriza-

русском языке объемом около 1 000 000 докумен- tion Based on Word2vec and Latent Semantic Analysis. 2015 IEEE 
Intern. Conf. on Comp. and Inform. Technology; Ubiquitous Com-

тов для достижения точности 90–95 %. puting and Communications; Dependable, Autonomic and Secure 
Следует отметить, что большинство упоминае- Computing; Pervasive Intelligence and Computing. Liverpool, UK, 

мых в обзоре экспериментов проводилось на кол- 2015, pp. 2276–2283. 

лекциях англоязычных текстов. Довольно часто 4. Moraes R., Valiati J.F., and Gavião Neto W.P. Document-
level sentiment classification: An empirical comparison between 

встречаются статьи с описанием исследований SVM and ANN. Expert Systems with Applications, 2013, no. 40,  
применительно к китайскому языку. Исследования pp. 621–633. 
по сравнению различных методов классификации 5. Pontiki M Galanis D., Pavlopoulos J., Papageorgiou H., An-

для русскоязычных текстов проводятся в основном droutsopoulos I., Manandhar S. SemEval-2014 Task 4: Aspect based 
sentiment analysis. The 8th Intern. Workshop on Semantic Evalua-

в контексте задачи сентимент-анализа, где рассмат- tion (SemEval 2014). Dublin, Ireland. 2014, pp. 27–35. 
риваются два класса: положительный и отрица- 6. Medhat W., Hassan A., Korashy H. Sentiment analysis al-

тельный. gorithms and applications: a survey. Ain Shams Eng. Jour., 2014,  

Создание общедоступной коллекции необходи- no. 5, pp. 1093–1113. 
7. Поляков И.В., Соколова Т.В., Чеповский А.А., Чепов-

мого размера позволило бы российским исследова- ский А.М. Проблема классификации текстов и дифференциру-
телям активнее изучать проблемы автоматической ющие признаки // Вестн. НГУ. Сер.: Информационные техноло-

обработки текстовой информации в целом и вместе гии. 2015. Т. 13. Вып. 2. С. 55–63. 

с тем разрабатывать новые инструменты для реше- 8. Tarasov D.S. Deep recurrent neural networks for multiple 
language aspect-based sen-timent analysis. Computational Linguis-

ния прикладных задач в данной области. tics and Intellectual Technologies. In Proc. Annual Intern. Conf. «Di-
Работа выполнена при финансовой поддержке Мин- alogue-2015». Moscow, 2015, vol. 2, iss. 14 (21), pp. 65–74. 

обрнауки РФ (договор № 02.G25.31.0146) в рамках реа- 9. Ghiassi M., Olschimke M., Moon B., Arnaudo P. Auto-
лизации Постановления Правительства РФ № 218. mated text classification using a dynamic artificial neural network 

 model. Expert Syst. with Applications, 2012, no. 39, pp. 10967–

Литература 10976. 
 10. Fuller C.M., Biros D.P. and Delen D. An investigation of 
1. Aggarwal C. Data classification: algorithms and applica- data and text mining methods for real world deception detection. Ex-

tions. CRC Press, 2014, chap. 9, pp. 245–273. pert Syst. with Applications, 2011, no. 38, pp. 8392–8398. 
2. Xiang Zhang, Junbo Zhao, Yann LeCun. Character-level 11. Yang Y. An evaluation of statistical approaches to text cat-

convolutional networks for text classification. Proc. Neural Inform. egorization. Information Retrieval Jour., 1999, vol. 1, iss. 1,  
Processing Systems Conf. (NIPS 2015). Montreal, Canada, 2015. pp. 69–90. 
URL: https://arxiv.org/abs/1509.01626 (дата обращения: 12. Haykin S. Neural networks: A comprehensive foundation 
18.07.2016). (2nd ed.). Pearson Education, Singapore, 2001, 824 p. 

 
 
 
 
 
 

Software & Systems                      Received 19.07.16 
DOI: 10.15827/0236-235X.030.1.085-099               2017, vol. 30, no. 1, pp. 85–99 

 

AUTOMATIC TEXT CLASSIFICATION METHODS 
 

T.V. Batura1, 2, Ph.D. (Physics and Mathematics), Leading Researcher, Senior Researcher, tatiana.v.batura@gmail.com 
 
1 Novosibirsk State University, Pirogov St. 2, Novosibirsk, 630090, Russian Federation 
2 A.P. Ershov Institute of Informatics Systems (IIS), Siberian Branch of the Russian Federationn Academy of Sciences, La-
vrentev Av. 6, Novosibirsk, 630090, Russian Federation 
 

Abstract. Text classification is one of the main tasks of computer linguistics because it unites a number of other problems: 
theme identification, authorship identification, sentiment analysis, etc. Content analysis in telecommunication networks is of 
great importance to ensure information security and public safety. Texts may contain illegal information (including data related 
to terrorism, drug trafficking, organization of protest movements and mass riots). This article provides a survey of text classi-
fication methods. The purpose of this survey is to compare modern methods for solving the text classification problem, detect 
a trend direction, and select the best algorithm for using in research and commercial problems. 

A well-known modern approach to text classification is based on machine learning methods. It should take into account 
the characteristics of each algorithm for selecting a particular classification method. This article describes the most popular 
algorithms, experiments carried out with them, and the results of these experiments. The survey was prepared on the basis of 
scientific publications which are publicly available on the Internet, made in the period of 2011–2016, and highly regarded by 
the scientific community. 

The article contains an analysis and a comparison of different classification methods with the following characteristics: 
precision, recall, running time, the possibility of the algorithm in incremental mode, amount of preliminary information neces-
sary for classification, language independence. 

Keywords: text classification, analysis of text information, data mining, text mining, natural language processing, classi-
fication quality, machine learning, deep learning, neural networks. 

98  



Программные продукты и системы / Software & Systems                1 (30) 2017 

 
Acknowledgements. The work has been financially supported by Ministry of Education and Science of the Russian Feder-

ation (contract no. 02.G25.31.0146) as a part of RF Government Regulation no. 218 execution. 
 

 
References  

 
1. Aggarwal C. Data Classification: Algorithms and Applications. CRC Press, 2014, pp. 245–273. 
2. Zhang X., Zhao J., LeCun Y. Character-level Convolutional Networks for Text Classification. Proc. of the Neural 

Information Processing Systems Conf. (NIPS 2015). Montreal, Canada, 2015. Available at: https://arxiv.org/abs/1509.01626 
(accessed July 18, 2016). 

3. Ju R. An Efficient Method for Document Categorization Based on Word2vec and Latent Semantic Analysis. 2015 
IEEE Int. Conf. on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Auto-
nomic and Secure Computing; Pervasive Intelligence and Computing. Liverpool, UK, 2015, pp. 2276–2283. 

4. Moraes R., Valiati J.F., Gavião Neto W.P. Document-level sentiment classification: An empirical comparison between 
SVM and ANN. Expert Systems with Applications. 2013, no. 40, pp. 621–633. 

5. Pontiki M., Galanis D., Pavlopoulos J., Papageorgiou H., Androutsopoulos I., Manandhar S.  SemEval-2014 Task 4: 
Aspect based sentiment analysis. Proc. 8th Int. Workshop on Semantic Evaluation (SemEval 2014). Dublin, Ireland, 2014,  
pp. 27–35. 

6. Medhat W., Hassan A., Korashy H.  Sentiment analysis algorithms and applications: A survey. Ain Shams Engineering 
Journ. 2014, no. 5, pp. 1093–1113. 

7. Polyakov I.V., Sokolova T.V., Chepovsky A.A., Chepovsky A.M. Text classification problem and features set. Vestn. 
NGU. Ser.: Informatsionnye tekhnologii [Novosibirsk State Univ. Journ. of Information Technologies]. 2015, vol. 13, iss. 2, 
pp. 55–63 (in Russ.). 

8. Tarasov D.S. Deep Recurrent Neural Networks for Multiple Language Aspect-Based Sentiment Analysis. Computa-
tional Linguistics and Intellectual Technologies: Proc. of Annual Int. Conf. “Dialogue-2015”. Moscow, Russia, 2015, vol. 2, 
iss. 14 (21), pp. 65–74. 

9. Ghiassi M., Olschimke M., Moon B., Arnaudo P. Automated text classification using a dynamic artificial neural net-
work model. Expert Systems with Applications. 2012, no. 39, pp. 10967–10976. 

10. Fuller C.M., Biros D.P. and Delen D. An investigation of data and text mining methods for real world deception detec-
tion. Expert Systems with Applications. 2011, no. 38, pp. 8392–8398. 

11. Yang Y. An evaluation of statistical approaches to text categorization. Information Retrieval Jour. 1999, vol. 1,  
iss. 1, pp. 69–90. 

12. Haykin S. Neural networks: A comprehensive foundation. 2nd ed., Pearson Education Publ., Singapore, 2001, 824 p. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

Примеры библиографического описания статьи  
 
1. Батура Т.В. Методы автоматической классификации текстов // Программные 

продукты и системы. 2017. Т. 30. № 1. С. 85–99; DOI: 10.15827/0236-235X.030.1.085-
099. 

 
2. Batura T.V. Automatic text classification methods. Programmnye produkty i sistemy 

[Software & Systems]. 2017, vol. 30, no. 1, pp. 85–99 (in Russ.); DOI: 10.15827/0236-
235X.030.1.085-099. 
  

 99