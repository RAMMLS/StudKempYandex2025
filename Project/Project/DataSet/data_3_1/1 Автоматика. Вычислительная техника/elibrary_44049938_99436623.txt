http://www.computeroptics.ru http://www.computeroptics.smr.ru 

Семантическая сегментация спутниковых снимков аэропортов  
с помощью свёрточных нейронных сетей 

В.А. Горбачёв 1, И.А. Криворотов 1,2, А.О. Маркелов 1,2, Е.В. Котлярова 2 
1 Государственный научно-исследовательский институт авиационных систем (ГНЦ РФ), Москва, Россия,  

2 МФТИ, Москва, Россия 

Аннотация 

Статья посвящена разработке эффективного алгоритма семантической сегментации для 
разметки элементов аэропортовой инфраструктуры на космических снимках оптического 
диапазона. В данной работе применены алгоритмы сегментации на основе глубоких свёр-
точных нейронных сетей. Они зарекомендовали себя в широком ряде задач, в том числе 
сегментации изображений наземной съёмки, где они показывают стабильно высокие ре-
зультаты. В ходе работы были вручную размечены обучающие и тестовые изображения. 
Был произведён поиск оптимальной для данной задачи архитектуры нейронной сети. Ис-
следованы различные комбинации энкодеров и декодеров. Для постобработки и учёта кон-
текстной информации и соседства объектов различных классов с целью устранения выбро-
сов применена модель условных случайных полей. Описаны особенности применённых 
решений на всех этапах подготовки алгоритма: подготовка данных, обучение нейронной се-
ти и постобработка её результатов. 

Ключевые слова: семантическая сегментация, искусственные нейронные сети, глубокое 
обучение, обработка изображений. 

Цитирование: Горбачёв, В.А. Семантическая сегментация спутниковых снимков аэро-
портов с помощью свёрточных нейронных сетей / В.А. Горбачёв, И.А. Криворотов, 
А.О. Маркелов, Е.В. Котлярова // Компьютерная оптика. – 2020. – Т. 44, № 4. – С. 636-645. – 
DOI: 10.18287/2412-6179-CO-636. 

Citation: Gorbachev VA, Krivorotov IA, Markelov AO, Kotlyarova EV. Semantic segmenta-
tion of satellite images of airports using convolutional neural networks. Computer Optics 2020; 
44(4): 636-645. DOI: 10.18287/2412-6179-CO-636. 

В связи с этим в работе рассмотрен вопрос приме-
Введение 

нения алгоритмов семантической сегментации к за-
Сегодня в разных областях науки и техники ши- даче автоматизации обработки аэрофото- и космиче-

роко востребованы цифровые карты местности и гео- ских снимков аэропортов для выделения границ объ-
информационные системы. На современном этапе ектов и объектового состава. 
карты должны содержать не только пространственное Семантическая сегментация изображений – это 
расположение объектов и высоты точек рельефа, но и разделение изображения на отдельные группы пиксе-
подробную информацию об объектовом составе. Эта лей, области, соответствующие одному классу объек-
информация необходима в широком круге задач от тов с одновременным определением типа объекта в 
планирования и администрирования территорий до каждой области. Задача семантической сегментации 
экологического и кадастрового мониторинга. Отдель- является высокоуровневой задачей обработки изоб-
ную роль электронные карты и планы играют в авиа- ражений, относящейся к группе задач так называемо-
ции. Не только маршрутизация воздушного и назем- го слабого искусственного интеллекта. Она является 
ного аэропортового транспорта, но и системы повы- более сложной, чем задача классификации изображе-
шения ситуационной осведомлённости и дополнен- ний и детектирования объектов, так как необходимо 
ного или синтезированного видения существенно не только определять классы объектов, но и правиль-
опираются на детальные карты местности и инфор- но выделять их границы на изображении. В то же 
мацию об объектовом составе.  время задача семантической сегментации заметно от-

При этом важны не только состав и детальность личается от обычной сегментации, когда области 
электронных карт, но и сроки их изготовления и об- объединяются по принципу цветового или текстурно-
новления. Процесс их создания является сложной и го сходства. Объекты могут иметь существенно раз-
трудоёмкой задачей, требующей значительного коли- личающиеся по фотометрическим характеристикам 
чества ручного труда. Алгоритмы семантической элементы и иметь значительный разброс показателей 
сегментации позволяют в существенной степени ав- объектов внутри одного класса. В данной работе се-
томатизировать этот процесс. Полученная алгорит- мантическая сегментация изображений применяется к 
мами информация потребует обработки оператором- спутниковым снимкам аэропортов в целях автомати-
картографом, но существенно снизит его нагрузку. зации процесса обработки снимков для обновления 

636 Computer Optics, 2020, Vol. 44(4)    DOI: 10.18287/2412-6179-CO-636 



Семантическая сегментация спутниковых снимков аэропортов... Горбачёв В.А., Криворотов И.А., Маркелов А.О., Котлярова Е.В. 

карт и извлечения информации о расположении эле- предложили пространственное пирамидальное объ-
ментов аэропортовой инфраструктуры, зелёных зон, единение (ASPP) таких фильтров для сегментирова-
зданий и проч. Задачей работы является исследование ния объектов в разных масштабах. В-третьих, была 
влияния различных элементов алгоритма на качество улучшена локализация границ объектов с помощью 
сегментации. комбинирования методов из глубоких свёрточных 

нейронных сетей и вероятностных графических мо-
Обзор существующих работ 

делей (CRF) для учёта контекстной информации. В 
Для задачи семантической сегментации историче- CFNet [9] для учёта контекста предлагается исполь-

ски существует большое количество методов реше- зовать специальный модуль Aggregated Co-Occurrent 
ния, однако результаты сравнения алгоритмов на от- Feature Module, оценивающий вероятности совмест-
крытых наборах данных, например, ISPRS Semantic ного проявления различных признаков. Приём объ-
Labeling Contest [1], показывают значительное пре- единения карт признаков spatial pyramid pooling, с 
восходство алгоритмов, основанных на свёрточных помощью которого сеть-дешифровальщик получает 
нейронных сетях в комбинации с различными подхо- информацию о глобальном контексте, предложен в 
дами к предобработке и постобработке изображений. архитектуре PSPNet [10]. RefineNet [11] подходит к 

Подобные алгоритмы были разработаны относи- проблеме потери контекста другим, более производи-
тельно недавно, статья о первой успешной нейросете- тельным способом, заметно отличающимся от 
вой архитектуре для сегментации FCN-8s вышла в PSPNet. Предложенная авторами архитектура итера-
2014 году [2], однако сейчас именно они показывают тивно объединяет повышающие разрешение векторы 
наилучшую точность работы. Большинство нейросе- признаков с помощью специальных блоков RefineNet 
тевых алгоритмов семантической сегментации имеют для нескольких диапазонов разрешений, и, наконец, 
аналогичную этой сети архитектуру: сначала для вы- создаёт карту сегментации с высоким разрешением. В 
деления семантической информации изображение DANet [12] авторы используют механизм внимания 
преобразуется в вектор признаков с помощью сети- (self-attention) для моделирования зависимостей как 
шифровальщика (encoder), затем вектор обратно раз- внутри каждого канала, так и между каналами. Мо-
ворачивается в матрицу изображения с помощью се- дель Mask R-CNN [13] явилась развитием методов 
ти-дешифровальщика (decoder). В качестве сети- детектирования и решает одновременно две задачи: 
шифровальщика часто используют различные заранее строит ограничивающий прямоугольник (bounding 
обученные свёрточные сети, такие как VGG [3] или box) объекта для решения задачи детектирования и 
ResNet [4]. Построение сети-дешифровальщика – за- одновременно в этом прямоугольнике производит 
дача более открытая, так как необходимо по семанти- сегментацию. Наконец, принципиально другим под-
ческой карте низкого разрешения построить попик- ходом к задачам семантической сегментации стало 
сельную карту разметки высокого разрешения, вос- использование генеративных состязательных сетей 
становив пространственную информацию. Различные (generative adversarial networks), работающих без 
архитектуры используют разные механизмы для ре- прямого использования функции потерь для сегмен-
шения этой проблемы.  тации [14]. 

Так, например, в архитектуре сети SegNet [5] ис-
План работы 

пользуется операция рассоединения (unpooling). Её 
новшество заключается в том, что при операции объ- Решение задачи сегментации включает в себя сле-
единения по максимуму (max-pooling), на этапе дующие этапы: 
свёртки в сети-шифровальщике индексы максималь-  предварительная обработка данных; 
ных значений сохраняются и позже используются,  создание обучающих выборок; 
чтобы повысить дискретизацию соответствующей  выбор архитектуры алгоритма;  
карты признаков в сети-дешифровальщике, совершив  выбор наиболее подходящей функции потерь; 
операцию рассоединения (unpooling) с использовани-  обучение и выполнение алгоритма; 
ем сохраненных индексов. Модель U-net [6] исполь-  постобработка полученных карт разметки. 
зует идею сквозных соединений (skip-connection) для Можно заметить, что алгоритм имеет модульную 
сохранения пространственной информации. Карты структуру и допускает выбор различных методов на 
признаков из сети-шифровальщика напрямую пере- каждом этапе и их комбинирование. В работе было 
даются и конкатенируются с картами признаков на приведено исследование каждого этапа, предложены 
соответствующих слоях сети-дешифровальщика, па- различные подходы по оптимизации алгоритма на 
раллельно с обычными свёрточными слоями. В каждом этапе и их экспериментальное сравнение. 
LinkNet [7] вместо конкатенации применяется сложе-

Исходные данные 
ние карт признаков. Архитектура DeepLab [8] при-
внесла три новшества. Во-первых, это свёртка филь- В качестве исходных данных были выбраны спут-
трами с повышенной дискретизацией (atrous convolu- никовые снимки оптического диапазона аэропортов 
tion, dilated convolution). Во-вторых, авторы первыми Домодедово, Шереметьево, Пулково, Внуково и 

Компьютерная оптика, 2020, том 44, №4    DOI: 10.18287/2412-6179-CO-636 637 



http://www.computeroptics.ru http://www.computeroptics.smr.ru 

Хельсинки, с разрешением 1/3 метра на пиксел, полу- вия освещённости, на снимках могут присутствовать 
ченных спутником WorldView-3. Разметка была про- тени от облаков и т.д. Например, из рис. 2 видно, что 
изведена вручную по семи классам, представленным цвета травы, асфальта и бетона сильно отличаются у 
в табл. 1. Всего в обучающей коллекции было 31 двух разных изображений. Искусственная имитация 
изображение высокого разрешения для обучения таких фотометрических особенностей на этапе обу-
нейросети, 3 для валидации и 4 для тестирования. чения необходима для повышения обобщающей спо-
Пример сегментированного человеком изображения собности алгоритма. 
(ground truth) представлен на рис. 1.  

Табл. 1. Кодирование объектов на снимках 

 Тип объекта Hex-код 
Цвет 

цвета 
0 Здания 0000ff синий 
1 Растительность 00ff00 зелёный 
2 Земля, стройка ffff00 жёлтый 
3 «Бетон» (ВПП, рулёжки) ffffff белый 
4 «Асфальт» (автодороги) 00ffff бирюзовый     
5 Нестационарные объекты ff00ff фиолетовый Рис. 2. Пример различия цветового баланса  

между изображениями различных аэропортов 
6 Другое ff0000 красный 

Изображения в высоком разрешении были нареза-
ны на фрагменты размером 440 × 440 и 660 × 660 с пе-
рекрытием в половину размера фрагмента. Затем 
фрагменты масштабировались к единому размеру. 
Всего было получено 3000 фрагментов. Использова-
ние масштабирования позволяет моделировать воз-
можную разницу в размерах объектов, а нарезка с пе-
рекрытием позволяет использовать большее количе-
ство контекстов. Для того чтобы дополнительно уве-
личить обучающую выборку и имитировать различия 

    
Рис. 1. Пример пары изображений  между снимками, были проведены следующие опера-

из обучающей выборки ции: случайные повороты изображений, случайные 
изменения масштаба в небольшом диапазоне (15 %) и 

При обучении разметка классов была редуцирова-
случайные мультипликативные изменения яркости 

на. Отличить покрытие автомобильных дорог от по-
(до 30 %). Примеры аргументированных снимков 

крытия аэродромов можно только по глобальному 
приведены на рис. 3.  

контексту, визуально они идентичны, а переходы 
между ними носят крайне условный характер. Поэто-
му они были объединены в один класс. Класс «объек-
ты» содержал самолёты, небольшие аэропортовые 
объекты, автомобили. Он крайне мало представлен в 
выборке и недостаточно точно размечен (оператор 
разметки, как правило, объединял рядом стоящие 
объекты в целые области), поэтому был объединён с 
предыдущим классом, так как на собранной выборке 
выучить его сегментацию оказалось невозможно. Он 

  
только ухудшал точность остальных классов. Классы 
«земля», «стройка» и «прочее» тоже были объедине-
ны, так как визуально очень похожи. В итоге исполь-
зовалось для обучения 4 класса: 1 – земля, стройка, 
прочее; 2 – растительность; 3 – асфальто-бетонное 
покрытие; 4 – здания. 

Аугментация данных 

Отметим, что изображения различных использо-
ванных аэропортов имеют существенные различия.   

Рис. 3. Пример аугментации изображения: оригинальный 
Снимки были произведены с разных спутников и в снимок, поворот, изменение яркости и приближение 
разное время, имеют различные цветопередачу, усло-

638 Computer Optics, 2020, Vol. 44(4)    DOI: 10.18287/2412-6179-CO-636 



Семантическая сегментация спутниковых снимков аэропортов... Горбачёв В.А., Криворотов И.А., Маркелов А.О., Котлярова Е.В. 

Выбор архитектуры нейросети зультаты по сравнению с обычными автоэнкодерами. 
Благодаря этому U-net не требует большого количе-

Было исследовано 3 разных базовых архитектуры 
ства изображений для обучения, так как имеет срав-

для сегментации изображений: Unet, PSPNet, LinkNet. 
нительно небольшое количество параметров.  

Каждая архитектура обучалась с несколькими раз-
Архитектура U-Net состоит из двух соединённых 

личными энкодерами, такими как: VGG16 [3], между собой сетей: сети-шифровальщика (энкодера) 
ResNet34 [4], InceptionV3 [15], MobileNetV2 [16], для извлечения из изображения семантической ин-
EfficientNetB0 [17]. Всего для выявления лучшего формации в виде вектора признаков и сети-дешиф-
подхода и особенностей для данной задачи было обу- ровальщика (декодера) для превращения вектора при-
чено 15 различных моделей. Результаты сравнения знаков в матрицу нового изображения – маски клас-
приведены в параграфе Эксперименты. Пример ком- сов (рис. 4). Чтобы сохранить пространственную ин-
бинирования различных энкодеров и декодеров про- формацию (контекст), карты признаков из энкодера с 
иллюстрируем на примере сети Unet-VGG16. помощью сквозных соединений напрямую передают-

По ряду причин U-net [5] является хорошей базо- ся в декодер и конкатенируются с картами признаков 
вой архитектурой. U-net был создан для семантиче- соответствующего разрешения декодера. 
ской сегментации медицинских изображений, для ко- Для повышения ёмкости модели и точности рабо-
торых характерен постоянный ракурс и масштаб объ- ты сети в качестве сети-шифровальщика вместо ис-
ектов, что соответствует постановке нашей задачи. U- ходного энкодера можно использовать сеть VGG-16 
net существенно использует идею сквозных соедине- [3]. Получившуюся архитектуру VGG-Unet можно 
ний (skip-connection), которая даёт очень хорошие ре- увидеть на рис. 6. 

 
Рис. 4. Архитектура U-net 

 
Рис. 5. Архитектура VGG-Unet 

Функция потерь игнорируются при обучении, так как их количество 
относительно мало. Проблему несбалансированности 

Распространённой проблемой в области анализа 
данных можно решать, например, с помощью изме-

изображений является детектирование или сегменти-
нения обучающей выборки либо с помощью выбора 

рование очень маленького «аномального» региона 
функции потерь (loss function). В данной работе были 

большого изображения (например, выделение не-
исследованы три функции потерь: кросс-энтропия, 

большого здания на фоне большого количества зелё-
обобщённая функция потерь Дайса и фокальная 

ных насаждений). Такие данные называются несба-
функция потерь. 

лансированными. Легко классифицируемые примеры 
составляют большую часть обучающей выборки и Кросс-энтропия 
доминируют при расчёте функции потерь. Сложные Кросс-энтропийная (CE) функция потерь часто 
примеры, на которых сеть ошибается, практически используется в задачах семантической сегментации. 

Компьютерная оптика, 2020, том 44, №4    DOI: 10.18287/2412-6179-CO-636 639 



http://www.computeroptics.ru http://www.computeroptics.smr.ru 

Её выходной сигнал представляет собой значение ве- 
FL  pt    yi 1 pi  ln pi , 

роятности в диапазоне от 0 до 1. Величина кросс- i

энтропийной функции потерь увеличивается, когда 
прогнозируемая вероятность отклоняется от целевой где y   

i = 1, если объект принадлежит к классу i, и 0 

метки. В бинарной классификации, где количество иначе, а pi – предсказанная вероятность принадлеж-

классов равно двум, кросс-энтропия может быть по- ности объекта к классу i. 

считана так: Когда пример классифицирован неправильно и 
вероятность pi_x0001_ небольшая, модулирующий 

CE  p, y   y ln p  1 y ln(1 p)  , фактор близок к единице и значение функции потерь 
не изменяется. При вероятности pi_x0001_, близкой к 

где y = 0 для объекта первого класса и y = 1 для второ- 1, коэффициент модуляции становится равным 0, а 
го, p – вероятность того, что объект принадлежит ко значение функции потери для уверенно классифици-
второму классу. рованных примеров снижаются. Параметр фокуси-

Если классов больше двух, нужно рассчитать от- ровки  плавно регулирует скорость, с которой у 
дельные значения для каждого класса и просуммиро- «простых» примеров понижаются веса. Когда  = 0, 
вать результат: фокальная функция потерь становится тождественна 

кросс-энтропийной. 
CE  p, y   yi  ln pi . 

i Постобработка 

Здесь и далее yi = 1, когда объект принадлежит к Для улучшения точности классификации необхо-
классу i, и yi = 0 иначе, а pi – предсказанная вероят- димо учитывать пространственные зависимости меж-
ность принадлежности объекта к классу i. ду целевыми переменными для улучшения простран-

Обобщённая функция потерь Дайса ственной поддержки разметки, при этом оставляя за-
дачу эффективно вычислимой. Был использован 

На основе известной меры сходства между мно- структурный подход на основе модели условных слу-
жествами такой, как коэффициент Дайса–Сёренсена, чайных полей (CRF). Условные случайные поля яв-
можно построить функцию потерь (т.н. Dice loss): ляются методом статистического моделирования, ко-

торый часто применяется в машинном обучении. В то 
yi  p

DL 1 2  . время как дискретный классификатор предсказывает 
 pi  yi  метку для одного образца без учёта меток соседних 

объектов, CRF может учитывать контекст, что явля-
Чтобы избежать проблемы влияния несбалансиро- ется важным для данной задачи, что было показано в 

ванности классов на функцию потерь, в статье [18] статье [20]. Учёт контекста заключается в гипотезе о 
авторы предложили использовать функцию потерь том, что соседний сегмент для данного сегмента име-
следующего вида (Generalized Dice loss): ет тот же класс (то есть границы между классами от-

w носительно редки), а вероятность встретить по сосед-
 i yi  p

GDL 1 2  , ству сегменты различных классов соответствует ве-
wi pi  yi  роятности на обучающей выборке. Математически 

где w  
i = (yi) –2, а yi – это сумма yi по всему изобра- такая гипотеза формулируется в виде модели услов-

жению, то есть количество пикселей класса i. Благо- ного случайного поля. Вероятность того, что изобра-

даря такому взвешиванию сеть лучше обучается на жению I соответствует разметка Y, можно описать 

объектах редко встречающихся классов, так как вес следующим образом: 

ошибок на них в функции потерь увеличивается.  1
P(Y | I )  (yi | I )  (yi , y j | I ) , 

Фокальная функция потерь Z (I ) i i jN (i)

Авторы статьи [19] предлагают изменить форму где Ф (yi | I) – фактор, выражающий вероятность того, 
функции потери таким образом, чтобы сосредоточить что сегмент i изображения будет иметь класс yi, 
её внимание на сложных редко встречающихся при- (yi, yi | I) – фактор, выражающий вероятность того, 
мерах. В случае доминирования объектов одного из что сегмент i и его сосед j из окрестности N (i) будут 
классов сеть при обучении будет пытаться устранить иметь классы yi и yj одновременно. Перемножение 
даже небольшие ошибки на объектах доминирующих производится по всем сегментам i изображения I. 
классов, а существенные ошибки редких классов бу- Z (i) – константа нормализации, равная сумме по всем 
дет игнорировать. Авторами предлагается добавить возможным разметкам произведений факторов. Мак-
модулирующий фактор (1 – pt) к кросс-энтропийной симизацию вероятности можно заменить минимиза-
функции потерь с настраиваемым фокусирующим цией логарифма вероятности, т.н. «энергии» карты 
параметром  ≥ 0. разметки: 

640 Computer Optics, 2020, Vol. 44(4)    DOI: 10.18287/2412-6179-CO-636 



Семантическая сегментация спутниковых снимков аэропортов... Горбачёв В.А., Криворотов И.А., Маркелов А.О., Котлярова Е.В. 

E(Y | I ) (yi | I )   (yi , y j | I ) , ных на 512 тестовых изображений. Точность вычис-
i i jN (i) лялась как доля правильно классифицированных пик-

селей изображения. При подсчёте сравнивались две 
где  = ln Ф – «унарный потенциал»,  = ln  – «би-

карты разметки: полученное нейросетью и размечен-
нарный потенциал». При этом вычислять константу 

ное человеком. Результаты по разным изображениям 
нормализации не требуется. В результате постобра-

усреднялись. Для оценки результатов использовались 
ботки карта разметки, полученная нейростетью, за-

метрики F1-score по каждому классу, их среднее по 
меняется картой разметки, имеющей наименьшую 

классам (Avg) и общая точность (Accuracy) по всему 
энергию (то есть наибольшую совместную правдопо-

изображению, они приведены в табл. 1. В целом вид-
добность в смысле указанного функционала). Резуль-

но, что лучше всего себя показало семейство LinkNet. 
таты экспериментов показывают, что условные слу-

С лучшей в среднем сетью LinkNet-EfficientNetB0 
чайные поля (CRF) являются эффективным инстру-

была проведена серия экспериментов с различными 
ментом для постобработки изображений. Она позво-

вариациями условий (табл. 2). 
ляет заметно устранить выбросы и сгладить результа-
ты сегментации. 

Результаты экспериментов 

При обучении в качестве оптимизатора выбран 
Adadelta, функция потерь – Focal Loss, размер батча – 
32. Для инициализации параметров использовались 
предобученные на коллекции данных ImageNet [21] 
веса энкодеров. Время обучения составляло от 4 до 8 
часов на видеокарте Tesla K80. 

По графикам обучения (рис. 6) видно, что для всех 
моделей значение 0,9 для F1-score является предель-  
ным значением. Так как среди моделей присутствуют Рис. 6. График функции потерь на обучении 
разного рода архитектуры, как более лёгкие 
(MobileNetV2, EfficientNetB0), так и более тяжёлые 
(InceptionV3, VGG16), и все они запоминают обуча-
ющую выборку одинаково, то можно предположить, 
что эта граница обусловлена качеством разметки 
обучающей выборки. Однако модели имеют различ-
ную обобщающую способность, что видно на графи-
ках валидации (рис. 7).  

На рис. 8 можно увидеть результаты сегментации по 
изначально указанным в разметке 7 классам. У исходно 
обученной сети плохо распознаётся класс зем-
ля/стройка, потому что он очень разнообразен внешне  
(имеет большую внутриклассовую дисперсию) и недо- Рис. 7. График функции потерь на валидации 

статочно обширно представлен на изображениях из 
обучающей выборки. Также плохой результат у класса 
дорог, так как отличить взлётно-посадочную полосу и 
рулёжные дорожки от автомобильной дороги можно 
только по контексту или по специфическим линиям      
разметки. Это естественно, так как классы локально ви- Рис. 8. Оригинальное изображение, сегментированное 
зуально практически неразличимы, имеют почти иден- нейронной сетью на 4 класса, сегментированное  

нейронной сетью на 7 классов 
тичную текстуру и различаются только функционально. 
На данной выборке сеть оказалась не в состоянии вы- Из анализа выборки можно заключить, что, поми-
полнить такой высокоуровневый анализ. Помимо этого, мо низкого качества разметки, основной проблемой 
довольно редко встречается класс «Нестационарные является дисбаланс классов. Класс «Стройка, земля, 
объекты», его удельная площадь на изображениях мусор» представлен в выборке крайне незначительно 
крайне низка. Это объясняет предпринятое далее пере- по сравнению с другими классами, вследствие чего 
распределение классов и редуцирование выборки до 4 точность распознавания на этом классе довольно низ-
классов на обучении. Сеть обучалась на тех же исход- ка. Это подтолкнуло к попытке искусственно изме-
ных изображениях, но с изменёнными метками.  нить баланс классов в обучающей выборке при обу-

Тестирование алгоритмов производилось на 4 от- чении, включая больше изображений, где данный 
ложенных снимках высокого разрешения, поделён- класс занимает большую точность. Для одной из се-

Компьютерная оптика, 2020, том 44, №4    DOI: 10.18287/2412-6179-CO-636 641 



http://www.computeroptics.ru http://www.computeroptics.smr.ru 

тей (Unet-MobileNetV2), которая была не самой луч- приводило к существенному результату (рис. 9). 
шей, была проведена серия экспериментов на таких Предположительно, это вызвано тем, что тень от об-
перебалансированных данных (табл. 3). Результаты в лака имеет ярко выраженную границу, в то время как 
целом были улучшены. На классе «здания» был до- аугментированные снимки затемнены целиком.  
стигнут лучший среди всех результат. Неожиданно 
балансировка отрицательно сказалась на результатах 
сети LinkNet-EfficientNetB0. 

Применение искусственного расширения обуча-
ющих данных привело к большей устойчивости алго-
ритма при появлении разных условий освещённости, 
изменении цвета травы, также стали лучше выделять-
ся здания на снимках. К сожалению, в случае с теня-      

Рис. 9. Оригинальное и распознанное нейронной сетью 
ми облаков использование данного приёма не всегда изображение  

Табл. 2. Сравнение различных архитектур. В ячейках указана F1-мера, её среднее значение по классам (Avg) 
и точность по всем пикселам в столбце Accuracy 

Модель 1 2 3 4 Avg Accuracy 
Unet-EfficientNetB0 30,65 97,1 95,08 64,11 71,73 94,53 
Unet-ResNet34 19,10 97,25 94,15 75,00 71,37 94,35 
Unet-MobileNetV2 37,21 96,89 94,57 72,47 75,29 94,05 
Unet-VGG16 29,17 96,61 93,52 71,26 72,64 92,95 
Unet-InceptionV3 20,95 97,25 94,50 76,75 72,36 94,20 
Linknet-VGG16 31,51 97,32 95,33 78,83 75,75 95,14 
LinkNet-MobileNetV2 23,65 97,05 94,60 65,30 70,15 94,10 
LinkNet-ResNet34 25,65 96,90 93,85 80,45 74,21 94,10 
LinkNet-EfficientNetB0 35,84 97,49 95,34 73,56 75,56 95,22 
LinkNet-Inceptionv3 23,50 97,42 95,46 75,99 73,09 94,79 
PSPNet-EfficientNetB0 18,85 96,70 93,35 38,75 61,91 92,40 
PSPNet-MobileNetV2 9,10 96,25 92,00 40,75 59,52 91,50 
PSPNet-VGG16 45,35 96,45 94,2 51,05 71,76 93,70 
PSPNet-ResNet34 25,76 96,72 93,31 39,07 63,71 93,08 
PSPNet-Inceptionv3 32,31 96,38 93,52 47,19 67,35 92,17 

Табл. 3. Точности алгоритма LinkNet-EfficientNetB0 для различных условий обучения. В ячейках указана F1-мера,  
её среднее значение по классам (Avg) и точность по всем пикселам в столбце Accuracy 

Balance CCE Focal Dice CRF 1 2 3 4 Avg Accuracy 
V  V   29,12 97,22 94,35 59,11 69,95 94,28 
 V    26,81 96,48 94,9 60,07 69,57 94,36 
  V   35,84 97,49 95,34 73,56 75,56 95,22 
   V  32,74 96,29 94,19 72,51 73,93 93,86 
 V   V 26,93 96,83 95,07 59,16 69,49 94,66 
  V  V 37,04 97,65 95,46 74,70 76,21 95,41 
   V V 33,66 96,90 94,49 73,07 74,53 94,25 

Табл. 4. Точности алгоритма Unet-MobileNetV2 для различных условий обучения. В ячейках указана F1-мера,  
её среднее значение по классам (Avg) и точность по всем пикселам в столбце Accuracy 

Balance CCE Focal Dice CRF 1 2 3 4 Avg Accuracy 
  V   37,21 96,89 94,57 72,47 75,29 94,05 

V  V   54,72 97,40 95,43 69,01 79,14 94,83 
V V    28,46 96,61 94,52 63,36 70,74 93,81 
V  V   54,72 97,40 95,43 69,01 79,14 94,83 
V   V  37,70 96,98 95,22 81,32 77,80 94,64 
V V   V 28,43 96,77 94,64 63,40 70,81 93,95 
V  V  V 57,56 97,51 95,54 69,30 79,98 94,95 
V   V V 37,79 97,10 95,21 81,74 77,96 94,74 

 

642 Computer Optics, 2020, Vol. 44(4)    DOI: 10.18287/2412-6179-CO-636 



Семантическая сегментация спутниковых снимков аэропортов... Горбачёв В.А., Криворотов И.А., Маркелов А.О., Котлярова Е.В. 

Как видно из рис. 10, использование разных работают при несбалансированных данных. Так, 
функции потерь для одной и той же архитектуры функция потерь Дайса хорошо себя показывает для 
для одних и тех же данных приводит к получению выделения зданий, которые недостаточно представ-
сетей, которые по-разному выделяют классы. В це- лены в выборке. В целом, разные архитектуры пока-
лом, лучшие результаты показывает фокальная зывают в среднем сходные результаты (рис. 11), вы-
функция потерь. Две другие функции потерь позво- бор должен производиться исходя из ценности вы-
ляют в разных случаях получать более качественные деления определённых классов в рамках конкретной 
результаты, в основном за счёт того, что они лучше практической задачи. 

          
Рис. 10. Сравнение результатов работы нейронной сети с тремя разными функциями потерь, слева-направо  
и сверху-вниз: ручная разметка, кросс-энтропийная, фокальная функция потерь, функция потерь Дайса 

          
Рис. 11. Исходное изображение, разметка и результаты сегментации LinkNet-EfficientNetB0 и Unet-MobileNetV2 

          
Рис. 12. Исходное изображение, разметка и результаты сегментации сетью LinkNet-EfficientNetB0  

без постобработки, с постобработкой̆ CRF 

Из табл. 1 видно, что с использованием кон- Заключение 
текстной информации через модель CRF можно до-

В данной работе решалась задача семантической 
стичь более высокой точности, чем без неё. На сегментации космических снимков аэропортов опти-
рис. 12 видно, что подобная обработка визуально ческого диапазона с помощью аппарата свёрточных 
сглаживает результаты работы нейросети и устраняет нейронных сетей. Было произведено исследование 
выбросы. влияния на результат сегментации всех элементов ал-

В целом, доля правильно расставленных меток раз- горитма: предобработки данных, архитектуры сети, 
нится в зависимости от класса, например, наиболее хо- функции потерь, постобработки результатов. В каче-
рошо распознаются дорожное покрытие и раститель- стве предобработки (аугментации) были применены 

ность. Это объясняется тем, что для данных классов повороты, отражения и изменения яркости. Было про-
изведено сравнение различных архитектур энкодеров и 

имеется более высокое количество обучающих приме-
декодеров. Наилучшим образом в данной задаче себя 

ров (дороги и растительность занимают на изображени- показала архитектура LinkNet-EfficientNetB0. Иссле-
ях из обучающей выборки наибольшую площадь), к то- довано влияние на результат функции потерь: кросс-
му же объекты данных имеют более гладкие границы. энропийной, фокальной и функции потерь Дайса. 

Компьютерная оптика, 2020, том 44, №4    DOI: 10.18287/2412-6179-CO-636 643 



http://www.computeroptics.ru http://www.computeroptics.smr.ru 

Фокальная оказывается оптимальным выбором в on Computer Vision and Pattern Recognition (CVPR). – 
условиях дисбаланса классов. Для повышения каче- 2019. – P. 548-557. 

ства итоговой семантической разметки и подавления 10. Hengshuang, Z. Pyramid scene parsing network / 
Z. Hengshuang, S. Jianping, Q. Xiaojuan, W. Xiaogang, 

шумов была проведена постобработка с помощью J. Jiaya // IEEE Conference on Computer Vision and Pattern 
модели условных случайных полей. Полученная точ- Recognition (CVPR). – 2017. – P. 2881-2890. 
ность составила около 95 % в среднем по всем клас- 11. Lin, G. RefineNet: Multi-path refinement networks for 
сам. Проведён сравнительный анализ точностей раз- high-resolution semantic segmentation / G. Lin, A. Milan, 
личных подходов и их комбинаций. Ch. Shen, I. Reid // IEEE Conference on Computer Vision 

and Pattern Recognition (CVPR). – 2019. – P. 5168-5177. 
Благодарности 12. Fu, J. Dual attention network for scene segmentation / 

J. Fu, J. Liu, H. Tian, Z. Fang, H. Lu // IEEE Conference on 
Работа была поддержана Российский фондом фун- Computer Vision and Pattern Recognition (CVPR). – 2019. 

даментальных исследований, грант № 17-08-00191. – P. 3146-3154. 
13. Kaiming, H. Mask R-CNN / H. Kaiming, G. Gkioxari, 

Литература P. Dollar, R. Girshick // IEEE International Conference on 
Computer Vision (ICCV). – 2017. – P. 2980-2988. 

1. ISPRS 2D semantic labeling contest [Electronical Resource]. 14. Goodfellow, I. Generative adversarial nets / I. Goodfellow, 
– URL: J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, 
http://www2.isprs.org/commissions/comm3/wg4/semantic- S. Ozair, A. Courville, Y. Bengio // Proceedings of the 27th 
labeling.html (request date 11.06.2019). International Conference on Neural Information Processing 

2. Long, J. Fully convolutional networks for semantic seg- Systems. – 2014. – Vol. 2. – P. 2672-2680. 
mentation / J. Long, E. Shelhamer, T. Darrell // IEEE 15. Szegedy, C. Rethinking the inception architecture for com-
Transactions on Pattern Analysis and Machine Intelligence. puter vision / C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, 
– 2017. – Vol. 39, Issue 4. – P. 640-651. Z. Wojna // IEEE Conference on Computer Vision and Pat-

3. Simonyan, K. Very deep convolutional networks for large- tern Recognition (CVPR): – 2015. – P. 2818-2826. 
scale image recognition [Electronical Resource] / K. Simonyan, 16. Sandler, M. MobileNetV2: Inverted residuals and linear 
A. Zisserman. – 2015. – URL: 
https://arxiv.org/pdf/1409.1556.pdf (request date 11.06.2019). bottlenecks / M. Sandler, A.G. Howard, M. Zhu, 

4. Kaiming, H. Deep residual learning for image recognition / A. Zhmoginov, L.-C. Chen // IEEE Conference on Comput-
H. Kaiming, Z. Xiangyu, R. Shaoqing, S. Jian // IEEE Con- er Vision and Pattern Recognition (CVPR): – 2018. – 
ference on Computer Vision and Pattern Recognition P. 4510-4520. 
(CVPR). – 2016. – P. 770-778.  17. Tan, M. EfficientNet: Rethinking model scaling for convo-

5. Badrinarayanan, V. SegNet: A deep convolutional encod- lutional neural networks / M. Tan, Q.V. Le // International 
er-decoder architecture for image segmentation / Conference on Machine Learning (ICML). – 2019. – 
V. Badrinarayanan, A. Kendall, R. Cipolla // IEEE Transac- P. 6105-6114. 
tions on Pattern Analysis and Machine Intelligence. – 2017. 18. Carole, H.S. Generalized Dice overlap as a deep learning 
– Vol. 39, Issue 12. – P. 2481-2495. loss function for highly unbalanced segmentations / 

6. Ronneberger, O. U-Net: Convolutional networks for bio- H.S. Carole, L. Wenqi, T. Vercauteren, S. Ourselin, 
medical image segmentation / O. Ronneberger, P. Fischer, M.J. Cardoso // Deep Learning in Medical Image Analysis 
T. Brox // International Conference on Medical Image and Multimodal Learning for Clinical Decision Support. – 
Computing and Computer-Assisted Intervention. – 2015. – 2017. – P. 240-248. 
Vol. 1, Issue 3. – P. 234-241. 19. Lin, T. Focal loss for dense object detection / T. Lin, 

7. Chaurasia, A. LinkNet: Exploiting encoder representations P. Goyal, R. Girshick, H. Kaiming, P. Dollar // IEEE Inter-
for efficient semantic segmentation / A. Chaurasia, national Conference on Computer Vision (ICCV). – 2017. – 
E. Culurciello // IEEE Visual Communications and Image P. 2999-3007. 
Processing (VCIP). – 2017. – P. 1-4. 20. Блохинов, Ю.Б. Разработка алгоритма семантической 

8. Chen, L.-Ch. DeepLab: Semantic image segmentation with сегментации аэрофотоснимков реального времени / 
deep convolutional nets, atrous convolution, and fully con-
nected CRFs / L.-Ch. Chen, G. Papandreou, I. Kokkinos, Ю.Б. Блохинов, В.А. Горбачев, Ю.О. Ракутин, А.Д. Ни-

K. Murphy, A.L. Yuille // IEEE Transactions on Pattern китин // Компьютерная оптика. – 2018. – Т. 42, № 1. – 
Analysis and Machine Intelligence. – 2018. – Vol. 40, Is- С. 141-148. – DOI: 10.18287/2412-6179-2018-42-1-141-148. 
sue 4. – P. 834-848. 21. ImageNet large scale visual recognition competition 2014 

9. Zhang, H. Co-occurrent features in semantic segmentation / [Electronical Resource]. – URL: http://image-
H. Zhang, H. Zhang, C. Wang, J. Xie // IEEE Conference net.org/challenges/LSVRC/2014/ (request date 11.06.2019). 

 
 

Сведения об авторах 

Горбачев Вадим Александрович, 1988 года рождения, в 2011 году окончил Московский физико-
технический институт (государственный университет) по направлению «Прикладные математика и физика», 
работает начальником сектора в ФГУП ГОСНИИАС (ГНЦ РФ). Область научных интересов: компьютерное 
зрение, машинное обучение, искусственный интеллект, обработка изображений.  
E-mail: vadim.gorbachev@gosniias.ru . 

 

644 Computer Optics, 2020, Vol. 44(4)    DOI: 10.18287/2412-6179-CO-636 



Семантическая сегментация спутниковых снимков аэропортов... Горбачёв В.А., Криворотов И.А., Маркелов А.О., Котлярова Е.В. 

Криворотов Иван Андреевич, 1997 года рождения, в 2019 году окончил бакалавриат Московского физико-
технического института (государственного университета) по направлению «Прикладные математика и физика», 
поступил в магистратуру МФТИ, работает инженером в ФГУП ГОСНИИАС (ГНЦ РФ). Область научных инте-
ресов: компьютерное зрение, машинное обучение, искусственный интеллект, обработка изображений.  
E-mail: krivorotov.ia@phystech.edu . 

 
Маркелов Александр Олегович, 1997 года рождения, в 2019 году окончил бакалавриат Московского фи-

зико-технического института (государственного университета) по направлению «Прикладные математика и фи-
зика», поступил в магистратуру МФТИ, работает инженером в ФГУП ГОСНИИАС (ГНЦ РФ). Область научных 
интересов: компьютерное зрение, машинное обучение, искусственный интеллект, обработка изображений.  
E-mail: markelov.ao@phystech.edu . 

 
Котлярова Екатерина Владимировна, 1995 года рождения, в 2019 году Московский физико-

технический институт (государственный университет) по направлению «Прикладные математика и физика», в 
2019 году поступила в аспирантуру МФТИ, работает младшим разработчиком в области машинного обуче-
ния в Huawei Labs RUS. Область научных интересов: компьютерное зрение, машинное обучение, искус-
ственный интеллект, обработка изображений. E-mail: kotlyarova.ev@phystech.edu . 
 
 

ГРНТИ: 28.23.15 
Поступила в редакцию 20 сентября 2019 г. Окончательный вариант – 04 декабря 2019 г. 

 
 

Компьютерная оптика, 2020, том 44, №4    DOI: 10.18287/2412-6179-CO-636 645 



 

Semantic segmentation of satellite images of airports  
using convolutional neural networks  

V.A. Gorbachev1, I.A. Krivorotov1,2, A.O. Markelov1,2, E.V. Kotlyarova2 
1State Research Institute of Aviation Systems (SSC of RF), Moscow, Russia, 

2Moscow Institute of Physics and Technology (State University), Moscow, Russia 
Abstract  

The paper is devoted to the development of an effective semantic segmentation algorithm for 
automation of airport infrastructure labelling in RGB satellite images. This task is addressed using 
algorithms based on deep convolutional artificial neural networks, as they have proven themselves 
in a wide range of tasks, including the terrestrial imagery segmentation, where they show consist-
ently high results. A new dataset was labelled for this particular task and a comparative analysis of 
different architectures and backbones was carried out. A conditional random field model (CRF) 
was used for postprocessing and accounting of contextual information and neighborhood of ob-
jects of different classes in order to eliminate outliers. Features of the solutions applied at all pre-
paratory stages of the algorithm were described, including data preparation, neural network train-
ing and post-processing of the training results.  

Keywords: semantic segmentation, artificial neural networks, deep learning, image processing. 
Citation: Gorbachev VA, Krivorotov IA, Markelov AO, Kotlyarova EV. Semantic segmenta-

tion of satellite images of airports using convolutional neural networks. Computer Optics 2020; 
44(4): 636-645. DOI: 10.18287/2412-6179-CO-636. 

Acknowledgements The work was supported by the Russian Foundation of Basic Research un-
der grant No. 17-08-00191.   

References [11] Lin G, Milan A, Shen Ch, Reid I. RefineNet: Multi-path 
refinement networks for high-resolution semantic 

[1] ISPRS 2D semantic labeling contest. Source: segmentation. IEEE CVPR 2019: 5168-5177. 
http://www2.isprs.org/commissions/comm3/wg4/semantic- [12] Fu J, Liu H, Tian H, Fang Z, Lu H. Dual attention network 
labeling.html. for scene segmentation. IEEE CVPR 2019: 3146-3154. 

[2] Long J, Shelhamer E, Darrell T. Fully convolutional [13] Kaiming H, Gkioxari G, Dollar P, Girshick R. Mask R-
networks for semantic segmentation. IEEE Trans Pattern CNN. IEEE ICCV 2017: 2980-2988. 
Anal Mach Intell 2017; 39(4): 640-651. [14] Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-

[3] Simonyan K, Zisserman A. Very deep convolutional Farley D, Ozair S, Courville A, Bengio Y. Generative 
networks for large-scale image recognition. Source: 
 adversarial nets. Proc NIPS'14 2014: 2672-2680. 
https://arxiv.org/pdf/1409.1556.pdf. 

[4] Kaiming H, Xiangyu Z, Shaoqing R, Jian S. Deep residual [15] Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. 
learning for image recognition. IEEE Conf Comp Vis Rethinking the inception architecture for computer vision. 
Pattern Recogn (CVPR) 2016: 770-778. IEEE CVPR 2015: 2818-2826. 

[5] Badrinarayanan V, Kendall A, Cipolla R. SegNet: A deep [16] Sandler M, Howard AG, Zhu M, Zhmoginov A, Chen L-C. 
convolutional encoder-decoder architecture for image MobileNetV2: Inverted residuals and linear bottlenecks. 
segmentation. IEEE Trans Pattern Anal Mach Intell 2017; IEEE CVPR 2018: 4510-4520. 
39(12): 2481-2495. [17] Tan M, Le QV. EfficientNet: Rethinking model scaling for 

[6] Ronneberger O, Fischer P, Brox T. U-Net: Convolutional convolutional neural networks. ICML 2019: 6105-6114. 
networks for biomedical image segmentation. Med Image [18] Carole HS, Wenqi L, Vercauteren T, Ourselin S, Cardoso 
Comput Comput Assist Interv 2015; 1(3): 234-241. MJ. Generalised Dice overlap as a deep learning loss 

[7] Chaurasia A, Culurciello E. LinkNet: Exploiting encoder function for highly unbalanced segmentations. Deep Learn 
representations for efficient semantic segmentation. IEEE 
VCIP 2017: 1-4. Med Image Anal Multimodal Learn Clin Decis Support 

[8] Chen L-Ch, Papandreou G, Kokkinos I, Murphy K, Yuille 2017: 240-248. 
AL. Deep Lab: Semantic image segmentation with deep [19] Lin T, Goyal P, Girshick R, Kaiming H, Dollar P. Focal loss 
convolutional nets, atrous convolution, and fully connected for dense object detection. IEEE ICCV 2017: 2999-3007. 
CRFs. IEEE Trans Pattern Anal Mach Intell 2018; 40(4): [20] Blokhinov YB, Gorbachev VA, Rakutin YO, Nikitin AD. 
834-848. A real-time semantic segmentation algorithm for aerial 

[9] Zhang H, Zhang H, Wang C, Xie J. Co-occurrent features imagery. Computer Optics 2018; 42(1): 141-148. DOI: 
in semantic segmentation. IEEE CVPR 2019: 548-557. 10.18287/2412-6179-2018-42-1-141-148. 

[10] Hengshuang Z, Jianping S, Xiaojuan Q, Xiaogang W, Jiaya [21] ImageNet large scale visual recognition competition 2014. 
J. Pyramid scene parsing network. IEEE CVPR 2017: 
2881-2890. Source: http://image-net.org/challenges/ LSVRC/2014/. 

 
 

 



 

Authors’ information  

Vadim Aleksandrovich Gorbachev (b. 1988) graduated from Moscow Institute of Physics and Technology in 
2011, majoring in Applied Mathematics and Physics. Currently he works as the head of sector at the FSUE State Re-
search Institute of Aviation Systems. Research interests are currently focused on computer vision, machine learning, ar-
tificial intelligence and image analysis. E-mail: vadim.gorbachev@gosniias.ru . 

 
Ivan Andreevich Krivorotov (b. 1997) graduated undergraduate from Moscow Institute of Physics and Technology 

in 2019, majoring in Applied Mathematics and Physics. Currently he works as the engineer at the FSUE State Research 
Institute of Aviation Systems. Research interests are currently focused on computer vision, machine learning, artificial 
intelligence and image analysis. E-mail: krivorotov.ia@phystech.edu . 

 
Aleksandr Olegovich Markelov (b. 1997) graduated undergraduate from Moscow Institute of Physics and Tech-

nology in 2019, majoring in Applied Mathematics and Physics. Currently he works as the engineer at the FSUE State 
Research Institute of Aviation Systems. Research interests are currently focused on computer vision, machine learning, 
artificial intelligence and image analysis. E-mail: markelov.ao@phystech.edu . 

 
Ekaterina Vladimirovna Kotlyarova (b. 1995) graduated from Moscow Institute of Physics and Technology in 

2019. She works as junior machine learning developer at Huawei Labs RUS. Her research interests are currently fo-
cused on computer vision, machine learning, artificial intelligence and image analysis.  
E-mail: kotlyarova.ev@phystech.edu . 
 
 

Received September 20, 2019. The final version – December 04, 2019.