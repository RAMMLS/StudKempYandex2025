Метод прогнозирования изменений параметров временных рядов в цифровых… Кропотов Ю.А., Проскуряков А.Ю., Белов А.А. 

МЕТОД ПРОГНОЗИРОВАНИЯ ИЗМЕНЕНИЙ ПАРАМЕТРОВ ВРЕМЕННЫХ РЯДОВ  
В ЦИФРОВЫХ ИНФОРМАЦИОННО-УПРАВЛЯЮЩИХ СИСТЕМАХ 

Ю.А. Кропотов 1, А.Ю. Проскуряков 1, А.А. Белов 1 
1 Муромский институт (филиал) федерального государственного бюджетного образовательного учреждения 

высшего образования «Владимирский государственный университет  
имени Александра Григорьевича и Николая Григорьевича Столетовых», Муром, Россия 

Аннотация 
Прогнозирование изменений параметров временных рядов является актуальной задачей 

при мониторинге исследуемых процессов в цифровых информационных системах управле-
ния при исследовании проблем увеличения горизонта предсказания и минимизации по-
грешности прогноза. В работе исследуются алгоритмы прогноза, основанные на моделях, 
воспроизводящих динамику временного ряда в форме искусственных нейронных сетей. По-
лучены уравнения функционирования и обучения искусственной нейронной сети в матрич-
ной форме, получен алгоритм обратной подстановки, с помощью которого можно увели-
чить глубину прогноза. В работе представлено решение задачи прогноза, состоящее в 
нахождении оценок предсказания посредством минимизации функции потерь – квадрата 
нормы отклонения оценок от наблюдаемых значений временного ряда и в определении ко-
эффициентов модели алгоритмом обучения искусственных нейронных сетей итерационным 
методом обратного распространения ошибок. Применение разработанных алгоритмов поз-
волило построить структурную схему реализации нейросетевого прогнозирования, с помо-
щью которого можно получить достаточно точное представление об изменениях парамет-
ров временных рядов в системах мониторинга исследуемых процессов по критериям дли-
тельности и минимизированной погрешности получения прогноза. 

Ключевые слова: прогнозирование, информационные системы управления, функцио-
нальный ряд, нейронная сеть, временной ряд, трехслойный персептрон. 

Цитирование: Кропотов, Ю.А. Метод прогнозирования изменений параметров времен-
ных рядов в цифровых информационно-управляющих системах / Ю.А. Кропотов, 
А.Ю. Проскуряков, А.А. Белов // Компьютерная оптика – 2018. – Т. 42, № 6. – С. 1093-1100. – 
DOI: 10.18287/2412-6179-2018-42-6-1093-1100. 

Введение 2] модель прогнозируемого процесса схематически 
Задача прогнозирования заключается в нахождении описывается дифференциальным уравнением, зави-

будущих значений параметров временного ряда на ин- сящим от неизвестных параметров системы a и фак-
тервале, называемом горизонтом прогнозирования [1, торов fk, отражающих неопределённость модели, где 
2], в пределах которого обеспечивается необходимая k – номер анализируемого фактора, находится в пре-
точность решения задачи. Для непрерывных процессов делах 1  k  M и идентифицируется методом 
это интервал (t, t  ], который для временного ряда за- наименьших квадратов. При этом в рассмотрение 
писывается как (n, n  N]. Здесь t и nT  текущие мо- вводятся три процесса: наблюдаемый процесс y, ис-
менты времени, при этом T  период дискретизации. следуемый  процесс x и модельный (прогностиче-
Прогнозирование обычно осуществляется по значени- ский) процесс z. Исследуемый процесс в силу не-
ям временного ряда или процесса на конечном, пред- определенности факторов fk является (из множества 

шествующем, интервале [t T, t] времени. возможных) неизвестным решением дифференци-

Горизонт предсказания является не только одной ального уравнения 

из важнейших мер качества прогноза, но и исполь- P(d/dt, x, a, fk )  0 . 
зуется в качестве критерия степени детерминиро- Пренебрежение указанными факторами позволяет 
ванности и случайности наблюдаемых явлений, получить дифференциальное уравнение, описываю-
служит характеристикой динамического хаоса (ха- щее модельный процесс z, при соответствующих 
рактеристикой хаотических колебаний в динамиче- условиях близкий к исследуемому процессу x. Это 
ских системах). В основе этого утверждения лежит уравнение можно записать в виде 
зависимость горизонта предсказания не только от 
используемых алгоритмов, но и от свойств анализи- G(d/dt, z, a)  0.  
руемых временных рядов и процессов. В задачах Здесь критерием качества прогнозирования может 
прогнозирования выбор алгоритма осуществляется являться среднеквадратическое значение нормы откло-
исходя из соображений максимизации горизонта нения модельного процесса по факторам fk от исследуе-
прогнозирования и достоверности прогноза. Один из мого на интервале предсказания, то есть величина [1] 
принципов прогнозирования временных рядов или 
процессов основывается на их представлении непре- 2 1 M t

2
x  z   x(v, fk )  z(v) dv )

M  . (1  
рывными или дискретными моделями. В работах [1, k1 t

Компьютерная оптика, 2018, том 42, №6 1093 



Метод прогнозирования изменений параметров временных рядов в цифровых… Кропотов Ю.А., Проскуряков А.Ю., Белов А.А. 

Аналогично определяется качество прогнозирова-
ния дискретных процессов или временных рядов, 
представленных дискретными моделями, которые, в 
частности, могут быть получены из непрерывных мо-
делей путём замены производных конечными разно-
стями. При этом операция интегрирования заменяет-
ся операцией суммирования по конечному множеству 
данных на интервале прогнозирования. Переход к 
дискретной модели эквивалентен численному реше-
нию дифференциального уравнения со свойственны-
ми этому решению проблемами чувствительности к 
возмущающим воздействиям. 

На практике построение моделей основывается 
на данных о соответствующих наблюдаемых про-
цессах: модели могут относиться к классам линей-
ных дискретных и регрессионных систем, стацио-
нарных и нестационарных процессов. При решении 
задач прогнозирования нестационарных процессов 
может быть применен метод, основанный на де-
композиции процессов по эмпирическим модам 
(метод EMD) [5]. 

Распространенными методами прогнозирования  
Рис. 1. Структура трехслойной нейронной сети 

являются параметрические методы регрессионной  обратного распространения ошибки 
аппроксимации [4], динамические модели авторе- При этом выходы j-го слоя сети можно предста-
грессии – скользящего среднего [3], методы им- вить вектором 
пульсных функций [6] и искусственных нейронных 
сетей [9, 10].  (wT

j ,1y j1  wj ,1,0 ) 
   

1. Нейросетевые методы прогнозирования  
(wT

j ,2y j1 wj ,2,0 )
y 

j   , (5) 
Горизонт прогнозирования любой модели зависит 


от того, насколько достоверно эта модель воспроизво-  

(wT
j , p y   w p )

j j 1 j , j ,0 
дит динамику временного ряда или системы, порож-
дающей наблюдаемый процесс. Поэтому в этой части где () – функция активации. 
работы исследуется вопрос о горизонте прогнозирова- Формула (5) является рекуррентным уравнением, 
ния на основе модели искусственной нейронной сети позволяющим найти последовательно выходы всех 
[7, 8]. Проблема здесь заключается в том, насколько слоёв сети, начиная с первого слоя (j  1) и заканчивая 
точно динамика процесса может быть представлена последним слоем (в рассматриваемом случае j = 3), 
весовыми коэффициентами сети. Поэтому обратные совпадающим с выходом сети. Вектор y0 – это вход-
связи формируются алгоритмами обучения методом ная последовательность временного ряда x(n). 
обратного распространения ошибки. Алгоритм функ- При решении задач прогноза выходами сети в пре-
ционирования многослойной нейронной сети прямого делах одного цикла её функционирования являются 
распространения при прохождении сигналов по результаты предсказания временного ряда или процес-
направлению от входа к выходу задаются уравнениями са на заданное число шагов вперёд, начиная с 1 и кон-
в матричной форме. Соответственно, схема нейронной чая pвых.сл.(число нейронов в выходном слое сети). 
сети представлена на рис. 1. Алгоритм обучения нейронной сети методом об-

В соответствии с рис. 1 вектор выходов j-го слоя ратного распространения ошибки также можно пред-
сети, состоящего из pj  нейронов, ставить уравнениями в матричной форме. 

T Введём матрицу весов j-го слоя сети 
y j   y j ,1 , y j ,2 ,, y j , p  , (2) 

j
Wj  w j ,1 , w j ,2 ,,w j , p , (6) 

j 
и вектор весовых коэффициентов l-го нейрона j-го 
слоя сети вектор смещения нейронов j-го слоя 

 T
w j ,l  w  Tw j ,0  wj ,1,0 , wj ,2,0 ,, wj , p j ,0 , (7) 

j ,1 , wj ,2 ,, wj, p . (3) 
j

Тогда синаптическая сумма l-го нейрона j-го слоя вектор синаптических сумм 
сети  Ts j  s j ,1 , s j ,2 ,, s j , p  (8) 

j

s T
j ,l  w j ,l y j1  wj ,l ,0 , (4) 

и векторную функцию активации j-го слоя 
где wj,l,0 – смещение нейрона. 

 Tφ(s j )  (s j ,1 ),(s j ,2 ),,(s j , p ) . (9) 
j

1094 Компьютерная оптика, 2018, том 42, №6 



Метод прогнозирования изменений параметров временных рядов в цифровых… Кропотов Ю.А., Проскуряков А.Ю., Белов А.А. 

Задача обучения сети заключается в нахождении ной ряд x(n) отсчетов значений процесса. Аналогично 
весовых коэффициентов j-го слоя сети путем мини- могут быть исследованы непрерывные функции либо 
мизации функционала временные ряды данных, отображающие информа-

p j p j цию изменения параметров различных процессов для 
2  2

J j (e j )  e jl   y jl  y j  решения задач прогнозирования в информационно-
l1 l1  (10) управляющих системах. 

T
 (s j )  y j  (s j )  y j  , Табл. 1. Алгоритм обучения многослойного персептрона  

где e jl  (T Этап 
jl y j1 j0l )  yl или соответственно Шаги алгоритма 

 обучения 
e jl  (s jl )  y j  – вектор ошибок по выходам j-го слоя, 1. Опреде-  (wT j

ление выхо- j1y j1  w01) 
 

y  T
j  y j ,1 , y j ,2 ,, y j , p j   – вектор требуемых выходов j- дов (прямой  

(wT
2 y j

y j j1  w02 ) 
j   , j 1,2,...; y C

го слоя сети. проход) : 0  m  
 

(wT y  w j

Если ввести матрицы W T
j  s j /y j1,  диагональ- 

jp j j1 0 p )
j 

ную матрицу Φ  T
j   (s j )/s j  в виде  2. Опреде- e j1  WjΦ je j ,ej  (s j )  y j ,  

ление оши-
T (s j )  (s 

a j,1) (s бок (обрат- s  T
j Wj y j1  wj0  (s j , s j 2 ,..., s p )T

0 j ,   
j

=d , j,2 ) (sj, p ) 
Φ i g , , j

j  
s    , (11) ный проход) 
 j  sj,1 s где wj = (wj1, wj2,…, wjpj) – матрица весовых 

j,2 s 
j, pj  синаптических коэффициентов. 

то алгоритм обучения методом обратного распро- 3. Коррек- wjl (q 1)  wjl (q)  hjl (s jl )ejl y j1 , 
странения ошибки принимает вид разностного урав- ция синап-

тических ко- wj0 (q 1)  wj0 (q)  Ф je j , 
нения 

эффициен- (s ) (s (s ) T

e j1  WjΦ je j ,  (12) j1 j2) jp  (s j )
тов Ф j  diag( ... j )  ,  

s j ,1 s j ,2 s j , p s
j j

с начальными условиями e j  (s j )  y j , при j = jвых.сл. (s
h s jl )

(номер выходного слоя сети). jl ( jl )  , 
s

Коррекция весовых коэффициентов сети по ошиб- jl

кам, полученным с помощью уравнения (12), осу-  – шаг настройки, выбирается в диапазоне 
ществляется градиентным методом по итерационным 0 <  < 1.  
формулам 

w j ,l (q 1)  w j ,l (q) hj ,l (s j ,l )ej ,l y j1 , 

w j ,0 (q 1)  w j ,0 (q) Φ je j , (13) 

(s l )hj ,l (s j ,l ) 
j , 

s jl  
где l = 1, 2,…, pj, ej,l является l-м компонентом вектора Рис. 2. Структурная схема нейросетевого прогнозирования 

ej ошибки, q – номер итерации,  – шаг настройки ве-  изменений значений функции 

совых коэффициентов,  выбирается в диапазоне Входные сигналы в виде непрерывной функции 
0    1. x(t) или дискретной функции в виде временного ряда 

Таким образом, выражения (2) – (13) формируют x(n) подаются на W-фильтр предварительной обра-
алгоритм обучения нейронной сети при прогнозиро- ботки вейвлет-преобразованием [6]. В W-фильтре 
вании изменения значений исследуемой функции, ре- формируются аппроксимирующие коэффициенты Ci,, 
ализуемый нейронной сетью, построенной по прави- вычисленные по формуле 
лу многослойного персептрона. 1

Шаги алгоритма сведены в табл. 1. С  (2i
i Ci1i t  n),  

p
2. Структура прогнозирования  где  i

i(2 t – n) – скейлинг-функция – коэффициент ор-
на трехслойном персептроне тонормирования, обеспечивающий единичную норму 

Структурная схема, реализующая нейросетевое скейлинг-функции. Детализирующие коэффициенты 
прогнозирование изменений значений параметров i-го уровня вейвлет-разложения вычисляются по 
функции с её предварительной вейвлет-обработкой, формулам: 
представлена на рис. 2. 1

Как видно из рис. 2, система прогнозирования, ре- d1  x(n)1(2t  n),  
ализованная на трехслойном персептроне прямого p
распространения, используется применительно к за- 1 m

даче мониторинга информации в информационно- di  Ci1 (2i
i t  n) . 

управляющих системах, которая формирует времен- p i2

Компьютерная оптика, 2018, том 42, №6 1095 



Метод прогнозирования изменений параметров временных рядов в цифровых… Кропотов Ю.А., Проскуряков А.Ю., Белов А.А. 

где i(2it – n) – вейвлет-функция, Ошибки на выходе 1-х нейронов 2-го и 1-го слоев 
m – максимальный уровень вейвлет-разложения.  вычисляются в соответствии с выражениями: 

Аппроксимирующие коэффициенты Ci подаются 64 10

на вход N-разрядного регистра сдвига, построенного e11 w2l e21e21 w3l e31 .  
на элементах задержки с передаточной функцией Z –1, l1 l1

в котором формируется выборка входных сигналов Вычисленные таким образом ошибки обратного 
нейронной сети в виде движущегося окна из N отсче- прохода, в свою очередь, адаптивно перестраивают 
тов, обработанных в W-фильтре. На выходах выход- синаптические коэффициенты связей между нейро-
ного слоя нейронной сети вычисляются сигналы в нами различных слоев. Таким образом, веса 1-х 
виде аппроксимирующих коэффициентов прогноза нейронов каждого слоя адаптивно настраиваются в 
C *r

m , где r – число периодов прогноза (r = 1, 2,…, 10, соответствии с выражениями: 

при P3 = 10). ' d3 (s1 )
w 0 *1

31  w31  e31 Cm ,  
Многослойный персептрон состоит из входного ds10

слоя, внутреннего слоя (где значение j внутреннего 
' d2 (s10 )

слоя принимает значение 0 или 1) и выходного слоя. w 21  w21  e21 y21 ,  
ds10

При j = 1 структурная схема персептрона представля-
d (s )

ет собой трехслойный персептрон. Увеличение числа w' 1 64
11  w11  e11 y11 .  

слоев, т.е. j > 1, в персептроне приводит к увеличе- ds64

нию вычислительных затрат при незначительном Минимизация ошибки обеспечивается выше рас-
уменьшении погрешности [7]. смотренной итерационной процедурой обучения 

Число нейронов во входном слое персептрона нейронной сети, в ходе которой осуществляется 
влияет на число анализируемых входных аппрокси- настройка весовых или синаптических коэффициен-
мирующих коэффициентов временного ряда Cm(n), тов сети. Таким образом, задача прогнозирования за-
соответственно на время анализа предыдущих значе- ключается в оценивании будущих значений процесса 
ний отсчетов исследуемой функции, на общую по- по имеющимся данным Cm в текущий момент, в 
грешность прогнозирования. В соответствии с [7] по- настройке значений коэффициентов нейронной сети 

по критерию минимальной величины ошибки пред-
грешность прогноза при r = 10 достигает   5% , в сказания, в оценивании управляемого объекта, осно-
случае числа нейронов во входном слое pвх = 64, ванных на сравнении выходных сигналов управляе-
внутреннем слое pвнутр = 10, выходном слое pвых = 10. мого объекта C *r

m  и его модели, в качестве которой 
При уменьшении числа нейронов во входном слое до используется нейронная сеть. 
pвх = 32 погрешность повышается до   (7...10)% .  Детализирующие коэффициенты di, вычисленные 

Полученные аппроксимирующие коэффициенты до уровня m (d1, d2, …, dm), после обработки алгорит-
прогноза C *r

m  с учетом необходимых для разных вы- мом сглаживания поступают на блоки восстановле-
ния выходного временного ряда прогноза.  

ходов нейронной сети задержек сравниваются с 
Алгоритм сглаживания детализирующих коэффи-

входными значениями Cm, что обеспечивает форми-
циентов по критерию адаптивного штрафного порога 

рование ошибок предсказаний e*r на всех p выходах 
имеет вид: 

нейронов выходного слоя нейронной сети. 
При этом формализуем процедуру вычисления di , di  0 ;

d *
i   

нейронной сетью аппроксимирующих коэффициен- 0, di  0 ,
тов прогноза, вычисление ошибок на выходах нейро-
нов каждого из слоев, а также процедуру адаптивной где   b 2

0  , 2
 – дисперсия шумовых составляю-

настройки синаптических весовых коэффициентов, щих во входном сигнале x(n), b – коэффициент про-
для каждого 1-го нейрона в рамках всех слоев порциональности, b  2ln N , N – число периодов 
нейронной сети. 

анализа. 
Аппроксимирующий коэффициент прогноза на 

Выходные сигналы с выходов нейронной сети в 
один период вычисляется на выходе l-го нейрона вы-

виде выходных аппроксимирующих коэффициентов 
ходного слоя в соответствии с выражением: 

C *r
m  (где r – номер выхода нейронной сети в соответ-

1
C *1

m  y31  3 (s10 )  . (14) ствии с числом периодов прогноза r[1, 10]) также 
1 exp(s10 ) поступают на r-й блок восстановления выходного 

На выходе 1-го нейрона выходного (3-го) слоя вы- временного ряда прогноза. На выходе r-х блоков вос-
числяется ошибка предсказания на один период – e*1 становления формируются выходные сигналы про-

31 , 
по которой вычисляется ошибка на выходе 1-го гноза в виде временного ряда s(n+r) [7]: 

нейрона предыдущего 2-го слоя нейронной сети –e21. 

1096 Компьютерная оптика, 2018, том 42, №6 



Метод прогнозирования изменений параметров временных рядов в цифровых… Кропотов Ю.А., Проскуряков А.Ю., Белов А.А. 

1  нала x(n) за счет формирования аппроксимирующих 
s(n  r)   x(n)1(2t  n)  коэффициентов m-го уровня Cm и подавляются ком-

p  n
 (15) поненты шума, имеющие место во входном сигнале, 

m 
C (2i ) C *r

i1 i t  n  путем обработки детализирующих коэффициентов 
m , алгоритмом сглаживания, что заметно снижает по-

n i2 n 
грешность представления информации. 

где r – число периодов времени прогноза, время про- Таким образом, полученный очищенный от по-
гноза определяется выражением tпрогн = rT. мех обработанный выходной временной ряд в ре-

Также в структурной схеме на рис. 2 представлен альном времени и обработанный выходной времен-
блок вейвлет-обработки временного ряда x(n) и блок ной ряд прогноза представляют информацию в 
восстановления выходного сигнала s(n) с пониженной устройствах отображения и в системах принятия 
погрешностью в соответствии с выражением восста- решений с более высокой точностью. Разработан-
новления: ный алгоритм нейросетевого прогнозирования из-

1  менения параметров временного ряда может быть 
s(n)   x(n)1(2t  n)  реализован в различных программных средах, та-

p  n
  (16) ких как MatLab Neural Network Toolbox, PyBrain и 

m 
 NeurophStudio. 

Ci 1 i (2i
  t  n) Cm  . Ошибки прогноза зависят от того, насколько раз-

n i2 n 
меры входного слоя ИНС соответствуют характерной 

В полученных выражениях (15) и (16), благодаря величине интервала временного ряда, по которому 
предварительной вейвлет-обработке в W-фильтре, можно восстановить его динамику, что подтвержда-
существенно ослабляются флуктуации входного сиг- ется графиками на рис. 3 и рис. 4 [2].  

а)        б)  
Рис. 3. Результаты отклонения прогноза от исследуемого процесса при размере сенсорного слоя 64 нейрона  

(T – период дискретизации) 

а)        б)  
Рис. 4. Результаты отклонения прогноза от исследуемого процесса при размере сенсорного слоя 200 нейронов 

Из рис. 3 и рис. 4 видно, что увеличение числа с 64 сенсорными нейронами (110 нейронов внут-
нейронов в первом (сенсорном) слое способствует ренний слой и 10 нейронов выходной слой) гори-
увеличению горизонта и уменьшению отклонения зонт предсказания может быть принят равным в 
прогноза от исследуемого процесса. Если для сети пределах 10T – 20T (рис. 3), то в случае 200 сен-

Компьютерная оптика, 2018, том 42, №6 1097 



Метод прогнозирования изменений параметров временных рядов в цифровых… Кропотов Ю.А., Проскуряков А.Ю., Белов А.А. 

сорных нейронов (110 нейронов внутренний слой и Литература 
10 нейронов выходной слой) (рис. 4) горизонт уве- 1. Кравцов, Ю.А. Случайность, детерминированность, 
личивается до 100T.  предсказуемость / Ю.Н. Кравцов // Успехи физических 

Выводы наук. - 1989. - Т. 158, № 1. - С. 93-122. - DOI: 
10.3367/UFNr.0158.198905c.0093. 

Существующие методы прогнозирования времен- 2. Ермолаев, В.А. О методах прогнозирования временных 
ных рядов и непрерывных процессов характеризуются рядов и непрерывных процессов / В.А. Ермолаев // Ра-
большим разнообразием, что, в свою очередь, обу- диотехнические и телекоммуникационные системы. - 
словлено большим разнообразием задач. Особый ин- 2016. - Вып. 2. - С. 52-63. 
терес в плане прогнозирования связан с представлени- 3. Бокс, Дж. Анализ временных рядов. Прогноз и управление 
ем временных рядов моделями авторегрессии и / Дж. Бокс, Г. Дженкинс. - М.: Мир, 1974. – 408 c. 
нейронными сетями. В работе показано, что в рамках 4. Маевский, В.В. Робастность регрессионного прогнозиро-
модели авторегрессии прогноз на несколько шагов вания при наличии функциональных искажений модели / 
вперед зависит от коэффициентов модели нелинейным В.В. Маевский, Ю.С. Харин // Автоматика и телемеханика. 
образом. При этом задачу прогноза, состоящую в - 2012. - Вып. 11. - С. 118-137. 
нахождении коэффициентов модели посредством ми- 5. Huang, N.E. The empirical mode decomposition and the Hil-

нимизации целевой функции, можно решить итераци- bert spectrum for nonlinear and non-stationary time series anal-

онным методом. Поэтому интерес представляют сети, ysis / N.E. Huang, Z. Shen, S.R. Long, M.C. Wu, H.H. Shin, 

реализующие функцию рекуррентного минимизирую- O. Zheng, N.C. Yen, C.C. Tung, H.H. Liu // Royal Society of 
London Proceedings Series A. - 1998. - Vol. 454, Issue 1971. - 

щего отклонения оценок от наблюдаемых значений P. 903-998. - DOI: 10.1098/rspa.1998.0193. 
временного ряда. В данной работе рассмотрены искус- 6. Дремин, И.М. Вейвлеты и их использование / 
ственные нейронные сети, в частности, рассмотрены И.М. Дремин, О.В. Иванов, В.А. Нечитайло // Успехи 
нейронные сети на персептроне с обратным распро- физических наук. - 2001. - Т. 17, № 5. - C. 465-501. - 
странением ошибки. В работе получены уравнения DOI: 10.3367/UFNr.0171.200105a.0465. 
функционирования и обучения искусственной нейрон- 7. Проскуряков, А.Ю. Алгоритмы автоматизированных си-
ной сети в матричной форме, получен алгоритм обрат- стем экологического мониторинга промышленных произ-
ной подстановки, с помощью которого можно увели- водств: монография. / А.Ю. Проскуряков, А.А. Белов, 
чить глубину прогноза. Результат моделирования и Ю.А. Кропотов. - Москва-Берлин: Директ-Медиа, 2015. - 
применения разработанного алгоритма заключается в 121 с. - ISBN: 978-5-4475-5245-9. 
повышении параметров результата прогнозирования 8. Пат. 2600099 Российская Федерация G 06 Q 10/04, G 06 
изменений значений исследуемых функций по показа- N 3/02. Способ нейросетевого прогнозирования изменения 
телям длительности и погрешности получения прогно- значений функции c её предварительной вейвлет-
за, а также быстродействия, адаптивности системы при обработкой и устройство его осуществления / Белов А.А., 

изменяющихся условиях. Дополнительным эффектом Ермолаев В.А., Кропотов Ю.А., Проскуряков А.Ю.; 

является также возможность гибкого изменения архи- 2015110284/08, заявл. 23.03.2015, опубл. 20.10.2016, Бюл. 

тектуры нейронной сети в случае изменения требова- № 29. 
9. Allende, H. Artificial neural networks in time series forecast-

ний на длительность прогноза. ing: a comparative analysis / H. Allende, C. Moraga, R. Salas // 
Предложенная структурная схема реализации Kybernetika. - 2002. - Vol. 38, No 6. - P. 685-707. 

нейросетевого прогнозирования изменений пара- 10. Zhang, G. Forecasting with artificial neural networks: The 
метров временных рядов с предварительной state of the art / G. Zhang, B.E. Patuwo, M.Y. Hu // Interna-
вейвлет-обработкой обеспечивает возможность до- tional Journal of Forecasting. - 1998. - Vol. 14, Issue 1. - 
статочно точного мониторинга исследуемых про- P. 35-62. - DOI: 10.1016/S0169-2070(97)00044-7. 
цессов в информационно-управляющих системах. 
 
 

Сведения об авторах 
Кропотов Юрий Анатольевич – доктор технических наук, профессор, заведующий кафедрой электроники 

и вычислительной техники». Муромский институт (филиал) Владимирского государственного университета 
имени Александра Григорьевича и Николая Григорьевич Столетовых. Область научных интересов: телекомму-
никационные и информационно-управляющие системы. E-mail: kaf-eivt@yandex.ru . 

 
Проскуряков Александр Юрьевич – кандидат технических наук, доцент кафедры электроники и вычисли-

тельной техники. Муромский институт (филиал) Владимирского государственного университета имени Алек-
сандра Григорьевича и Николая Григорьевич Столетовых. Область научных интересов: прогнозирование данных, 
нейронные сети, обработка и предсказание данных в экономических системах. E-mail: kaf-eivt@yandex.ru . 

 
Белов Алексей Анатольевич – кандидат технических наук, доцент, доцент кафедры электроники и вычисли-

тельной техники. Муромский институт (филиал) Владимирского государственного университета имени Алек-

1098 Компьютерная оптика, 2018, том 42, №6 



Метод прогнозирования изменений параметров временных рядов в цифровых… Кропотов Ю.А., Проскуряков А.Ю., Белов А.А. 

сандра Григорьевича и Николая Григорьевич Столетовых. Область научных интересов: телекоммуникационные 
системы мониторинга, обработка данных, методы вейвлет-преобразования. E-mail: aleks.murom@mail.ru .  
 
 

ГРНТИ: 50.43.17  
Поступила в редакцию 21 декабря 2017 г. Окончательный вариант – 26 июля 2018 г. 

 
 

METHOD FOR FORECASTING CHANGES IN TIME SERIES PARAMETERS  
IN DIGITAL INFORMATION MANAGEMENT SYSTEMS 

Y.A. Kropotov 1, A.Y. Proskuryakov 1, A.A. Belov 1 
1 Murom Institute (Branch) of Vladimir State University, Murom, Russia 

Abstract 
Predicting changes in the parameters of time series is of high significance when monitoring the 

research processes in digital information management systems. This task also arises when research-
ing the issues of increasing the prediction horizon and minimizing the forecast error. In this paper, we 
investigate prediction algorithms based on models that reproduce the dynamics of a time series in the 
form of artificial neural networks. We also consider the development of algorithms for control, func-
tioning and training of an artificial neural network in a matrix form and obtaining an algorithm for 
the return substitution, with the help of which it is possible to obtain an increase in the depth of the 
forecast. The paper presents the solution of the prediction problem consisting in finding prediction 
estimates by minimizing the loss function - the square of the norm of estimate deviation from the ob-
served values of the time series and in determining the model coefficients by using an artificial neural 
networks learning algorithm based on the iterative method of back-propagating errors. Application of 
the developed algorithms has allowed us to build a structural scheme for implementing neural net-
work forecasting, with the help of which it is possible to obtain a fairly accurate representation of 
changes in the parameters of time series in the process monitoring systems in terms of the runtime 
and the minimized error of the forecasting. 

Keywords: forecasting, information management systems, functional series, neural network, 
time series, three-layer perceptron. 

Citation: Kropotov YA, Proskuryakov AY, Belov AA. Method for forecasting changes in time 
series parameters in digital information management systems. Computer Optics 2018; 42(6): 1093-
1100. DOI: 10.18287/2412-6179-2018-42-6-1093-1100. 

References [6] Dremin IM, Ivanov OV, Nechitailo VA. Wavelets and 

[1] Kravcov YuA. Randomness, determinateness, and predict- their uses. Phys Usp 2001; 44(5): 447-478. DOI: 

ability. Sov Phys Usp 1989; 32(5): 434-449. DOI: 10.1070/PU2001v044n05ABEH000918. 

10.1070/PU1989v032n05ABEH002718. [7] Proskuryakov AYu, Belov AA, Kropotov YA. Algorithms 

[2] Ermolaev VA. Predictive methods of time series and con- of automated systems of ecological monitoring of industri-

tinuous processes [In Russian]. Radio and telecommunica- al productions: monogr [In Russian]. Moscow-Berlin: "Di-

tion systems 2016; 2: 52-63. rect-Media" Publisher; 2015. 

[3] Box G, Jenkins G. Time series analysis: Forecasting and [8] Belov AA, Ermolaev VА, Kropotov YA, Proskuryakov 

control. San Francisco: Holden-Day; 1970. AY. Method of neural network forecasting of change of 

[4] Maevskii VV, Kharin YuS. Robust regressive forecasting values of function with its complementary wavelet pro-

under functional distortions in a model. Automation and cessing and device for its implementation [In Russian]. Pat 

Remote Control 2002; 63(11): 1803-1820. RF of Invent N 2600099 of October 20, 2016, Russian Bull 

[5] Huang NE, Shen Z, Long SR, Wu MC, Shin HH, Zheng Q, of Inventions N29, 2016. 

Yen NC, Tung CC, Liu HH. The empirical mode decom- [9] Allende H, Moraga C, Salas R. Artificial neural networks 

position and the Hilbert spectrum for nonlinear and non- in time series forecasting: a comparative analysis. Kyber-

stationary time series analysis. Proc R Soc Lond A 1998; netika 2002; 38(6): 685-707. 

454(1971): 903-998. DOI: 10.1098/rspa.1998.0193. [10] Zhang G, Patuwo BE, Hu MY. Forecasting with artificial 
neural networks: The state of the art. International Journal 
of Forecasting 1998; 14(1): 35-62. DOI: 10.1016/S0169-
2070(97)00044-7. 

 
 

Author’s information 
Yuriy Anatolievich Kropotov – Dr. of Engineering Sciences, Full Professor. Head of Electronics and Computer Sci-

ence department. Murom Institute (Branch) of Vladimir State University named after Alexander and Nickolay Stoletovs. 
Field of research: telecommunication information and control systems. E-mail: kaf-eivt@yandex.ru . 

Компьютерная оптика, 2018, том 42, №6 1099 



Метод прогнозирования изменений параметров временных рядов в цифровых… Кропотов Ю.А., Проскуряков А.Ю., Белов А.А. 

 
Alexander Yurievich Proskuryakov – Ph.D. of Engineering Sciences, associate professor of Electronics and Com-

puter Science department. Murom Institute (Branch) of Vladimir State University named after Alexander and Nickolay 
Stoletovs. Field of research: data prediction, neural networks, data processing and prediction in economic systems. E-
mail: kaf-eivt@yandex.ru . 

 
Aleksey Anatolievich Belov – Ph.D. of Engineering Sciences, associate professor of Electronics and Computer Sci-

ence department. Murom Institute (Branch) of Vladimir State University named after Alexander and Nickolay 
Stoletovs. Field of research: telecommunication system monitoring, data processing, wavelet transform techniques.  
E-mail: aleks.murom@mail.ru . 
 
 

Received December 21, 2017. The final version – July 26, 2018.  
 
 

1100 Компьютерная оптика, 2018, том 42, №6