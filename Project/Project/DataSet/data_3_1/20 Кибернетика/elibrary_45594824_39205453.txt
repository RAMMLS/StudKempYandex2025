___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________
УДК 004.032.26 DOI 10.15622/ia.2021.20.2.8

 
А.Н. ГОЛУБИНСКИЙ, А.А. ТОЛСТЫХ 

ГИБРИДНЫЙ МЕТОД ОБУЧЕНИЯ СВЕРТОЧНЫХ 
НЕЙРОННЫХ СЕТЕЙ 

 
Голубинский А.Н., Толстых А.А. Гибридный метод обучения сверточных нейрон-
ных сетей. 

Аннотация. Предложен гибридный метод обучения сверточных нейронных сетей. 
Метод заключается в объединении методов второго и первого порядка для разных 
элементов архитектуры сверточной нейронной сети. Гибридный метод обучения 
сверточных нейронных сетей позволяет добиваться значительно лучшей сходимости 
по сравнению с методом обучения сверточных нейронных сетей «Adam» и требует 
меньше вычислительных операций для реализации. Рассматриваемый метод 
применим для обучения сетей, на которых происходит паралич обучения при 
использовании методов первого порядка. Более того, предложенный метод обладает 
способностью подстраивать свою вычислительную сложность под аппаратные 
средства, на которых производится вычисление, вместе с тем гибридный метод 
позволяет использовать подход обучения мини-пакетов. 

Приведен анализ соотношения вычислений между сверточными нейронными 
сетями и полносвязными искусственными нейронными сетями. Рассмотрен 
математический аппарат оптимизации ошибки искусственных нейронных сетей, 
включающий в себя метод обратного распространения ошибки, алгоритм Левенберга-
Марквардта. Проанализированы основные ограничения данных методов, 
возникающие при обучении сверточной нейронной сети. 

Проведен анализ устойчивости предлагаемого метода при 
изменении инициализирующих параметров. Приведены результаты 
применимости метода в различных задачах. 

Ключевые слова: сверточные нейронные сети, методы обучения 
искусственных нейронных сетей, методы оптимизации 

 
1. Введение. В задаче классификации объектов на телевизионных 

изображениях широко применяют сверточные нейронные сети (СНС), ко-
торые показывают в данном классе задач наилучшие результаты [1, 2]. Од-
нако существует набор проблем, присущих этому подходу. 

В настоящий момент невозможно использовать детерминистиче-
ские алгоритмы оптимизации функции ошибки СНС в реальных задачах 
ввиду их большой вычислительной сложности, что влечет за собой 
трудности при обучении СНС. Основным инструментом обучения СНС 
являются стохастический метод и его модернизации [1, 3, 4]. Данные 
методы подвержены сильному воздействию начальных условий и не 
могут гарантировать сходимость. С другой стороны, существуют ме-
тоды оптимизации второго порядка [5, 6], которые гарантируют сходи-
мость и менее зависимы от способа инициализации. Их основной про-
блемой является большая вычислительная сложность и использование 
большего объема памяти.  

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 463
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
СНС можно разделить на параметризатор и классификатор. Пер-

вый представляет собой набор сверточных слоев и слоев подвыборки 
разной конфигурации, второй – полносвязную искусственную нейрон-
ную сеть (ПИНС). Обычно классификатор имеет в своей архитектуре 3–
4 полносвязных слоя, в то время как параметризатор может иметь сотни 
и даже тысячи слоев [7, 8]. Методы обучения сверточных нейронных 
сетей как первого, так и второго порядков, используют понятие гради-
ента, через которое могут быть связанны. Таким образом, методы вто-
рого порядка целесообразно применить к классификатору, получив на 
входе классификатора градиент, который будет передан методам пер-
вого порядка для оптимизации параметризатора. 

В литературе в явном виде отсутствуют сведения о применении 
методов обучения второго порядка к СНС, в связи с этим необходимо 
рассмотреть эквивалентность сверточных и полносвязных слоев для 
адаптации вышеуказанных алгоритмов к СНС. Методы обучения пер-
вого порядка имеют ряд существенных недостатков, связанных с мед-
ленной скоростью обучения, возникновением эффекта паралича сети и 
др., что обуславливает актуальность научно-прикладных исследований 
по применению методов второго порядка к СНС. 

Целью работы является разработка гибридного метода обуче-
ния СНС в задачах классификации объектов на цифровых изображе-
ниях, позволяющего эффективно обучать СНС, достигая задан-
ного критерия останова. 

2. Анализ эквивалентности СНС и ПИНС. Рассмотрим подроб-
нее архитектуру сверточных слоев для анализа их эквивалентности полно-
связным слоям. На рисунке 1 приведена схема сверточного слоя (CL). 

Каждая карта СL-слоя может быть связана с некоторым количе-
ством карт предыдущего слоя. Из рис. 1 видно, что карта СL связана с 
двумя картами предыдущего слоя или входного слоя, которые располага-
ются перед ней. Каждый нейрон СL имеет рецептивное поле (РП) сразу 
на двух картах в идентичных позициях предыдущего слоя. На рисунке 1 
РП размером 2 2  обозначены сплошной линией и штрих-пунктиром. 
Значит, для нейрона СL необходимо 8 настраиваемых параметров (весов) 
с учётом смещения (bias). Особенность СL заключается в том, что для 
всех положений РП используются одни и те же веса. Такие веса называ-
ются связанными (sharing weights). Пунктиром на рис. 1 обозначено РП 
для следующего нейрона. Эти РП пересекаются, шаг пересечения регули-
руется на этапе построения СНС. РП и общие веса – это встроенная апри-
орная информация, которая является составной частью гиперпараметров, 
за счёт которой происходит выделение признаков. Нейроны СL имеют 
структуру, представленную на рисунке 2. 

 

464 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________

 
Рис. 1. Схема сверточного слоя (CL) 

 
  

 

   
 

  
 

Рис. 2. Структура нейрона СL 
 

На рисунке 2 KС  – общее количество нейронов или элементов 
входного вектора, входящих в РП n-го нейрона СL; F k  – настраивае-

мые веса нейрона; b  – смещение n-го нейрона, причём b  и F k  – 

одни и те же для всей карты СL; xn k   – входные данные для n-го 

нейрона СL k  0KC 1.  Входные данные xn  k   дают взвешен-

ную сумму с настраиваемыми параметрами F k : 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 465
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
KC 1

p  b   F k xnk .  (1) 
k0

 
Ядро выбирается исходя из размеров изображения, поступаю-

щего на вход СНС, шага сканирующего окна и заданной вычислитель-
ной сложности СНС. В общем случае ядро может быть любой прямо-
угольной матрицей, включая 11  [9]. Отклик нейрона определяет 
функция активации, на вход которой поступает взвешенная сумма p. 
Наиболее часто [1, 9, 7] используется семейство кусочно-линейных 
функций (Rectified Linear Unit, ReLU). Типичная кусочно-линейная 
функция выглядит следующим образом: 

 
f x  max 0, x ,  (2) 

 
где x – отклик нейрона; f – кусочно-линейная функция активации. 

Рассмотрим одно ядро F CL. Пусть вход CL X имеет размер-
ность 3 6 4,  где первое измерение обозначает количество карт при-
знаков во входных данных (например, цветовые каналы, в случае по-
ступления на вход изображения). Сверточное ядро положим размер-
ностью 2 2,  смещения S  2 , заполнение нулями P  0  по каждому 
измерению. Для каждой ячейки выходной карты признаков необхо-
димо произвести операцию: 

 
 2 2 1 

a  f  Xc,i2i, j2 j  F b ,  (3) 
 c0 i0 j0 

 
где i 2 i, j 2 j  – способ выбора подматрицы X;   – поэлементное 
умножение. Индексы матриц считаются с «0». Заметим, что необходимо 
вычислить 6 положений сканирующего окна для одного канала. Данное 
вычисление представлено графически на рисунке 3. 

На рисунке 4 представлена схема выбора значений внутри ска-
нирующего окна [1]: стрелками изображен способ преобразования 
двумерного изображения к одномерной последовательности пиксе-
лей, в рамках сканирующего окна. 

Приведем схему из рисунка 3 к полносвязному 
виду (рис. 5), используя схему выбора значений внутри скользя-
щего окна, приведенную выше. 

466 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________

 
Рис. 3. Схема вычисления отклика без активации для одного сверточного ядра 

и одной карты признаков входных данных 
 

 
Рис. 4. Схема выбора значений внутри сканирующего окна 

 

 
Рис. 5. Схема вычисления отклика без активации для одного сверточного ядра 

и одной карты признаков входных данных в виде полносвязного слоя 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 467
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
Как видно из рисунка 5, операцию вычисления для одного свер-

точного ядра и одной карты признаков входных данных можно предста-
вить как разреженный полносвязный слой. В данном случае каждый вес 
сверточного ядра участвует только в 6 операциях, вместо 24. Определим 
оператор M  ,  преобразующий вычисление для одного сверточного 
ядра и одной карты признаков входных данных к вычислению разре-
женного полносвязного слоя: 

 
M CLC

F X , F   MLP X , F  ,  (4) 
 

где C – конкретная карта признаков входных данных; F – ядро для дан-
ной карты. Оператор M преобразует входную карту признаков к виду 
вектор-строки, а также преобразует веса ядра F к виду матрицы разме-
ром  f1 f 2  s1s2  ,  где s1, s2 – количество смещений, получаемое при про-
ходе сканирующим окном по вертикали и горизонтали соответственно; 
f1, f2 – размерность ядра по вертикали и горизонтали соответственно. 
Используя (3) и свойство коммутативности умножения, группа преоб-
разований входных данных будет иметь вид: 
 

2 1
X    Xi2i, j2 j , X 22 X 14,  (5) 

i0 j0

 
или, в общем случае: 
 

s1 s2
X   Xi f i j f  j X   F  X   f f ,  

1 , ,
2 1 1 2  (6) 

i0 j0
 

Вторая группа преобразований в операторе M – преобразова-
ние ядра к виду вектор-строки. Данное преобразование выглядит сле-
дующим образом: 
 

FC  FC  FC  f1 f2 1; FC  IFC ,  (7) 
 

где I – диагональная единичная матрица размерностью  f1 f2  f1 f2 .  
Следует отметить, что веса вне основной диагонали не учувствуют в 
обучении (frozen parameters). 

468 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________
Используя принцип преобразования (см. рис. 4), получим вычис-

ление одного сверточного ядра и одной карты признаков входных дан-
ных к вычислению разреженного полносвязного слоя: 

 s1 s2
XC   XC ,i f1i, j f ,

2  j XC  FC  XC 1 f1 f2
 i0 j0

M CLC
F X , F  

: FC  FC  FC  f1 f2 1; FC  IFC ; (8)

 pC  XC FC .  




 
 

Рассмотрим операцию по вычислению свертки для всех карт при-
знаков входных параметров, преобразуем выражение (3) с учетом (8): 

 

 2 2 1 
a  f  Xc,i2i, j2 j  F  b 

 с0 i0 j0   (9) 
 2 

 f M CLc
F X , F .

 c0 
 

Графически данная операция представлена на рисунке 6. 
 

 

Первая карта  Вторая карта  Третья карта  
входных признаков входных признаков входных признаков

 
Рис. 6. Операция по вычислению свертки для всех карт признаков входных 

параметров 
 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 469
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
Данная операция аналогична вычислению 3х полносвязных 

слоев с последующим поэлементным сложением. Введем оператор 
D , выполняющий следующее преобразование: 

2
D(X , F ) :M CLC

F X , F   b.  (10) 
c0

 
Таким образом, для обработки одного сверточного слоя необхо-

димо вычислить C независимых полносвязных разряженных слоя. Об-
работка сверточного слоя сводится к: 

 
 2 2 1 

a  f  Xc,i2i, j2 j  Fc b 
 с0 i0 j0   

 f D(X , F).
 

 (11) 
в общем виде: 

 
 C s1 s2 

a  f  Xc,is1i, js2 j  Fc b 
 с0 i0 j0   (12) 

 f D(X , F).
 
Данное преобразование позволяет более тонко настраи-

вать свертку, вводя в диагональную матрицу весов из (8) дополни-
тельные веса вне главной диагонали. 

Рассмотрим обратное распространение ошибки через CL-слой, 
представленный оператором D. Данная операция аналогична классиче-
скому обратному распространению ошибки. Для экономии ресурсов це-
лесообразно использовать маску: 

 
M CLC

F X , F   MLP m.  (13) 
 

где m – маска, формируемая по следующему принципу: 
 

1, если i  j
mi, j   .  (14) 

0 иначе
 

470 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________
Учитывая замечание о том, что для более точной настройки 

свертки в (8) вводятся дополнительные веса вне главной диагонали, 
маска изменяется в соответствии с введенными весами. Учитывая, что 
матричное умножение разряженных матриц – дорогая операция, её сле-
дует заменить поэлементным умножением, градиенты в таком случае 
вычисляются на основе концепции вычислительного графа [10]. 

Таким образом, продемонстрирована эквивалентность СНС и 
ПИНС с разряженной матрицей весов. 

3. Анализ методов обучения искусственных нейронных сетей. 
В настоящее время наиболее используемым методом обучения искус-
ственных нейронных сетей (ИНС) является метод обратного распро-
странения ошибки (его модификации, например Adam [3]). Для даль-
нейшего применения следует рассмотреть классический метод обрат-
ного распространения ошибки, ввиду того, что модификации не изме-
няют его изначальной идеи. При рассмотрении будет использоваться 
наиболее простая функция ошибки – среднеквадратичная ошибка. 
Пусть ИНС имеет множество входных нейронов x1,...,xn, множество вы-
ходных нейронов y1,…,yn и множество скрытых нейронов. Перенуме-
руем все узлы (включая входы и выходы) числами от 1 до N (сквозная 
нумерация, вне зависимости от топологии слоёв). Обозначим через wi,j 
вес, находящийся на ребре, соединяющем i-й и j-й узлы, а через ri – вы-
ход i-го узла. Если известен обучающий пример – правильные ответы 
сети, такие что yk ,k Y . В данном случае функция ошибки будет иметь 
вид [2]: 

 

E w  1
i j  t  rk 

2
,  .  (15) 

2 k
kY

 
Чтобы достигнуть минимума ошибки, необходимо двигаться в 

сторону, противоположную градиенту, то есть, на основании каждой 
группы правильных ответов, добавлять к каждому весу wi,j: 
 

E
wi, j  

   .  
 (16) 
wi, j

 
Производная функции ошибки считается следующим образом. 

Пусть сначала jY , то есть вес входит в нейрон последнего слоя. Следует 
отметить, что wi,j влияет на выход сети только как часть суммы: 
 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 471
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
S j  wi, j xi ,  (17) 

i

 
где сумма берется по входам j-го узла. Из этого следует: 

E E S j E
  x

  i .  (18) 
wi, j S j wi, j S j

 
Аналогично, Sj влияет на общую ошибку только в рамках выхода 

j-го узла rj. Поэтому [2]: 
 

E E rj   1 
    2 

f (S) 
(t  r ) 

S r S r 2 k k  
j j j  j kY  S SS 

  
j (19) 

 2 rj (1 rj )(t j  rj ),
 
где f(S) – функция активации (в рассматриваемом случае экспоненци-
альная сигмоида). Если же j-й узел не на последнем слое, то у него есть 
выходы. Обозначим их через C(j). В этом случае: 
 

E  E S
 k ,  

 ( 0)
S j kC j Sk  2  

( ) S j

 
S S r 

k  k j r
 w j

j,k  2wj,k rj (1 rj ).  (21) 
S j rj S j S j

 
Описанный подход (17-21) имеет ряд недостатков. Во-первых, 

явление паралича сети. В процессе обучения сети значения весов могут, 
в результате коррекции, стать очень большими величинами. Данный 
факт может привести к тому, что все или большинство нейронов будут 
функционировать при очень больших выходных значениях в области, 
где производная функции активации мала. Так как посылаемая обратно 
в процессе обучения ошибка пропорциональна этой производной, то 
процесс обучения может практически замереть. В теоретическом отно-
шении эта проблема плохо изучена. Обычно этого избегают уменьше-
нием размера шага η, но это увеличивает время обучения. Различные 
эвристики [1, 2, 11] позволяют избежать паралич или восстановить про-
цесс обучения после него, но пока что они могут рассматриваться лишь 

472 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________
как экспериментальные. Во-вторых, алгоритм чувствителен к локаль-
ным минимумам. Обратное распространение использует разновидность 
градиентного спуска, то есть осуществляет спуск вниз по гиперповерх-
ности ошибки, непрерывно подстраивая веса в направлении к мини-
муму. Гиперповерхность ошибки сложной сети сильно изрезана и со-
стоит из холмов, долин, складок и оврагов в пространстве высокой раз-
мерности. Сеть может попасть в локальный минимум, когда рядом име-
ется гораздо более глубокий минимум. В точке локального минимума все 
направления ведут вверх, и сеть неспособна из него выбраться. Основную 
трудность при обучении нейронных сетей составляют как раз методы вы-
хода из локальных минимумов: каждый раз выходя из локального мини-
мума снова ищется следующий локальный минимум тем же методом об-
ратного распространения ошибки до тех пор, пока найти из него выход 
уже не удаётся. 

Методы второго порядка получили свое название благодаря ис-
пользованию второй производной функции ошибки, а также аппрокси-
мированного гессиана ИНС. В общем случае сущность данных методов 
можно выразить с помощью следующего соотношения [12]: 

 
W W 1

n n1  H  g  ,  (22) 
 

где W – веса ИНС; n – текущая эпоха обучения; H – гессиан функции 
ошибки; g – вектор градиента функции ошибки. Рассмотрим подробнее 
каждую составляющую данного выражения. Веса ИНС W представляют 
собой одномерный вектор, в который последовательно включены веса и 
смещения всех слоев ИНС. Градиент g представляет собой вектор, содер-
жащий производную ошибки по каждому из весов и смещений [5]: 
 

 E 
 w 
 1 

g  E     , wW .  (23) 
  
 E 
wk 

 
Гессиан по определению [12] является матрицей вторых произ-

водных функции ошибки E: 
 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 473
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
 2E 2E 
 
 w1w1 w1


wk 

H       .  (24) 
 
 2E 2

 E 
wkw1 w 
 kwk 

Вычисление гессиана является крайне затратной вычислительной 
процедурой. Так как необходимо вычислить k 2  вторых производных мно-
гомерной функции, где k –количество весов и смещений в ИНС. 

Наиболее эффективным методом из данного класса является метод 
Левенберга-Марквардта, заключающийся в аппроксимации гессиана с по-
мощью якобиана. Гессиан аппроксимируется следующим образом [5]: 

 
H  JT J I,  (25) 

 
где H – гессиан; J – якобиан;   – параметр регуляризации, изменяю-
щийся в процессе выполнения алгоритма; I – единичная матрица размерно-
стью J T J , в некоторых источниках [5] предлагается использование диа-
гональных элементов якобиана вместо единичной матрицы. Однако при 
проведении экспериментов значительные отличия применения единиц или 
элементов якобиана на диагонали I обнаружены не были. 

Градиент (23) в данном методе вычисляется следующим образом: 
 

g  E  J T e;
 e11 
  
 
e   (26) 

e  d  r  M1
  ,
 e12 
  
 
eMP 

 
где e –векторизованная ошибка; d – истинное значение вы-
хода ИНС; r – отклик ИНС; M – количество выходов; P – количество 
объектов в обучающей выборке. 

Рассмотрим составление матрицы якобиана. Так как якобиан – 
это матрица частных производных функции ошибки по всем настра-
иваемым параметрам модели, в случае ИНС – весам и смещениям, на 

474 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________
всей обучающей выборке [13], то размер данной матрицы соста-
вит (P M )T ,  где T – количество весов и смещений ИНС. В общем 
случае на каждой строке якобиана содержатся частные производные 
функции ошибки по всем весам и смещениям модели для конкретного 
выхода и объекта из обучающей выборки. Формально это выглядит 
следующим образом: 

 e1(P1)  e1(P1) 

 W1 W 

T 
J       .  (27) 


eMP (PP )  

 eMP (PP ) 
 W1 W 

T 
 

Следует отметить, что для применения метода Левенберга-
Марквардта удобнее представлять смещения как дополнительный вес 
нейрона, на вход которого всегда подается единица, подробнее дан-
ный подход к вычислению смещений рассмотрен в [2]. Для вычисле-
ния отдельных элементов якобиана необходимо модифицировать ме-
тод обратного распространения ошибки. Введем в (17) обозначение 
слоя и произведем замену входных данных на отклик предыдущего 
слоя для общности изложения: 
 

sl ( p)  l l
j wji y 1

i ( p),  (28) 
i

 

где y – отклик предыдущего слоя, p – текущий объект из обучающей вы-
борки P; l – текущий слой ИНС; j – текущий нейрон в j-ом слое; i – вес j-го 
нейрона. Отклик текущего слоя выражается следующим образом: 
 

yl p  f l
j ( ) (s j ( p)),  (29) 

 

где f ()  – функция активации. Используя (27) и применяя правило диф-
ференцирования по частям [11], элемент якобиана будет иметь вид: 
 

 l l
em ( p) rm ( p) y j ( p) s j ( p)

    ,  
l l (3

wji y j ( p) sl
j ( p) wl 0) 

ji

 
где m – текущий выход из набора M. 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 475
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
После вычисления матрицы якобиана для изменения весов ИНС 

необходимо выполнить процедуру, аналогичную обратному распро-
странению ошибки [5]. Для проведения операции обратного распро-
странения ошибки необходимо вычислить производную функции, опи-
сывающей преобразование сигнала между выходом нейрона j слоя l и 
выходом сети m на объекте из обучающей выборки p: 

 
 l   l   l

mj Fmj p f j  p ,  (31) 
где f l

j  p   – значение производной функции активации для нейрона j 
слоя l на объекте из обучающей выборки p. Для нейрона j выходного 
слоя l  L , выхода сети m и объекта обучающей выборки p значение 
производной описываемой функции определяется следующим обра-
зом [5]: 

 


    lL
lL f j  p , если m  j

fmj p   .  (32) 
0, иначе

 
Для полного описания производной функции, описывающей 

преобразование сигнала между выходом нейрона j выходного слоя 
l  L  и выходом сети m на всех объектах обучающей выборки P, 
необходимо P диагональных матриц M M , где M – количество вы-
ходов ИНС. После вычисления производной передаточной функции 
для выходного слоя последовательно вычисляются передаточные 
функции для всех остальных слоев: 
 

 l  p   wl1  l   l
mk ki  mk p fk  p ,  (33) 

i(l1)

 
где k – нейрон скрытого слоя l, i – скрытый нейрон последующего слоя 
l+1. Выражение (33) может быть записано в матричной форме (для каж-
дого объекта p из обучающей выборки) [5]: 
 

 l  p   l1  p W l  f l  pT ,  (34) 

 
где   – поэлементное умножение матриц. Обобщенная схема алго-
ритма обучения Левенберга-Марквардта представлена на рисунке 7. 

476 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________
Алгоритм Левенберга-Марквардта наиболее устойчив к измене-

нию начальной инициализации параметров ИНС, а также наиболее 
быстро сходится [14]. Недостатком данного алгоритма является высо-
кая вычислительная сложность. 

Для корректного сравнения алгоритмов обучения ИНС следует 
сравнить их основные характеристики: вычислительную сложность и 
используемое количество ячеек памяти. 
 

 
Рис. 7. Обобщенная схема алгоритма обучения Левенберга-Марквардта 

 
4. Гибридный алгоритм обучения ИНС. Предложенная мо-

дификация заключается в гибридизации двух методов – Левенберга-
Марквардта [5] и Adam [3]. Сочетание методов разных порядков 
возможно благодаря тому факту, что в якобиане и значении ошиб-
ки в косвенном виде присутствуют значения градиентов (26). Таким 
образом, вычисляется градиент на классификаторе СНС, а далее ин-
формация о градиентах передается в метод первого порядка Adam 
для вычисления весов сверточной части сети (параметризато-
ра). Данная гибридизация методов обучения позволяет увеличивать 
эффективность шага изменения параметров в полносвязной ча-
сти СНС, а также избегать излишней вычислительной сложно-
сти при вычислении изменения параметров сверточной части. Схе-
ма гибридного алгоритма обучения ИНС приведена на рисунке 8. 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 477
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________

 
Рис. 8. Схема гибридного алгоритма обучения ИНС 

 
На первом этапе, как и во всех алгоритмах обучения ИНС [1, 2], 

инициализируются параметры СНС – веса W и смещения b. При реали-
зации данного алгоритма использовалась инициализация весов, описан-
ная в [8]. Далее выполняются вычисления откликов СНС и ошибки 

478 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________
классификации. Затем выполняется цикл вычисления приращений па-
раметров W, b классификатора с помощью (22), (25)-(34). 

Градиенты, вычисленные на данном шаге, сохраняются в па-
мяти для последующего использования. После вычисления прираще-
ний параметров W, b классификатора градиенты g передаются в пара-
метризатор и вычисляются приращения параметров W, b параметри-
затора с помощью метода Adam. В конце итерации гибридный алго-
ритм вычисляет ошибку классификации при измененных ве-
сах и сравнивает её с критерием останова. В реализации использова-
лись критерии [14]: 
 

 1 
10log   ,  (35) 

 4Qp 
 
где Q – количество объектов в обучающей выборке; p – количество 
выходов СНС. Данный критерий выбирался в связи с тем, что 
при инициализации сети ошибки распознавания составляли порядка 
100% [14]. Следует отметить, что при использовании мини-паке-
тов (mini-batches) критерий останова рассчитывается от количества 
всех объектов в обучающей выборке, а не от количества объектов в 
мини-пакете. Ошибка обучения данного метода приводилась к пока-
зателю в децибелах: 
 

   0 2
yk  u 

 k 
EdB  10log  kp  ,  (36) 

  yn 2
  

 k uk  
 kp 

 
где n – текущая эпоха обучения; u – отклик при инициализации сети. 

Предложенный алгоритм позволяет производить обучение СНС 
как в режиме обработки всех обучающих данных одновременно, так 
и в режиме мини-пакетов. Для использования режима мини-паке-
тов необходимо арифметически усреднить приращения параметров 
W, b по всем мини-пакетам. 

Для оценки сложности рассмотренных алгоритмов введем следу-
ющие обозначения [15]:   – количество операций сложения, вычита-
ния и сравнения;   – количество операций умножения и деления;   
– количество нелинейных операций логарифмирования, вычисления 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 479
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
экспоненты. В таблице 1 приведены полученные аналитические 
оценки на основе учета количества требуемых тактов для каждой опе-
рации сложности составных частей для алгоритмов обучения СНС. 
Степень соответствия полученных оценок подтверждается экспери-
ментальным сравнением приведенных оценок с реализацией ИНС (с 
использованием библиотеки тензорных вычислений TensorFlow). Ре-
зультаты сравнения приведены на рисунке 9.  

1000000
900000
800000
700000
600000
500000
400000
300000 Оценка сложности
200000
100000 Реализация ИНС

0
10 30 50 70 90

Количество объектов в обучающих данных
 

Рис. 9. Сравнение полученных оценок вычислительной сложности с 
реализацией ИНС 

 
На рисунке 10 приведен график зависимости возрастания вычис-

лительной сложности рассмотренных алгоритмов в зависимости от раз-
мера батча и количество скрытых нейронов в последнем скрытом слое 
для СНС с архитектурой: 

 входные данные: тензор 15101 ; 
 3 сверточных ядра 55  со смещением 5 в первом CL; 
 слой подвыборки 3 2  с единичным смещением в MP слое; 
 2 нейрона в первом скрытом слое; 
 1 выходной нейрон. 

              Из рисунка 10 видно, что данная модификация алгоритма 
позволяет обучать СНС имущие любую архитектуру в то время, как 
классический метод Левенберга-Марквардта не позволяет работать с 
относительно большими СНС – требуется производить операции 

480 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________

Вычислительная сложность, FLOP



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________
с большими матрицами (размерностью количество параметров   ко-
личество обучающих объектов). 
 

Таблица 1. Вычислительная сложность слоев СНС 
Слои СНС Аналитическая оценка сложности 
Прямое вычисление СНС

b 
Полносвязный nini1      ni      

слой bi – количество объектов в батче; ni – количество 
нейронов на i слое. 

bCWHmwmh ( );
M w  F

W  w 1;  
Sw

Слой подвы- M h  F
борки H  h 1.

Sh

С – количество каналов в предыдущем слое; М – вход-
ной тензор; h, w – высота и ширина соответственно; S – 

смещение; m – окно подвыборки. 
b KCWH      KCWHfw fh   ;

M w  Fw  2P
W  w 1;  

Сверточный Sw

слой M h  Fh  2P
H  h 1.

Sh

K – количество ядер; 
f – матрица ядра; S – смещение; P – заполнение нулями. 

Adam 
  d  yN 1 N ;

Выходной   
полносвязный b nni1 10 13  2  2t  ,

слой   – составляющая градиента без умножения на вход-
ной вектор; N – отклик сети.

   i1W ;
 

Полносвязный nini1 10 15  2  nini1  nini1  2t ,
слой ni – количество нейронов в слое i, W – веса предыду-

щего слоя. 
Слой 

Нет настраиваемых параметров 
подвыборки 

 
 
 
 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 481
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
Продолжение таблицы 1 

Слои СНС Аналитическая оценка сложности 

   i1wi1 max(0,CL);

Kfw fh 7  9  2t  KCWH      KCWHfw fh   ;

M w  Fw  2P
W  w 1;

Сверточный Sw
слой 

M h  Fh  2P
H  h 1,

Sh

CL – отклик сверточного слоя; w – веса ядра сверточ-
ного слоя. 

Метод Левенберга-Марквардта 

Выходной слой: Jвых  bp ni1;  

Построение   i1 
cлой i: Ji  bp 2n n2

i i1  knk1    ,  
Якобиана  k0 

Ji – якобиан для i-го слоя; p – количество объектов в 
батче. 

H  JT J  I : l3/2 logl  l2.37  l  l; l  max b  p,wобщ 
H – якобиан; l – количество параметров СНС. Оценка 

Аппроксимация 
l3/2

якобиана log(l)  является оценкой транспонирования, оценка 

l2.37 wобщ
 – оценка матричного умножения [16]: – об-

щее количество настраиваемых параметров СНС. 

L    i1 
KСЛМ bp [ni1 ] L 1bp 2nin

2
i1  knk1   

i0   k0 
Общая вычис- l3/2 log l  l2.37  l  l   M l  l  FВ  E    

лительная 
сложность  pmba;

 2.37
E  pb  2  pb ,

где L – общее количество слоев СНС, E –вектор 
ошибки. 

 
 
 
 
 

482 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________
Продолжение таблицы 1 

Слои СНС Аналитическая оценка сложности 
Предложенный гибридный метод 

O   O1  
KСЛМ bp [ni1 ] O 1bp 2n n2

i i1  knk1   
  

i0   k0  
Общая вычис- l3/2

O log l l2.37
O  O  lO  l   M lO  lO  FВ  E    

лительная 
сложность  pmba  AdamL O,

O – количество слоев обучаемых методом Левенберга-
Марквардта; L – общее количество слоев СНС; Adam – вы-

числительная сложность для метода Adam. 

Рис. 10. Зависимость вычислительной сложности от размера батча и 
количества скрытых нейронов: 1 – сложность метода Левенберга-Марквардта; 
2 – сложность предложенного гибридного метода; 3 – сложность метода Adam 

5. Анализ эффективности гибридного алгоритма обучения
ИНС. Для анализа предложенного гибридного алгоритма была разрабо-
тана программа на языке python. Использовалась библиотека тензорных 
вычислений TensorFlow [10]. В качестве задач использовались следую-
щие наборы данных: Iris [1] – набор данных 4 значимых признака, 150 
объектов в обучающей выборке, 3 выхода ИНС; MNIST [17] – 784 зна-
чимых признака; 60000 объектов в обучающей выборке, 10 выходов 
ИНС. Результаты ошибки обучения для набора Iris приведены на ри-
сунке 11. Архитектура для решения задачи:  

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 483
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
 4 сверточных ядра 2 2  в первом CL; 
 4 нейрона в первом скрытом слое; 
 3 выходных нейрона. 
На рисунке 11 изображены только 100 эпох обучения, так как 

обучение ИНС методом Adam не улучшало ошибку ниже –23 дБ. Сле-
дует отметить, что предложенный метод эффективен: обладает высокой 
сходимостью и скоростью (по сравнению с Adam), а также мало отли-
чается по сходимости (не более чем на 10 дБ на протяжении всего обу-
чения) от метода Левенберга-Марквардта. Вычислительно предложен-
ный алгоритм достаточно сложен, однако его сложность возможно кон-
тролировать путем изменения количества слоев, обучаемых методом 
Левенберга-Марквардта, например, если классификатор имеет в своей 
архитектуре более 1000 нейронов, целесообразно обучать методом Ле-
венберга-Марквардта только два-три выходных слоя классификатора. В 
предельном случае, когда число параметров во всей СНС менее 2000, 
предложенный гибридный алгоритм сводится к методу Левенберга-
Марквардта. Подобная гибкость позволяет применять предложенный 
гибридный алгоритм как на мощных вычислительных серверах, так и на 
конечных устройствах, изменяя границу перехода между методом пер-
вого и второго порядка в зависимости от производительности вычисли-
тельных средств. В таблице 2 приведены полученные аналитические 
оценки сложности вычисления алгоритмов обучения СНС для рассмот-
ренных случаев. 

За основу расчета количества тактов процессора на выполнение опе-
раций были выбраны следующие усредненные значения: сложение и вычи-
тание ()  – 4 такта; умножение и деление ( )  – 20 тактов; нелинейные 
операции ( )  – 70 тактов. Оценка времени производилась на основе техни-
ческих параметров процессора Intel Core i7-4930K (Ivy Bridge), 3,4 ГГц, 6 
ядер (2013 г.) с пиковой производительностью Z=163 ГФлопс/с. Для 
оценки времени использовалась следующая формула: 

 
K

T  вс* ,  (38) 
Z V

 
где V – загруженность процессора конкретной задачей; Z – пиковая про-
изводительность. В расчетах V=0.75.  

 

484 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________

10

0

-10

-20

-30 Метод Adam
-40 Метод Левенберга-
-50 Марквардта

Гибридный алгоритм
-60

-70 Критерий останова

-80

-90
0 10 20 30 40 50 60 70 80 90 100

Эпохи обучения
 

Рис. 11. Ошибка обучения ИНС различными методами на наборе данных iris 
 

Таблица 2. Вычислительная сложность распознавания и обучения СНС 
Такты (усредненное 

Операция Время выполнения 
значение) 

Распознавание 2172 2.6 108  c.
Обучение Adam (1 

1890400 2.31 105  c.
эпоха)  
Обучение Левенберг-

14658396 
Марквардт (1 эпоха) 1.79 104  с. 

Обучение гибридный 
12252313 4  c. 

алгоритм (1 эпоха) 1.20 10

 
Рассмотрим более сложную задачу классификации изображе-

ний – набор данных MNIST. Это набор рукописных цифр, включаю-
щий в себя 60000 образцов. Гибридный метод обучения применялся 
в режиме мини-пакетов, результаты приведены на рисунке 12. Архи-
тектура для решения задачи: 4 сверточных ядра 33  со смещением 2 
в первом CL; подвыборка 2 2  со смещением 2; 5 сверточных ядер 
33  со смещением 2 во втором CL; подвыборка 2 2  со смещением 2; 
12 нейронов в первом скрытом слое; 11 нейронов во втором скрытом 
слое; 10 выходных нейронов. 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 485
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________

Ошибка обучения, дБ



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
Подобную СНС затруднительно обучить, используя метод Ле-

венберга-Марквардта ввиду того, что необходимо оперировать с матри-
цами размерностью более чем 5103,  однако предложенный гибридный 
алгоритм позволяет производить обучение. Следует отметить, что пред-
ложенный метод обеспечивает лучшую сходимость за эквивалентное 
время. Под эквивалентным временим понимается время, затраченное на 
вычисление обоих алгоритмов. В приведенном эксперименте эквива-
лентным временем выступает время 4000 эпох обучения методом Adam, 
соответствующее 20 эпохам обучения гибридного метода. При этом для 
обучения алгоритмом Adam наблюдается эффект паралича сети (сеть не 
обучилась), а гибридный метод обеспечил обучение до критерия оста-
нова –8 дБ, что соответствует 95% точности классификации. Аналогич-
ные результаты наблюдались и на выборках большей размерности, 
например, для данных размерностью 2242243  (цветные изображе-
ния военной техники) точность классификации составила 93.5% при эк-
вивалентном времени расчета. 

0
-1
-2
-3 Гибридный 

алгоритм
-4

Метод 
-5 Adam
-6
-7
-8

1 10 100 1000
Эпохи обучения

 
Рис. 12. Ошибка обучения ИНС различными методами на наборе данных 

MNIST (логарифмический масштаб по оси эпох) 
 

Предложенный гибридный алгоритм обучения СНС эффективен 
при выполнении следующих условий: ограниченное время обучения на 
заданной архитектуре и достаточное количество ресурсов для проведе-
ния вычислений значений гессиана. 

6. Заключение. В работе продемонстрирована эквивалент-
ность СНС и ПИНС, предложен способ внесения дополнительных ве-
сов в структуру CL-слоев. 

486 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________

Ошибка обучения, дБ



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________
Предложен гибридный метод обучения СНС, совмещающий в 

себе метод Левенберга-Марквардта и Adam. Гибридный метод обуче-
ния СНС позволяет добиваться значительно лучшей сходимости по 
сравнению с Adam и требует меньше вычислительных операций для ре-
ализации. Используя предложенный метод возможно обучать сети, на 
которых происходит паралич обучения при использовании методов пер-
вого порядка. Более того, предложенный метод обладает способностью 
подстраивать свою вычислительную сложность под аппаратные сред-
ства, на которых производится вычисление, вместе с тем гибридный ме-
тод позволяет использовать подход обучения мини-пакетов.  

Также в работе приведены результаты вычислительных экспери-
ментов на различных наборах данных для оценки эффективности ги-
бридного алгоритма обучения СНС. Показано, что предложенный алго-
ритм обучения позволяет достичь ошибки, отличающейся не более чем 
на 10 дБ от ошибки, полученной методом Левенберга-Марквардта. 

 
Литература 

1. Гудфеллоу Я., Бенджио И., Курвилль А. Глубокое обучение // М.: ДМК Пресс. 
2017. 652 с. 

2. Хайкин С. Нейронные сети. Полный курс // М.: Вильямс. 2006. 1104 с. 
3. Kingma D.P., Ba J.A. A Method for Stochastic Optimization // CoRR. Т. 

abs/1412.6980. 2014. 
4. Bo Y.H., WeiL., I-Chen W. Stochastic Gradient Descent with Hyperbolic-Tangent De-

cay // CoRR. Т. abs/1806.01593. 2018. pp. 1–10. 
5. Wilamowski B.M., Irwin D.J. Intelligent systems // CRC Press. 2011. 568 p. 
6. Smith J.S., Wu B., Wilamowski B.M. Neural Network Training With Levenberg-Mar-

quardt and Adaptable Weight Compression // IEEE Transactions on Neural Networks 
and Learning Systems. 2018. pp. 1–8. 

7. Szegedy C., Ioffe S., Vanhoucke V., Alemi A.A. Inception-v4, Inception-ResNet and the 
Impact of Residual Connections on Learning // International Conference on Learning 
Representations (ICLR) Workshop. 2016. pp. 375–387. 

8. He K., Zhang X., Ren S., Sun J. Delving Deep into Rectifiers: Surpassing Human-Level 
Performance on ImageNet Classification // arXiv.org e-Print archive. 2015. URL: 
https://arxiv.org/abs/1502.01852 (дата обращения: 12.11.2020). 

9. Szegedy С. et al. Going deeper with convolutions // IEEE Conference on Computer 
Vision and Pattern Recognition. 2014. pp. 1–9. 

10. Zaccone G., Karim R., Menshawy A. Deep Learning with TensorFlow: Explore neural 
networks with Python // Packt Publishing. 2017. 320 p. 

11. Вьюгин В.В. Математические основы теории машинного обучения и прогнозиро-
вания // М.: МЦНМО. 2013. 387 с. 

12. Shepherd A.J. Second-Order Methods for Neural Networks: Fast and Reliable Training 
Methods for Multi-Layer Perceptrons // Springer. 1997. 160 p. 

13. Nocedal J., Wright S.J. Numerical Optimization // Springer. 2006. 664 p. 
14. Голубинский А.Н. О построении архитектур и оценке параметров искусственных 

нейронных сетей // Теория и техника радиосвязи. 2020. № 1. С. 72–87. 
15. Максимушкин В.В., Арзамасцев А.А. Сравнительная оценка вычислительной 

сложности обучения искусственной нейронной сети с жестким ядром и сети с 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 487
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
классической структурой // Вестник российских университетов. Математика., 
2006. № 2. С. 190–197. 

16. Абрамов С.А. Лекции о сложности алгоритмов // М.: МЦНМО. 2012. 248 с. 
17. Yann LeCun's Home Page. MNIST handwritten digit database, Yann LeCun, Corinna 

Cortes and Chris Burges. 2012. URL: http://yann.lecun.com/exdb/mnist/ (дата 
обращения: 23.05.2020). 

18. Smith L.N. No More Pesky Learning Rate Guessing Games // CoRR. 2015. pp. 1–10. 
19. Salimans T., Kingma D.P. Weight Normalization: A Simple Reparameterization to Ac-

celerate Training of Deep Neural Networks // Advances in Neural Information Pro-
cessing Systems 29. 2016. pp. 901–909. 

20. Matuszyk P., Castillo R.T., Kottke D., Spiliopoulou M. A Comparative Study on Hy-
perparameter Optimization for Recommender Systems // Workshop on Recommender 
Systems and Big Data Analytics (RS-BDA'16). 2016. 

21. Hu G. et al. Frankenstein: Learning Deep Face Representations using Small Data // 
IEEE Transactions on Image Processing. 2017. vol. 27. no. 1. pp. 293–303. 

22. Ioffe S., Szegedy C. Batch Normalization: Accelerating Deep Network Training by Re-
ducing Internal Covariate Shift // International conference on machine learning. 2015. 
pp. 448–456. 

23. Lewkowycz A. et al. The large learning rate phase of deep learning: the catapult mecha-
nism. 2020. 

24. Liao Q., Kawaguchi K., Poggio T.A. Streaming Normalization: Towards Simpler and 
More Biologically-plausible Normalizations for Online and Recurrent Learning // 
CoRR. Т. abs/1610.06160. 2016. 

25. Mahajan D. et al. Exploring the Limits of Weakly Supervised Pretraining // CoRR. Т. 
abs/1805.00932. 2018. 

26. Petroski S.F. et al. Deep Neuroevolution: Genetic Algorithms Are a Competitive Alter-
native for Training Deep Neural Networks for Reinforcement Learning // ArXiv e-
prints. 2017. 

27. Su H., Zhu X., Gong S. Deep Learning Logo Detection with Data Expansion by Synthe-
sising Context // 2017 IEEE winter conference on applications of computer vi-
sion (WACV). 2017. pp. 530–539. 

28. Xu C., Qin T., Wang G., Liu T.Y. An Actor-Critic Algorithm For Learning Rate 2017. 
pp. 1–12. 

29. Xu C., Qin T., Wang G., Liu T.Y. Reinforcement Learning for Learning Rate Control // 
arXiv preprint arXiv:1705.11159. 2017. 

 
Голубинский Андрей Николаевич – д-р техн. наук, доцент, заместитель научного руко-
водителя, АО «Концерн «Созвездие». Область научных интересов: математическое моде-
лирование систем с элементами искусственного интеллекта. Число научных публикаций 
– 205. annikgol@mail.ru; Московский пр., 92, 394068, Воронеж, Россия; 
р.т.: +79103436537. 
 
Толстых Андрей Андреевич – преподаватель кафедры, кафедра специальных информа-
ционных технологий, Московский университет МВД России им. В.Я. Кикотя. Область 
научных интересов: искусственные нейронные сети, машинное обучение. Число научных 
публикаций – 52. tolstykh.aa@yandex.ru; Коптевская, 63, 125239, Москва, Россия; р.т.: 
+79102427955. 
  

488 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________



___________A_R_T_I_F_IC__IA_L_ _IN__T_E_L_L_I_G_E_N_C__E_, _K_N_O__W__L_E_D_G_E__ A_N__D_ D__A_T_A_ _E_N_G__IN_E__E_R_I_N_G___________
DOI 10.15622/ia.2021.20.2.8 

 

A. GOLUBINSIY, A. TOLSTYKH 
HYBRID METHOD OF CONVENTIONAL NEURAL NETWORK 

TRAINING 
 

Golubinsiy A., Tolstykh A.  Hybrid Method of Conventional Neural Network Training. 
Abstract. The paper proposes a hybrid method for training convolutional neural networks. The 

method consists in combining second and first order methods for different elements of the architecture 
of a convolutional neural network. The hybrid convolution neural network training method allows to 
achieve significantly better convergence compared to Adam and requires fewer computational 
operations to implement. Using the proposed method, it is possible to train networks on which learning 
paralysis occurs when using first-order methods. Moreover, the proposed method could adjust its 
computational complexity to the hardware on which the computation is performed; at the same time, 
the hybrid method allows using the batch learning approach. 

The analysis of the ratio of computations between convolutional neural networks and fully 
connected artificial neural networks is presented. The mathematical apparatus of error 
optimization of artificial neural networks is considered, including the method of back 
propagation of the error, the Levenberg-Marquardt algorithm. The main limitations of these 
methods that arise when training a convolutional neural network are analyzed. 

The analysis of the stability of the proposed method when the initialization parameters are 
changed. The results of the applicability of the method in various problems are presented. 

Keywords: Сonvolutional Neural Networks, Training Methods for Artificial Neural 
Networks, Optimization Methods 
 
Golubinskiy Andrey – Ph.D., Dr.Sci., Associate Professor, Head of Scientific Director, JSC 
“Concern “Sozvezdie”. Research interests: mathematical modeling of systems with elements of 
artificial intelligence. The number of publications – 205. annikgol@mail.ru; 92, Moskovsky 
prospect, 394068, Voronezh, Russia; office phone: +79103436537. 
 
Tolstykh Andrey – Lecturer of the Department, Department of Special Information 
Technologies, Moscow University of the Ministry of Internal Affairs of Russia. Research 
interests: artificial neural networks, machine learning. The number of publications – 52. 
tolstykh.aa@yandex.ru; 63, Koptevskaya, 125239, Moscow, Russia; office 
phone: +79102427955. 
 

References 
1. Gudfellou Ia., Bendjıo I., Kýrvıll A. Glubokoe obuchenie [Deep learning]. M.: DMK 

Press. 2017. 652 p. (In Russ.). 
2. Haıkın S. Nejronnye seti. Polnyj kurs [Neural networks. Complete course]. M.: 

Vil'yams2006. 1104 p. (In Russ.). 
3. Kingma D.P., Ba J.A. A Method for Stochastic Optimization. CoRR. Т. abs/1412.6980. 

2014. 
4. Bo Y.H., WeiL., I-Chen W. Stochastic Gradient Descent with Hyperbolic-Tangent De-

cay. CoRR. Т. abs/1806.01593. 2018. pp. 1–10. 
5. Wilamowski B.M., Irwin D.J. Intelligent systems. CRC Press. 2011. 568 p. 
6. Smith J.S., Wu B., Wilamowski B.M. Neural Network Training With Levenberg-Mar-

quardt and Adaptable Weight Compression. IEEE Transactions on Neural Networks 
and Learning Systems. 2018. pp. 1–8. 

7. Szegedy C., Ioffe S., Vanhoucke V., Alemi A.A. Inception-v4, Inception-ResNet and 
the Impact of Residual Connections on Learning. International Conference on Learning 
Representations (ICLR) Workshop. 2016. pp. 375–387. 

Informatics and Automation. 2021. Vol. 20 No. 2. ISSN 2713-3192 (print) 489
ISSN 2713-3206 (online) www.ia.spcras.ru

_______________________________________________________________________________



___________И_С_К__У_С_С_Т_В__Е_Н_Н_Ы__Й_ _И_Н_Т_Е__Л_Л_Е_К_Т_,_ И__Н_Ж__Е_Н_Е_Р_И__Я_ _Д_А_Н_Н__Ы_Х_ _И_ _З_Н_А_Н__И_Й___________
8. He K., Zhang X., Ren S., Sun J. Delving Deep into Rectifiers: Surpassing Human-Level 

Performance on ImageNet Classification. arXiv.org e-Print archive. 2015. Available at: 
https://arxiv.org/abs/1502.01852 (accessed: 12.11.2020). 

9. Szegedy С. et al. Going deeper with convolutions. IEEE Conference on Computer Vi-
sion and Pattern Recognition. 2014. pp. 1–9. 

10. Zaccone G., Karim R., Menshawy A. Deep Learning with TensorFlow: Explore neural 
networks with Python. Packt Publishing. 2017. 320 p. 

11. Shepherd A.J. Second-Order Methods for Neural Networks: Fast and Reliable Training 
Methods for Multi-Layer Perceptrons. New York: Springer, 1997. 160 pp. 

12. Shepherd A.J. Second-Order Methods for Neural Networks: Fast and Reliable Training 
Methods for Multi-Layer Perceptrons. Springer. 1997. 160 p. 

13. Nocedal J., Wright S.J. Numerical Optimization. Springer. 2006. 664 p. 
14. Golubinskij A.N. [On the construction of architectures and the assessment of the pa-

rameters of artificial neural networks]. Teoriya i tekhnika radiosvyazi – Theory and 
technology of radio communication. 2020. vol. 1. pp. 72–87. (In Russ.). 

15. Maksimushkın V.V., Arzamastsev A.A. [Comparative evaluation of the computational 
complexity of training an artificial neural network with a hard core and a network with 
a classical structure]. Vestnik rossiiskih universitetov. Matematıka – Russian Universi-
ties Reports. Mathematics. 2006. vol. 2. pp. 190–197. (In Russ.). 

16. Abramov S.A. Lekcii o slozhnosti algoritmov [Lectures on the complexity of algo-
rithms]. M.: MCNMO. 2012. 248 p. (In Russ.). 

17. Yann LeCun's Home Page. MNIST handwritten digit database, Yann LeCun, Corinna 
Cortes and Chris Burges. 2012. Available at: http://yann.lecun.com/exdb/mnist/ (ac-
cessed: 23.05.2020). 

18. Smith L.N. No More Pesky Learning Rate Guessing Games. CoRR. 2015. pp. 1–10. 
19. Salimans T., Kingma D.P. Weight Normalization: A Simple Reparameterization to Ac-

celerate Training of Deep Neural Networks. Advances in Neural Information Pro-
cessing Systems 29. 2016. pp. 901–909. 

20. Matuszyk P., Castillo R.T., Kottke D., Spiliopoulou M. A Comparative Study on Hy-
perparameter Optimization for Recommender Systems. Workshop on Recommender 
Systems and Big Data Analytics (RS-BDA'16). 2016. 

21. Hu G. et al. Frankenstein: Learning Deep Face Representations using Small Data. IEEE 
Transactions on Image Processing. 2017. vol. 27. no. 1. pp. 293–303. 

22. Ioffe S., Szegedy C. Batch Normalization: Accelerating Deep Network Training by Re-
ducing Internal Covariate Shift. International conference on machine learning. 2015. 
pp. 448–456. 

23. Lewkowycz A. et al. The large learning rate phase of deep learning: the catapult mech-
anism. 2020. 

24. Liao Q., Kawaguchi K., Poggio T.A. Streaming Normalization: Towards Simpler and 
More Biologically-plausible Normalizations for Online and Recurrent Learning. CoRR. 
Т. abs/1610.06160. 2016. 

25. Mahajan D. et al. Exploring the Limits of Weakly Supervised Pretraining. CoRR. Т. 
abs/1805.00932. 2018. 

26. Petroski S.F. et al. Deep Neuroevolution: Genetic Algorithms Are a Competitive Alter-
native for Training Deep Neural Networks for Reinforcement Learning. ArXiv e-prints. 
2017. 

27. Su H., Zhu X., Gong S. Deep Learning Logo Detection with Data Expansion by Syn-
thesising Context. 2017 IEEE winter conference on applications of computer vi-
sion (WACV). 2017. pp. 530–539. 

28. Xu C., Qin T., Wang G., Liu T.Y. An Actor-Critic Algorithm for Learning Rate 2017. 
pp. 1–12. 

29. Xu C., Qin T., Wang G., Liu T.Y. Reinforcement Learning for Learning Rate Control. 
arXiv preprint arXiv:1705.11159. 2017. 

490 Информатика и автоматизация. 2021. Том 20 № 2. ISSN 2713-3192 (печ.) 
ISSN 2713-3206 (онлайн) www.ia.spcras.ru

_______________________________________________________________________________